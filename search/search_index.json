{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-]","pipeline":["stemmer"]},"docs":[{"location":"","title":"\ud83d\udcd5 Documentation","text":""},{"location":"#table-of-contents","title":"\ud83d\udd17 Table of Contents","text":"<ul> <li>\ud83d\udcd5 Documentation</li> <li>\ud83d\udd17 Table of Contents</li> <li>\ud83d\udcdd Overview</li> <li>\ud83d\uddfa Module Structure</li> <li>\ud83e\uddf1 Our Documentation System</li> <li>\ud83c\udf8a Contribution<ul> <li>\ud83d\udd8a Adding a New Documentation</li> <li>\ud83e\uddf9 Doc Testing</li> <li>\ud83d\udc89 Auto Documentation</li> </ul> </li> </ul>"},{"location":"#overview","title":"\ud83d\udcdd Overview","text":"<p>We evaluated various existing solutions for documentation in the community and discussed their advantages and disadvantages in the issue #2651. Therefore, we propose to build a more modern and robust documentation system by integrating the Sphinx autodoc function and the Docusaurus framework.</p>"},{"location":"#module-structure","title":"\ud83d\uddfa Module Structure","text":"<pre><code>- docs\n    - source\n        - en\n        - zh-Hans\n    - sidebars.json\n    - versions.json\n    - requirements-doc-test.txt\n</code></pre> <p>The documentation module structure is shown above: 1. source: This folder contains multi-language documentation files. 2. <code>sidebars.json</code>: The <code>sidebars.json</code> defines the table of content for the tutorials. You need to update this file when a new doc is added/deleted. 3. <code>versions.json</code>: The <code>versions.json</code> in the main branch in the latest commit will be used to control the versions to be displayed on our website</p>"},{"location":"#our-documentation-system","title":"\ud83e\uddf1 Our Documentation System","text":"<p>We believe that the combination of the existing systems can yield several advantages such as simplicity, usability and maintainability: 1. Support Markdown. We believe is a more popular language for writing documentation compared to RST. 2. Support Autodoc. It can automatically generate documentation from the docstrings in the source code provided by Sphinx. 3. Support elegant and modern UI, which is provided by Docusaurus. 4. Support MDX for more flexible and powerful documentation, which is provided by Docusaurus. 5. Support hosting blogs/project home page/other pages besides the documentation, which is provided by Docusaurus.</p> <p>Therefore, we have built the ColossalAI-Documentation repository to integrate the features above.</p>"},{"location":"#contribution","title":"\ud83c\udf8a Contribution","text":"<p>You can contribute to the documentation by directly setting up a Pull Request towards the <code>docs/source</code> folder. There are several guidelines for documentation contribution.</p> <ol> <li>The documentation is written in Markdown. You can refer to the Markdown Guide for the syntax.</li> <li>You must ensure that the documentation exists for all languages. You can refer to the Adding a New Documentation for more details.</li> <li>You must provide a test command for your documentation, please see Doc Testing for more details.</li> <li>You can embed your docstring in your markdown, please see Auto Documentation for more details.</li> </ol>"},{"location":"#adding-a-new-documentation","title":"\ud83d\udd8a Adding a New Documentation","text":"<p>You can add a Markdown file to the <code>docs/source</code> folder<code>. You need to ensure that multi-language is supported in your PR. Let's assume that you want to add a file called</code>your_doc.md`, your file structure will look like this.</p> <pre><code>- docs\n  - source\n    - en\n        - your_doc.md  # written in English\n    - zh-Hans\n        - your_doc.md  # written in Chinese\n  - sidebars.json  # add your documentation file name here\n</code></pre> <p>Meanwhile, you need to ensure the <code>sidebars.json</code> is updated such that it contains your documentation file. Our CI will check whether documentation exists for all languages and can be used to build the website successfully.</p>"},{"location":"#doc-testing","title":"\ud83e\uddf9 Doc Testing","text":"<p>Every documentation is tested to ensure it works well. You need to add the following line to the bottom of your file and replace <code>$command</code> with the actual command. Do note that the markdown will be converted into a Python file. Assuming you have a <code>demo.md</code> file, the test file generated will be <code>demo.py</code>. Therefore, you should use <code>demo.py</code> in your command, e.g. <code>python demo.py</code>.</p> <pre><code>&lt;!-- doc-test-command: $command  --&gt;\n</code></pre> <p>Meanwhile, only code labeled as a Python code block will be considered for testing.</p> <pre><code>    ```python\n    print(\"hello world\")\n    ```\n</code></pre> <p>Lastly, if you want to skip some code, you just need to add the following annotations to tell <code>docer</code> to discard the wrapped code for testing.</p> <pre><code>&lt;!--- doc-test-ignore-start --&gt;\n\n    ```python\n    print(\"hello world\")\n    ```\n\n&lt;!--- doc-test-ignore-end --&gt;\n</code></pre> <p>If you have any dependency required, please add it to <code>requirements-doc-test.txt</code> for pip and <code>conda-doc-test-deps.yml</code> for Conda.</p>"},{"location":"#auto-documentation","title":"\ud83d\udc89 Auto Documentation","text":"<p>Lastly, you may want to include the API documentation for a class/function in your documentation for reference. We support <code>autodoc</code> to extract the docstring and transform it into a Web element for an elegant display. You just need to add <code>{{ autodoc:&lt;mod-name&gt; }}</code> in your markdown as a single line. An example is given below and you can see the outcome in this PR.</p> <pre><code>{{ autodoc:colossalai.legacy.amp.apex_amp.convert_to_apex_amp }}\n</code></pre>"},{"location":"README-zh-Hans/","title":"Colossal-AI","text":"[![logo](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png)](https://www.colossalai.org/)     Colossal-AI: \u200b\u8ba9\u200bAI\u200b\u5927\u200b\u6a21\u578b\u200b\u66f4\u200b\u4f4e\u6210\u672c\u200b\u3001\u200b\u65b9\u4fbf\u200b\u6613\u7528\u200b\u3001\u200b\u9ad8\u6548\u200b\u6269\u5c55\u200b       \u200b\u8bba\u6587\u200b  |     \u200b\u6587\u6863\u200b  |     \u200b\u4f8b\u7a0b\u200b  |     \u200b\u8bba\u575b\u200b  |     \u200b\u535a\u5ba2\u200b      [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/ColossalAI?style=social)](https://github.com/hpcaitech/ColossalAI/stargazers)    [![Build](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml/badge.svg)](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml)    [![Documentation](https://readthedocs.org/projects/colossalai/badge/?version=latest)](https://colossalai.readthedocs.io/en/latest/?badge=latest)    [![CodeFactor](https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge)](https://www.codefactor.io/repository/github/hpcaitech/colossalai)    [![HuggingFace badge](https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow)](https://huggingface.co/hpcai-tech)    [![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp;)](https://github.com/hpcaitech/public_assets/tree/main/colossalai/contact/slack)    [![WeChat badge](https://img.shields.io/badge/\u200b\u5fae\u4fe1\u200b-\u200b\u52a0\u5165\u200b-green?logo=wechat&amp;)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png)     | [English](README.md) | [\u200b\u4e2d\u6587\u200b](README-zh-Hans.md) |"},{"location":"README-zh-Hans/#_1","title":"\u65b0\u95fb","text":"<ul> <li>[2023/09] One Half-Day of Training Using a Few Hundred Dollars Yields Similar Results to Mainstream Large Models, Open-Source and Commercial-Free Domain-Specific Llm Solution</li> <li>[2023/09] 70 Billion Parameter LLaMA2 Model Training Accelerated by 195%</li> <li>[2023/07] HPC-AI Tech Raises 22 Million USD in Series A Funding</li> <li>[2023/07] 65B Model Pretraining Accelerated by 38%, Best Practices for Building LLaMA-Like Base Models Open-Source</li> <li>[2023/03] ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline</li> <li>[2023/03] Intel and Colossal-AI Partner to Deliver Cost-Efficient Open-Source Solution for Protein Folding Structure Prediction</li> <li>[2023/03] AWS and Google Fund Colossal-AI with Startup Cloud Programs</li> <li>[2023/02] Open Source Solution Replicates ChatGPT Training Process! Ready to go with only 1.6GB GPU Memory</li> <li>[2023/01] Hardware Savings Up to 46 Times for AIGC and  Automatic Parallelism</li> </ul>"},{"location":"README-zh-Hans/#_2","title":"\u76ee\u5f55","text":"<ul> <li>\u200b\u4e3a\u4f55\u200b\u9009\u62e9\u200b Colossal-AI </li> <li>\u200b\u7279\u70b9\u200b </li> <li> Colossal-AI \u200b\u6210\u529f\u200b\u6848\u4f8b\u200b <ul> <li>Colossal-LLaMA-2: \u200b\u5343\u5143\u200b\u9884\u7b97\u200b\u534a\u5929\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6548\u679c\u200b\u5ab2\u7f8e\u200b\u4e3b\u6d41\u200b\u5927\u200b\u6a21\u578b\u200b\uff0c\u200b\u5f00\u6e90\u200b\u53ef\u200b\u5546\u7528\u200b\u4e2d\u6587\u200bLLaMA-2</li> <li>ColossalChat\uff1a\u200b\u5b8c\u6574\u200bRLHF\u200b\u6d41\u7a0b\u200b0\u200b\u95e8\u69db\u200b\u514b\u9686\u200bChatGPT</li> <li>AIGC: \u200b\u52a0\u901f\u200b Stable Diffusion</li> <li>\u200b\u751f\u7269\u533b\u836f\u200b: \u200b\u52a0\u901f\u200bAlphaFold\u200b\u86cb\u767d\u8d28\u200b\u7ed3\u6784\u200b\u9884\u6d4b\u200b</li> </ul> </li> <li> \u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u6837\u4f8b\u200b\u5c55\u793a\u200b <ul> <li>LLaMA 1/2</li> <li>GPT-3</li> <li>GPT-2</li> <li>BERT</li> <li>PaLM</li> <li>OPT</li> <li>ViT</li> <li>\u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u6a21\u578b\u200b</li> </ul> </li> <li> \u200b\u5355\u200bGPU\u200b\u8bad\u7ec3\u200b\u6837\u4f8b\u200b\u5c55\u793a\u200b <ul> <li>GPT-2</li> <li>PaLM</li> </ul> </li> <li> \u200b\u63a8\u7406\u200b (Energon-AI) \u200b\u6837\u4f8b\u200b\u5c55\u793a\u200b <ul> <li>GPT-3</li> <li>1750\u200b\u4ebf\u200b\u53c2\u6570\u200bOPT\u200b\u5728\u7ebf\u200b\u63a8\u7406\u200b\u670d\u52a1\u200b</li> <li>1760\u200b\u4ebf\u200b\u53c2\u6570\u200b BLOOM</li> </ul> </li> <li> \u200b\u5b89\u88c5\u200b <ul> <li>PyPI</li> <li>\u200b\u4ece\u200b\u6e90\u4ee3\u7801\u200b\u5b89\u88c5\u200b</li> </ul> </li> <li>\u200b\u4f7f\u7528\u200b Docker</li> <li>\u200b\u793e\u533a\u200b</li> <li>\u200b\u505a\u51fa\u200b\u8d21\u732e\u200b</li> <li>\u200b\u5f15\u7528\u200b\u6211\u4eec\u200b</li> </ul>"},{"location":"README-zh-Hans/#colossal-ai_1","title":"\u4e3a\u4f55\u200b\u9009\u62e9\u200b Colossal-AI","text":"James Demmel \u200b\u6559\u6388\u200b (\u200b\u52a0\u5dde\u5927\u5b66\u200b\u4f2f\u514b\u5229\u5206\u6821\u200b): Colossal-AI \u200b\u8ba9\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u9ad8\u6548\u200b\u3001\u200b\u6613\u7528\u200b\u3001\u200b\u53ef\u200b\u6269\u5c55\u200b\u3002  <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#_3","title":"\u7279\u70b9","text":"<p>Colossal-AI \u200b\u4e3a\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u5e76\u884c\u200b\u7ec4\u4ef6\u200b\u3002\u200b\u6211\u4eec\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u8ba9\u200b\u60a8\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b AI \u200b\u6a21\u578b\u200b\u50cf\u200b\u6784\u5efa\u200b\u666e\u901a\u200b\u7684\u200b\u5355\u200b GPU \u200b\u6a21\u578b\u200b\u4e00\u6837\u200b\u7b80\u5355\u200b\u3002\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u7684\u200b\u53cb\u597d\u200b\u5de5\u5177\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u60a8\u200b\u5728\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u5185\u200b\u5feb\u901f\u200b\u5f00\u59cb\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406\u200b\u3002</p> <ul> <li>\u200b\u5e76\u884c\u200b\u5316\u200b\u7b56\u7565\u200b</li> <li>\u200b\u6570\u636e\u200b\u5e76\u884c\u200b</li> <li>\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b</li> <li>1\u200b\u7ef4\u200b, 2\u200b\u7ef4\u200b, 2.5\u200b\u7ef4\u200b, 3\u200b\u7ef4\u200b \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b</li> <li>\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b</li> <li>\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b (ZeRO)</li> <li>\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b</li> <li>\u200b\u5f02\u6784\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b</li> <li>PatrickStar</li> <li>\u200b\u4f7f\u7528\u200b\u53cb\u597d\u200b</li> <li>\u200b\u57fa\u4e8e\u200b\u53c2\u6570\u200b\u6587\u4ef6\u200b\u7684\u200b\u5e76\u884c\u200b\u5316\u200b</li> <li>\u200b\u63a8\u7406\u200b</li> <li>Energon-AI</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#colossal-ai_2","title":"Colossal-AI \u200b\u6210\u529f\u200b\u6848\u4f8b","text":""},{"location":"README-zh-Hans/#colossal-llama-2","title":"Colossal-LLaMA-2","text":"<ul> <li>\u200b\u5343\u5143\u200b\u9884\u7b97\u200b\u534a\u5929\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6548\u679c\u200b\u5ab2\u7f8e\u200b\u4e3b\u6d41\u200b\u5927\u200b\u6a21\u578b\u200b\uff0c\u200b\u5f00\u6e90\u200b\u53ef\u200b\u5546\u7528\u200b\u4e2d\u6587\u200bLLaMA-2 [\u200b\u4ee3\u7801\u200b] [\u200b\u535a\u5ba2\u200b] [\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b]</li> </ul> Backbone Tokens Consumed MMLU CMMLU AGIEval GAOKAO CEval - 5-shot 5-shot 5-shot 0-shot 5-shot Baichuan-7B - 1.2T 42.32 (42.30) 44.53 (44.02) 38.72 36.74 42.80 Baichuan-13B-Base - 1.4T 50.51 (51.60) 55.73 (55.30) 47.20 51.41 53.60 Baichuan2-7B-Base - 2.6T 46.97 (54.16) 57.67 (57.07) 45.76 52.60 54.00 Baichuan2-13B-Base - 2.6T 54.84 (59.17) 62.62 (61.97) 52.08 58.25 58.10 ChatGLM-6B - 1.0T 39.67 (40.63) 41.17 (-) 40.10 36.53 38.90 ChatGLM2-6B - 1.4T 44.74 (45.46) 49.40 (-) 46.36 45.49 51.70 InternLM-7B - 1.6T 46.70 (51.00) 52.00 (-) 44.77 61.64 52.80 Qwen-7B - 2.2T 54.29 (56.70) 56.03 (58.80) 52.47 56.42 59.60 Llama-2-7B - 2.0T 44.47 (45.30) 32.97 (-) 32.60 25.46 - Linly-AI/Chinese-LLaMA-2-7B-hf Llama-2-7B 1.0T 37.43 29.92 32.00 27.57 - wenge-research/yayi-7b-llama2 Llama-2-7B - 38.56 31.52 30.99 25.95 - ziqingyang/chinese-llama-2-7b Llama-2-7B - 33.86 34.69 34.52 25.18 34.2 TigerResearch/tigerbot-7b-base Llama-2-7B 0.3T 43.73 42.04 37.64 30.61 - LinkSoul/Chinese-Llama-2-7b Llama-2-7B - 48.41 38.31 38.45 27.72 - FlagAlpha/Atom-7B Llama-2-7B 0.1T 49.96 41.10 39.83 33.00 - IDEA-CCNL/Ziya-LLaMA-13B-v1.1 Llama-13B 0.11T 50.25 40.99 40.04 30.54 - Colossal-LLaMA-2-7b-base Llama-2-7B 0.0085T 53.06 49.89 51.48 58.82 50.2"},{"location":"README-zh-Hans/#colossalchat","title":"ColossalChat","text":"<p>ColossalChat: \u200b\u5b8c\u6574\u200bRLHF\u200b\u6d41\u7a0b\u200b0\u200b\u95e8\u69db\u200b\u514b\u9686\u200b ChatGPT [\u200b\u4ee3\u7801\u200b] [\u200b\u535a\u5ba2\u200b] [\u200b\u5728\u7ebf\u200b\u6837\u4f8b\u200b] [\u200b\u6559\u7a0b\u200b]</p> <p> </p> <ul> <li>\u200b\u6700\u9ad8\u200b\u53ef\u200b\u63d0\u5347\u200bRLHF PPO\u200b\u9636\u6bb5\u200b3\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b10\u200b\u500d\u200b</li> </ul> <p> </p> <ul> <li>\u200b\u6700\u9ad8\u200b\u53ef\u200b\u63d0\u5347\u200b\u5355\u673a\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b7.73\u200b\u500d\u200b\uff0c\u200b\u5355\u5361\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b1.42\u200b\u500d\u200b</li> </ul> <p> </p> <ul> <li>\u200b\u5355\u5361\u200b\u6a21\u578b\u200b\u5bb9\u91cf\u200b\u6700\u200b\u591a\u200b\u63d0\u5347\u200b10.3\u200b\u500d\u200b</li> <li>\u200b\u6700\u5c0f\u200bdemo\u200b\u8bad\u7ec3\u200b\u6d41\u7a0b\u200b\u6700\u4f4e\u200b\u4ec5\u200b\u9700\u200b1.62GB\u200b\u663e\u5b58\u200b (\u200b\u4efb\u610f\u200b\u6d88\u8d39\u200b\u7ea7\u200bGPU)</li> </ul> <p> </p> <ul> <li>\u200b\u63d0\u5347\u200b\u5355\u5361\u200b\u7684\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\u5bb9\u91cf\u200b3.7\u200b\u500d\u200b</li> <li>\u200b\u540c\u65f6\u200b\u4fdd\u6301\u200b\u9ad8\u901f\u8fd0\u884c\u200b</li> </ul> <p>(back to top)</p>"},{"location":"README-zh-Hans/#aigc","title":"AIGC","text":"<p>\u200b\u52a0\u901f\u200bAIGC(AI\u200b\u5185\u5bb9\u200b\u751f\u6210\u200b)\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u200bStable Diffusion v1 \u200b\u548c\u200b Stable Diffusion v2</p> <p> </p> <ul> <li>\u200b\u8bad\u7ec3\u200b: \u200b\u51cf\u5c11\u200b5.6\u200b\u500d\u200b\u663e\u5b58\u200b\u6d88\u8017\u200b\uff0c\u200b\u786c\u4ef6\u200b\u6210\u672c\u200b\u6700\u9ad8\u200b\u964d\u4f4e\u200b46\u200b\u500d\u200b(\u200b\u4ece\u200bA100\u200b\u5230\u200bRTX3060)</li> </ul> <p> </p> <ul> <li>DreamBooth\u200b\u5fae\u8c03\u200b: \u200b\u4ec5\u200b\u9700\u200b3-5\u200b\u5f20\u200b\u76ee\u6807\u200b\u4e3b\u9898\u200b\u56fe\u50cf\u200b\u4e2a\u6027\u5316\u200b\u5fae\u8c03\u200b</li> </ul> <p> </p> <ul> <li>\u200b\u63a8\u7406\u200b: GPU\u200b\u63a8\u7406\u200b\u663e\u5b58\u200b\u6d88\u8017\u200b\u964d\u4f4e\u200b2.5\u200b\u500d\u200b</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#_4","title":"\u751f\u7269\u533b\u836f","text":"<p>\u200b\u52a0\u901f\u200b AlphaFold \u200b\u86cb\u767d\u8d28\u200b\u7ed3\u6784\u200b\u9884\u6d4b\u200b</p> <p> </p> <ul> <li>FastFold: \u200b\u52a0\u901f\u200bAlphaFold\u200b\u8bad\u7ec3\u200b\u4e0e\u200b\u63a8\u7406\u200b\u3001\u200b\u6570\u636e\u200b\u524d\u200b\u5904\u7406\u200b\u3001\u200b\u63a8\u7406\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u8d85\u8fc7\u200b10000\u200b\u6b8b\u57fa\u200b</li> </ul> <p> </p> <ul> <li>FastFold with Intel: 3\u200b\u500d\u200b\u63a8\u7406\u200b\u52a0\u901f\u200b\u548c\u200b39%\u200b\u6210\u672c\u200b\u8282\u7701\u200b</li> </ul> <p> </p> <ul> <li>xTrimoMultimer: 11\u200b\u500d\u200b\u52a0\u901f\u200b\u86cb\u767d\u8d28\u200b\u5355\u4f53\u200b\u4e0e\u200b\u590d\u5408\u7269\u200b\u7ed3\u6784\u200b\u9884\u6d4b\u200b</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#_5","title":"\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u6837\u4f8b\u200b\u5c55\u793a","text":""},{"location":"README-zh-Hans/#llama2","title":"LLaMA2","text":"<ul> <li>700\u200b\u4ebf\u200b\u53c2\u6570\u200bLLaMA2\u200b\u8bad\u7ec3\u200b\u52a0\u901f\u200b195% [code] [blog]</li> </ul>"},{"location":"README-zh-Hans/#llama1","title":"LLaMA1","text":"<ul> <li>650\u200b\u4ebf\u200b\u53c2\u6570\u200b\u5927\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u52a0\u901f\u200b38% [\u200b\u4ee3\u7801\u200b] [\u200b\u535a\u5ba2\u200b]</li> </ul>"},{"location":"README-zh-Hans/#gpt-3","title":"GPT-3","text":"<ul> <li>\u200b\u91ca\u653e\u200b 50% GPU \u200b\u8d44\u6e90\u200b\u5360\u7528\u200b, \u200b\u6216\u200b 10.7% \u200b\u52a0\u901f\u200b</li> </ul>"},{"location":"README-zh-Hans/#gpt-2","title":"GPT-2","text":"<ul> <li>\u200b\u964d\u4f4e\u200b11\u200b\u500d\u200b GPU \u200b\u663e\u5b58\u200b\u5360\u7528\u200b\uff0c\u200b\u6216\u8d85\u200b\u7ebf\u6027\u200b\u6269\u5c55\u200b\uff08\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff09</li> </ul> <ul> <li>\u200b\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u8bad\u7ec3\u200b24\u200b\u500d\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b</li> <li>\u200b\u8d85\u200b3\u200b\u500d\u200b\u7684\u200b\u541e\u5410\u91cf\u200b</li> </ul>"},{"location":"README-zh-Hans/#bert","title":"BERT","text":"<ul> <li>2\u200b\u500d\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\uff0c\u200b\u6216\u200b1.5\u200b\u500d\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b</li> </ul>"},{"location":"README-zh-Hans/#palm","title":"PaLM","text":"<ul> <li>PaLM-colossalai: \u200b\u53ef\u200b\u6269\u5c55\u200b\u7684\u200b\u8c37\u6b4c\u200b Pathways Language Model (PaLM) \u200b\u5b9e\u73b0\u200b\u3002</li> </ul>"},{"location":"README-zh-Hans/#opt","title":"OPT","text":"<ul> <li>Open Pretrained Transformer (OPT), \u200b\u7531\u200bMeta\u200b\u53d1\u5e03\u200b\u7684\u200b1750\u200b\u4ebf\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u7531\u4e8e\u200b\u5b8c\u5168\u200b\u516c\u5f00\u200b\u4e86\u200b\u9884\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\u6743\u91cd\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4fc3\u8fdb\u200b\u4e86\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200b\u548c\u200b\u5e94\u7528\u200b\u90e8\u7f72\u200b\u7684\u200b\u53d1\u5c55\u200b\u3002</li> <li>\u200b\u52a0\u901f\u200b45%\uff0c\u200b\u4ec5\u7528\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u4ee5\u200b\u4f4e\u6210\u672c\u200b\u5fae\u8c03\u200bOPT\u3002[\u200b\u6837\u4f8b\u200b] [\u200b\u5728\u7ebf\u200b\u63a8\u7406\u200b]</li> </ul> <p>\u200b\u8bf7\u200b\u8bbf\u95ee\u200b\u6211\u4eec\u200b\u7684\u200b \u200b\u6587\u6863\u200b \u200b\u548c\u200b \u200b\u4f8b\u7a0b\u200b \u200b\u4ee5\u200b\u4e86\u89e3\u200b\u8be6\u60c5\u200b\u3002</p>"},{"location":"README-zh-Hans/#vit","title":"ViT","text":"<ul> <li>14\u200b\u500d\u6279\u200b\u5927\u5c0f\u200b\u548c\u200b5\u200b\u500d\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\uff08\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b=64\uff09</li> </ul>"},{"location":"README-zh-Hans/#_6","title":"\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u6a21\u578b","text":"<ul> <li>Cached Embedding, \u200b\u4f7f\u7528\u200b\u8f6f\u4ef6\u200bCache\u200b\u5b9e\u73b0\u200bEmbeddings\uff0c\u200b\u7528\u200b\u66f4\u5c11\u200bGPU\u200b\u663e\u5b58\u200b\u8bad\u7ec3\u200b\u66f4\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#gpu","title":"\u5355\u200bGPU\u200b\u8bad\u7ec3\u200b\u6837\u4f8b\u200b\u5c55\u793a","text":""},{"location":"README-zh-Hans/#gpt-2_1","title":"GPT-2","text":"<ul> <li>\u200b\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u8bad\u7ec3\u200b20\u200b\u500d\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b</li> </ul> <ul> <li>\u200b\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u8bad\u7ec3\u200b120\u200b\u500d\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b (RTX 3080)</li> </ul>"},{"location":"README-zh-Hans/#palm_1","title":"PaLM","text":"<ul> <li>\u200b\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u8bad\u7ec3\u200b34\u200b\u500d\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#energon-ai","title":"\u63a8\u7406\u200b (Energon-AI) \u200b\u6837\u4f8b\u200b\u5c55\u793a","text":"<ul> <li>Energon-AI \uff1a\u200b\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u63a8\u7406\u200b\u52a0\u901f\u200b50%</li> </ul> <ul> <li>OPT\u200b\u63a8\u7406\u200b\u670d\u52a1\u200b: \u200b\u4f53\u9a8c\u200b1750\u200b\u4ebf\u200b\u53c2\u6570\u200bOPT\u200b\u5728\u7ebf\u200b\u63a8\u7406\u200b\u670d\u52a1\u200b</li> </ul> <ul> <li>BLOOM: \u200b\u964d\u4f4e\u200b1760\u200b\u4ebf\u200b\u53c2\u6570\u200bBLOOM\u200b\u6a21\u578b\u200b\u90e8\u7f72\u200b\u63a8\u7406\u200b\u6210\u672c\u200b\u8d85\u200b10\u200b\u500d\u200b</li> </ul> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#_7","title":"\u5b89\u88c5","text":"<p>\u200b\u73af\u5883\u200b\u8981\u6c42\u200b:</p> <ul> <li>PyTorch &gt;= 1.11 (PyTorch 2.x \u200b\u6b63\u5728\u200b\u9002\u914d\u200b\u4e2d\u200b)</li> <li>Python &gt;= 3.7</li> <li>CUDA &gt;= 11.0</li> <li>NVIDIA GPU Compute Capability &gt;= 7.0 (V100/RTX20 and higher)</li> <li>Linux OS</li> </ul> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u9047\u5230\u200b\u5b89\u88c5\u200b\u95ee\u9898\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5411\u672c\u200b\u9879\u76ee\u200b \u200b\u53cd\u9988\u200b\u3002</p>"},{"location":"README-zh-Hans/#pypi","title":"\u4ece\u200bPyPI\u200b\u5b89\u88c5","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7528\u200b\u4e0b\u9762\u200b\u7684\u200b\u547d\u4ee4\u200b\u76f4\u63a5\u200b\u4ece\u200bPyPI\u200b\u4e0a\u200b\u4e0b\u8f7d\u200b\u5e76\u200b\u5b89\u88c5\u200bColossal-AI\u3002\u200b\u6211\u4eec\u200b\u9ed8\u8ba4\u200b\u4e0d\u4f1a\u200b\u5b89\u88c5\u200bPyTorch\u200b\u6269\u5c55\u200b\u5305\u200b\u3002</p> <pre><code>pip install colossalai\n</code></pre> <p>\u200b\u6ce8\u200b\uff1a\u200b\u76ee\u524d\u200b\u53ea\u200b\u652f\u6301\u200bLinux\u3002</p> <p>\u200b\u4f46\u662f\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u5728\u200b\u5b89\u88c5\u200b\u65f6\u200b\u5c31\u200b\u76f4\u63a5\u200b\u6784\u5efa\u200bPyTorch\u200b\u6269\u5c55\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8bbe\u7f6e\u200b\u73af\u5883\u53d8\u91cf\u200b<code>CUDA_EXT=1</code>.</p> <pre><code>CUDA_EXT=1 pip install colossalai\n</code></pre> <p>\u200b\u5426\u5219\u200b\uff0cPyTorch\u200b\u6269\u5c55\u200b\u53ea\u4f1a\u200b\u5728\u200b\u4f60\u200b\u5b9e\u9645\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u4ed6\u4eec\u200b\u65f6\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u91cc\u200b\u88ab\u200b\u6784\u5efa\u200b\u3002</p> <p>\u200b\u4e0e\u6b64\u540c\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u4e5f\u200b\u6bcf\u5468\u200b\u5b9a\u65f6\u200b\u53d1\u5e03\u200bNightly\u200b\u7248\u672c\u200b\uff0c\u200b\u8fd9\u80fd\u200b\u8ba9\u200b\u4f60\u200b\u63d0\u524d\u200b\u4f53\u9a8c\u200b\u5230\u200b\u65b0\u200b\u7684\u200bfeature\u200b\u548c\u200bbug fix\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5b89\u88c5\u200bNightly\u200b\u7248\u672c\u200b\u3002</p> <pre><code>pip install colossalai-nightly\n</code></pre>"},{"location":"README-zh-Hans/#_8","title":"\u4ece\u200b\u6e90\u7801\u200b\u5b89\u88c5","text":"<p>\u200b\u6b64\u200b\u6587\u6863\u200b\u5c06\u200b\u4e0e\u200b\u7248\u672c\u200b\u5e93\u200b\u7684\u200b\u4e3b\u200b\u5206\u652f\u200b\u4fdd\u6301\u4e00\u81f4\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\uff0c\u200b\u6b22\u8fce\u200b\u7ed9\u200b\u6211\u4eec\u200b\u63d0\u200b issue :)</p> <pre><code>git clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# install dependency\npip install -r requirements/requirements.txt\n\n# install colossalai\npip install .\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u9ed8\u8ba4\u200b\u5728\u200b<code>pip install</code>\u200b\u65f6\u200b\u4e0d\u200b\u5b89\u88c5\u200bPyTorch\u200b\u6269\u5c55\u200b\uff0c\u200b\u800c\u662f\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u200b\u4e34\u65f6\u200b\u7f16\u8bd1\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u8981\u200b\u63d0\u524d\u200b\u5b89\u88c5\u200b\u8fd9\u4e9b\u200b\u6269\u5c55\u200b\u7684\u8bdd\u200b\uff08\u200b\u5728\u200b\u4f7f\u7528\u200b\u878d\u5408\u200b\u4f18\u5316\u200b\u5668\u200b\u65f6\u4f1a\u200b\u7528\u5230\u200b\uff09\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4e00\u4e0b\u200b\u547d\u4ee4\u200b\u3002</p> <pre><code>CUDA_EXT=1 pip install .\n</code></pre> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#docker","title":"\u4f7f\u7528\u200b Docker","text":""},{"location":"README-zh-Hans/#dockerhub","title":"\u4ece\u200bDockerHub\u200b\u83b7\u53d6\u200b\u955c\u50cf","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4ece\u200b\u6211\u4eec\u200b\u7684\u200bDockerHub\u200b\u4e3b\u9875\u200b\u83b7\u53d6\u200b\u6700\u65b0\u200b\u7684\u200b\u955c\u50cf\u200b\uff0c\u200b\u6bcf\u200b\u4e00\u6b21\u200b\u53d1\u5e03\u200b\u6211\u4eec\u200b\u90fd\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u4e0a\u4f20\u200b\u6700\u65b0\u200b\u7684\u200b\u955c\u50cf\u200b\u3002</p>"},{"location":"README-zh-Hans/#_9","title":"\u672c\u5730\u200b\u6784\u5efa\u200b\u955c\u50cf","text":"<p>\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ece\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u7684\u200b docker \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5efa\u7acb\u200b docker \u200b\u955c\u50cf\u200b\u3002</p> <p>\u200b\u5728\u200bDockerfile\u200b\u91cc\u200b\u7f16\u8bd1\u200bColossal-AI\u200b\u9700\u8981\u200b\u6709\u200bGPU\u200b\u652f\u6301\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200bNvidia Docker Runtime\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u9ed8\u8ba4\u200b\u7684\u200bRuntime\u3002\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u70b9\u51fb\u200b\u8fd9\u91cc\u200b\u3002 \u200b\u6211\u4eec\u200b\u63a8\u8350\u200b\u4ece\u200b\u9879\u76ee\u200b\u4e3b\u9875\u200b\u76f4\u63a5\u200b\u4e0b\u8f7d\u200bColossal-AI.</p> <pre><code>cd ColossalAI\ndocker build -t colossalai ./docker\n</code></pre> <p>\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ece\u4ee5\u200b\u4ea4\u4e92\u5f0f\u200b\u542f\u52a8\u200b docker \u200b\u955c\u50cf\u200b.</p> <pre><code>docker run -ti --gpus all --rm --ipc=host colossalai bash\n</code></pre> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#_10","title":"\u793e\u533a","text":"<p>\u200b\u6b22\u8fce\u200b\u901a\u8fc7\u200b\u8bba\u575b\u200b, Slack, \u200b\u6216\u200b\u5fae\u4fe1\u200b\u52a0\u5165\u200b Colossal-AI \u200b\u793e\u533a\u200b\uff0c\u200b\u4e0e\u200b\u6211\u4eec\u200b\u5206\u4eab\u200b\u4f60\u200b\u7684\u200b\u5efa\u8bae\u200b\u548c\u200b\u95ee\u9898\u200b\u3002</p>"},{"location":"README-zh-Hans/#_11","title":"\u505a\u51fa\u200b\u8d21\u732e","text":"<p>\u200b\u53c2\u8003\u200b\u793e\u533a\u200b\u7684\u200b\u6210\u529f\u200b\u6848\u4f8b\u200b\uff0c\u200b\u5982\u200b BLOOM and Stable Diffusion \u200b\u7b49\u200b, \u200b\u65e0\u8bba\u662f\u200b\u4e2a\u4eba\u200b\u5f00\u53d1\u8005\u200b\uff0c\u200b\u8fd8\u662f\u200b\u7b97\u529b\u200b\u3001\u200b\u6570\u636e\u200b\u3001\u200b\u6a21\u578b\u200b\u7b49\u200b\u53ef\u80fd\u200b\u5408\u4f5c\u65b9\u200b\uff0c\u200b\u90fd\u200b\u6b22\u8fce\u200b\u53c2\u4e0e\u200b\u53c2\u4e0e\u200b\u5171\u5efa\u200b Colossal-AI \u200b\u793e\u533a\u200b\uff0c\u200b\u62e5\u62b1\u200b\u5927\u200b\u6a21\u578b\u200b\u65f6\u4ee3\u200b\uff01</p> <p>\u200b\u60a8\u200b\u53ef\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u8054\u7cfb\u200b\u6216\u200b\u53c2\u4e0e\u200b\uff1a 1. \u200b\u7559\u4e0b\u200bStar \u2b50 \u200b\u5c55\u73b0\u200b\u4f60\u200b\u7684\u200b\u559c\u7231\u200b\u548c\u200b\u652f\u6301\u200b\uff0c\u200b\u975e\u5e38\u611f\u8c22\u200b! 2. \u200b\u53d1\u5e03\u200b issue, \u200b\u6216\u8005\u200b\u5728\u200bGitHub\u200b\u6839\u636e\u200b\u8d21\u732e\u200b\u6307\u5357\u200b \u200b\u63d0\u4ea4\u200b\u4e00\u4e2a\u200b PR\u3002 3. \u200b\u53d1\u9001\u200b\u4f60\u200b\u7684\u200b\u6b63\u5f0f\u200b\u5408\u4f5c\u200b\u63d0\u6848\u200b\u5230\u200b contact@hpcaitech.com</p> <p>\u200b\u771f\u8bda\u200b\u611f\u8c22\u200b\u6240\u6709\u200b\u8d21\u732e\u8005\u200b\uff01</p> <p> </p> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"README-zh-Hans/#cicd","title":"CI/CD","text":"<p>\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200bGitHub Actions\u200b\u6765\u200b\u81ea\u52a8\u5316\u200b\u5927\u90e8\u5206\u200b\u5f00\u53d1\u200b\u4ee5\u53ca\u200b\u90e8\u7f72\u200b\u6d41\u7a0b\u200b\u3002\u200b\u5982\u679c\u200b\u60f3\u200b\u4e86\u89e3\u200b\u8fd9\u4e9b\u200b\u5de5\u4f5c\u200b\u6d41\u662f\u200b\u5982\u4f55\u200b\u8fd0\u884c\u200b\u7684\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b\u8fd9\u4e2a\u200b\u6587\u6863\u200b.</p>"},{"location":"README-zh-Hans/#_12","title":"\u5f15\u7528\u200b\u6211\u4eec","text":"<p>Colossal-AI\u200b\u9879\u76ee\u200b\u53d7\u200b\u4e00\u4e9b\u200b\u76f8\u5173\u200b\u7684\u200b\u9879\u76ee\u200b\u542f\u53d1\u200b\u800c\u200b\u6210\u7acb\u200b\uff0c\u200b\u4e00\u4e9b\u200b\u9879\u76ee\u200b\u662f\u200b\u6211\u4eec\u200b\u7684\u200b\u5f00\u53d1\u8005\u200b\u7684\u200b\u79d1\u7814\u9879\u76ee\u200b\uff0c\u200b\u53e6\u200b\u4e00\u4e9b\u200b\u6765\u81ea\u200b\u4e8e\u200b\u5176\u4ed6\u200b\u7ec4\u7ec7\u200b\u7684\u200b\u79d1\u7814\u5de5\u4f5c\u200b\u3002\u200b\u6211\u4eec\u200b\u5e0c\u671b\u200b. \u200b\u6211\u4eec\u200b\u5e0c\u671b\u200b\u5728\u200b\u53c2\u8003\u6587\u732e\u200b\u5217\u8868\u200b\u4e2d\u200b\u5217\u51fa\u200b\u8fd9\u4e9b\u200b\u4ee4\u4eba\u200b\u79f0\u8d5e\u200b\u7684\u200b\u9879\u76ee\u200b\uff0c\u200b\u4ee5\u5411\u200b\u5f00\u6e90\u200b\u793e\u533a\u200b\u548c\u200b\u7814\u7a76\u200b\u9879\u76ee\u200b\u81f4\u8c22\u200b\u3002</p> <p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u683c\u5f0f\u200b\u5f15\u7528\u200b\u8fd9\u4e2a\u200b\u9879\u76ee\u200b\u3002</p> <pre><code>@article{bian2021colossal,\n  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},\n  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},\n  journal={arXiv preprint arXiv:2110.14883},\n  year={2021}\n}\n</code></pre> <p>Colossal-AI \u200b\u5df2\u200b\u88ab\u200bNeurIPS, SC, AAAI, PPoPP, CVPR, ISC, NVIDIA GTC ,\u200b\u7b49\u200b\u9876\u7ea7\u200b\u4f1a\u8bae\u200b\u5f55\u53d6\u200b\u4e3a\u200b\u5b98\u65b9\u200b\u6559\u7a0b\u200b\u3002</p> <p>(\u200b\u8fd4\u56de\u200b\u9876\u7aef\u200b)</p>"},{"location":"REFERENCE/","title":"References","text":"<p>The Colossal-AI project aims to provide a wide array of parallelism techniques for the machine learning community in the big-model era. This project is inspired by quite a few research works, some are conducted by some of our developers and the others are research projects open-sourced by other organizations. We would like to credit these amazing projects below in the IEEE citation format.</p>"},{"location":"REFERENCE/#by-our-team","title":"By Our Team","text":"<ul> <li> <p>Q. Xu, S. Li, C. Gong, and Y. You, \u2018An Efficient 2D Method for Training Super-Large Deep Learning Models\u2019. arXiv, 2021.</p> </li> <li> <p>Z. Bian, Q. Xu, B. Wang, and Y. You, \u2018Maximizing Parallelism in Distributed Training for Huge Neural Networks\u2019. arXiv, 2021.</p> </li> <li> <p>S. Li, F. Xue, C. Baranwal, Y. Li, and Y. You, \u2018Sequence Parallelism: Long Sequence Training from System Perspective\u2019. arXiv, 2021.</p> </li> <li> <p>S. Li et al., \u2018Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training\u2019. arXiv, 2021.</p> </li> <li> <p>B. Wang, Q. Xu, Z. Bian, and Y. You, \u2018Tesseract: Parallelize the Tensor Parallelism Efficiently\u2019, in Proceedings of the 51th International Conference on Parallel Processing, 2022.</p> </li> <li> <p>J. Fang et al., \u2018A Frequency-aware Software Cache for Large Recommendation System Embeddings\u2019. arXiv, 2022.</p> </li> <li> <p>J. Fang et al., \u2018Parallel Training of Pre-Trained Models via Chunk-Based Dynamic Memory Management\u2019, IEEE Transactions on Parallel and Distributed Systems, vol. 34, no. 1, pp. 304\u2013315, 2023.</p> </li> <li> <p>Y. Liu, S. Li, J. Fang, Y. Shao, B. Yao, and Y. You, \u2018Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models\u2019. arXiv, 2023.</p> </li> </ul>"},{"location":"REFERENCE/#by-other-organizations","title":"By Other Organizations","text":"<ul> <li> <p>M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro, \u2018Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\u2019. arXiv, 2019.</p> </li> <li> <p>S. Rajbhandari, J. Rasley, O. Ruwase, and Y. He, \u2018ZeRO: Memory Optimizations toward Training Trillion Parameter Models\u2019, in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, 2020.</p> </li> <li> <p>J. Rasley, S. Rajbhandari, O. Ruwase, and Y. He, \u2018DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters\u2019, in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, Virtual Event, CA, USA, 2020, pp. 3505\u20133506.</p> </li> <li> <p>D. Narayanan et al., \u2018Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM\u2019, in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, St. Louis, Missouri, 2021.</p> </li> <li> <p>Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, Yuxiong He. 2021. ZeRO-Offload: Democratizing Billion-Scale Model Training. arXiv:2101.06840 and USENIX ATC 2021.</p> </li> <li> <p>S. Rajbhandari, O. Ruwase, J. Rasley, S. Smith, and Y. He, \u2018ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning\u2019. in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, St. Louis, Missouri, 2021.</p> </li> <li> <p>L. Zheng et al., \u2018Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning\u2019, in 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22), 2022, pp. 559\u2013578.</p> </li> </ul>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/installation/","title":"\u5b89\u88c5","text":"<p>\u200b\u73af\u5883\u200b\u8981\u6c42\u200b:</p> <ul> <li>PyTorch &gt;= 1.11 (PyTorch 2.x \u200b\u6b63\u5728\u200b\u9002\u914d\u200b\u4e2d\u200b)</li> <li>Python &gt;= 3.7</li> <li>CUDA &gt;= 11.0</li> <li>NVIDIA GPU Compute Capability &gt;= 7.0 (V100/RTX20 and higher)</li> <li>Linux OS</li> </ul> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u9047\u5230\u200b\u5b89\u88c5\u200b\u95ee\u9898\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5411\u672c\u200b\u9879\u76ee\u200b \u200b\u53cd\u9988\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/installation/#pypi","title":"\u4ece\u200bPyPI\u200b\u4e0a\u200b\u5b89\u88c5","text":"<p>\u200b\u4f60\u200b\u53ef\u4ee5\u200bPyPI\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u76f4\u63a5\u200b\u5b89\u88c5\u200bColossal-AI\u3002</p> <pre><code>pip install colossalai\n</code></pre> <p>\u200b\u6ce8\u200b\uff1a\u200b\u73b0\u5728\u200b\u53ea\u200b\u652f\u6301\u200bLinux\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u540c\u65f6\u200b\u5b89\u88c5\u200bPyTorch\u200b\u6269\u5c55\u200b\u7684\u8bdd\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6dfb\u52a0\u200b<code>CUDA_EXT=1</code>\u3002\u200b\u5982\u679c\u200b\u4e0d\u200b\u6dfb\u52a0\u200b\u7684\u8bdd\u200b\uff0cPyTorch\u200b\u6269\u5c55\u200b\u4f1a\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u200b\u81ea\u52a8\u200b\u5b89\u88c5\u200b\u3002</p> <pre><code>CUDA_EXT=1 pip install colossalai\n</code></pre>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/installation/#_2","title":"\u4ece\u6e90\u200b\u5b89\u88c5","text":"<p>\u200b\u6b64\u200b\u6587\u6863\u200b\u5c06\u200b\u4e0e\u200b\u7248\u672c\u200b\u5e93\u200b\u7684\u200b\u4e3b\u200b\u5206\u652f\u200b\u4fdd\u6301\u4e00\u81f4\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\uff0c\u200b\u6b22\u8fce\u200b\u7ed9\u200b\u6211\u4eec\u200b\u63d0\u200b issue\u3002</p> <pre><code>git clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# install dependency\npip install -r requirements/requirements.txt\n\n# install colossalai\nCUDA_EXT=1 pip install .\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u60f3\u200b\u5b89\u88c5\u200b\u548c\u200b\u542f\u7528\u200b CUDA \u200b\u5185\u6838\u200b\u878d\u5408\u200b\uff08\u200b\u4f7f\u7528\u200b\u878d\u5408\u200b\u4f18\u5316\u200b\u5668\u65f6\u200b\u5f3a\u5236\u200b\u5b89\u88c5\u200b\uff09\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4e0d\u200b\u6dfb\u52a0\u200b<code>CUDA_EXT=1</code>\uff1a</p> <pre><code>pip install .\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200b\u4f7f\u7528\u200bCUDA 10.2\uff0c\u200b\u60a8\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u6e90\u7801\u200b\u5b89\u88c5\u200bColossalAI\u3002\u200b\u4f46\u662f\u200b\u60a8\u200b\u9700\u8981\u200b\u624b\u52a8\u200b\u4e0b\u8f7d\u200bcub\u200b\u5e93\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u590d\u5236\u5230\u200b\u76f8\u5e94\u200b\u7684\u200b\u76ee\u5f55\u200b\u3002</p> <pre><code># clone the repository\ngit clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# download the cub library\nwget https://github.com/NVIDIA/cub/archive/refs/tags/1.8.0.zip\nunzip 1.8.0.zip\ncp -r cub-1.8.0/cub/ colossalai/kernel/cuda_native/csrc/kernels/include/\n\n# install\nCUDA_EXT=1 pip install .\n</code></pre>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/reading_roadmap/","title":"\u9605\u8bfb\u200b\u6307\u5f15","text":"<p>Colossal-AI\u200b\u4e3a\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u7684\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u3002\u200b\u6211\u4eec\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u652f\u6301\u200b\u60a8\u200b\u5f00\u53d1\u200b\u5206\u5e03\u5f0f\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c31\u200b\u50cf\u200b\u60a8\u200b\u7f16\u5199\u200b\u5355\u200bGPU\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u4e00\u6837\u200b\u7b80\u5355\u200b\u3002ColossalAI\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u6613\u4e8e\u200b\u4f7f\u7528\u200b\u7684\u200bAPI\u200b\u6765\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u542f\u52a8\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u4e3a\u4e86\u200b\u66f4\u597d\u200b\u5730\u200b\u4e86\u89e3\u200bColossalAI\u200b\u7684\u200b\u5de5\u4f5c\u200b\u539f\u7406\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u60a8\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u987a\u5e8f\u200b\u9605\u8bfb\u200b\u672c\u200b\u6587\u6863\u200b\u3002</p> <ul> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u719f\u6089\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\uff0c\u200b\u6216\u8005\u200b\u6ca1\u6709\u200b\u4f7f\u7528\u200b\u8fc7\u200bColossal-AI\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5148\u200b\u6d4f\u89c8\u200b<code>\u200b\u6982\u5ff5\u200b</code>\u200b\u90e8\u5206\u200b\uff0c\u200b\u4e86\u89e3\u200b\u6211\u4eec\u200b\u8981\u200b\u5b9e\u73b0\u200b\u7684\u200b\u76ee\u6807\u200b\u540c\u65f6\u200b\u638c\u63e1\u200b\u4e00\u4e9b\u200b\u5173\u4e8e\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u7684\u200b\u80cc\u666f\u200b\u77e5\u8bc6\u200b\u3002</li> <li>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b<code>\u200b\u57fa\u7840\u6559\u7a0b\u200b</code>\u200b\u8fdb\u884c\u200b\u5b66\u4e60\u200b\u3002\u200b\u8be5\u8282\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5173\u4e8e\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200bColossal-AI\u200b\u7684\u200b\u7ec6\u8282\u200b\u3002</li> <li>\u200b\u8fd9\u65f6\u5019\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5c0f\u8bd5\u725b\u5200\u200b\u4e86\u200b\uff01<code>\u200b\u529f\u80fd\u200b</code> \u200b\u90e8\u5206\u200b\u5c06\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u5c1d\u8bd5\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200bColossal-AI\u200b\u4e3a\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u8fdb\u884c\u200b\u52a0\u901f\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b\u6559\u7a0b\u200b\u63d0\u4f9b\u200b\u4e00\u4e2a\u200b\u4ee3\u7801\u200b\u5e93\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u6559\u7a0b\u200b\u5c06\u200b\u6db5\u76d6\u200bColossal-AI\u200b\u7684\u200b\u57fa\u672c\u200b\u7528\u6cd5\u200b\uff0c\u200b\u4ee5\u200b\u5b9e\u73b0\u200b\u7b80\u5355\u200b\u7684\u200b\u529f\u80fd\u200b\uff0c\u200b\u5982\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u548c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u3002</li> <li>\u200b\u6700\u540e\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5e94\u7528\u200b\u66f4\u200b\u9ad8\u8d85\u200b\u7684\u200b\u6280\u672f\u200b\uff0c\u200b\u6bd4\u5982\u200b\uff0c\u200b\u5982\u4f55\u200b\u5728\u200bGPT-3\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\uff0c\u200b\u5feb\u200b\u6765\u200b<code>\u200b\u9ad8\u7ea7\u200b\u6559\u7a0b\u200b</code>\u200b\u90e8\u5206\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u642d\u5efa\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200b\u6a21\u578b\u200b\u5427\u200b\uff01</li> </ul> <p>\u200b\u6211\u4eec\u200b\u59cb\u7ec8\u200b\u6b22\u8fce\u200b\u793e\u533a\u200b\u7684\u200b\u5efa\u8bae\u200b\u548c\u200b\u8ba8\u8bba\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u975e\u5e38\u200b\u613f\u610f\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200bGitHub \u200b\u63d0\u200b issue \uff0c\u200b\u6216\u200b\u5728\u200b\u8bba\u575b\u200b\u4e0a\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u8ba8\u8bba\u200b\u4e3b\u9898\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/","title":"\u5feb\u901f\u200b\u6f14\u793a","text":"<p>Colossal-AI \u200b\u662f\u200b\u4e00\u4e2a\u200b\u96c6\u6210\u200b\u7684\u200b\u5927\u89c4\u6a21\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u7cfb\u7edf\u200b\uff0c\u200b\u5177\u6709\u200b\u9ad8\u6548\u200b\u7684\u200b\u5e76\u884c\u200b\u5316\u200b\u6280\u672f\u200b\u3002\u200b\u8be5\u200b\u7cfb\u7edf\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5e94\u7528\u200b\u5e76\u884c\u200b\u5316\u200b\u6280\u672f\u200b\u5728\u200b\u5177\u6709\u200b\u591a\u4e2a\u200b GPU \u200b\u7684\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u4e0a\u200b\u52a0\u901f\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u3002\u200b\u8be5\u200b\u7cfb\u7edf\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5728\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b GPU \u200b\u7684\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b Colossal-AI \u200b\u7684\u200b Quick demos\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#gpu","title":"\u5355\u200b GPU","text":"<p>Colossal-AI \u200b\u53ef\u4ee5\u200b\u7528\u200b\u5728\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b GPU \u200b\u7684\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u8fbe\u5230\u200b baseline \u200b\u7684\u200b\u6027\u80fd\u200b\u3002 \u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b \u200b\u5728\u200b CIFAR10 \u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200b ResNet \u200b\u7684\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u8be5\u200b\u4f8b\u5b50\u200b\u53ea\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b GPU\u3002 \u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b ColossalAI-Examples \u200b\u4e2d\u200b\u83b7\u53d6\u200b\u8be5\u200b\u4f8b\u5b50\u200b\u3002\u200b\u8be6\u7ec6\u200b\u8bf4\u660e\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5176\u200b <code>README.md</code> \u200b\u4e2d\u200b\u83b7\u53d6\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#gpu_1","title":"\u591a\u200b GPU","text":"<p>Colossal-AI \u200b\u53ef\u200b\u7528\u4e8e\u200b\u5728\u200b\u5177\u6709\u200b\u591a\u4e2a\u200b GPU \u200b\u7684\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u901a\u8fc7\u200b\u5e94\u7528\u200b\u9ad8\u6548\u200b\u7684\u200b\u5e76\u884c\u200b\u5316\u200b\u6280\u672f\u200b\u5927\u5e45\u200b\u52a0\u901f\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u591a\u79cd\u200b\u5e76\u884c\u200b\u5316\u200b\u6280\u672f\u200b\u4f9b\u200b\u60a8\u200b\u5c1d\u8bd5\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#1","title":"1. \u200b\u6570\u636e\u200b\u5e76\u884c","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4e0e\u200b\u4e0a\u8ff0\u200b\u5355\u200b GPU \u200b\u6f14\u793a\u200b\u76f8\u540c\u200b\u7684\u200b ResNet \u200b\u4f8b\u5b50\u200b\u3002 \u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b <code>--nproc_per_node</code> \u200b\u4e3a\u200b\u60a8\u200b\u673a\u5668\u200b\u4e0a\u200b\u7684\u200b GPU \u200b\u6570\u91cf\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u80fd\u200b\u628a\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u5e94\u7528\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u4f8b\u5b50\u200b\u4e0a\u200b\u4e86\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#2","title":"2. \u200b\u6df7\u5408\u200b\u5e76\u884c","text":"<p>\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u5305\u62ec\u200b\u6570\u636e\u200b\u3001\u200b\u5f20\u91cf\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u3002\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u652f\u6301\u200b\u4e0d\u540c\u200b\u7c7b\u578b\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff08\u200b\u5373\u200b 1D\u30012D\u30012.5D \u200b\u548c\u200b 3D\uff09\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u7b80\u5355\u200b\u5730\u200b\u6539\u53d8\u200b <code>config.py</code> \u200b\u4e2d\u200b\u7684\u200b\u914d\u7f6e\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4e4b\u95f4\u200b\u5207\u6362\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b GPT example, \u200b\u66f4\u200b\u591a\u200b\u7ec6\u8282\u200b\u80fd\u200b\u5728\u200b\u5b83\u200b\u7684\u200b <code>README.md</code> \u200b\u4e2d\u200b\u88ab\u200b\u627e\u5230\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#3-moe","title":"3. MoE \u200b\u5e76\u884c","text":"<p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b ViT-MoE \u200b\u4f8b\u5b50\u200b \u200b\u6765\u200b\u9a8c\u8bc1\u200b MoE \u200b\u7684\u200b\u5e76\u884c\u6027\u200b\u3002 WideNet \u200b\u4f7f\u7528\u200b Mixture of Experts\uff08MoE\uff09\u200b\u6765\u200b\u5b9e\u73b0\u200b\u66f4\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u7ec6\u8282\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6211\u4eec\u200b\u7684\u200b\u6559\u7a0b\u200b\u4e2d\u200b\u83b7\u53d6\u200b\uff1a\u200b\u6559\u4f1a\u200b\u60a8\u200b\u5982\u4f55\u200b\u628a\u200b Mixture of Experts \u200b\u6574\u5408\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\u3002</p>"},{"location":"1-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/run_demo/#4","title":"4. \u200b\u5e8f\u5217\u200b\u5e76\u884c","text":"<p>\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u662f\u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b NLP \u200b\u4efb\u52a1\u200b\u4e2d\u200b\u7684\u200b\u5185\u5b58\u200b\u6548\u7387\u200b\u548c\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u9650\u5236\u200b\u95ee\u9898\u200b\u3002 \u200b\u6211\u4eec\u200b\u5728\u200b ColossalAI-Examples \u200b\u4e2d\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b Sequence Parallelism \u200b\u4f8b\u5b50\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b <code>README.md</code> \u200b\u6765\u200b\u6267\u884c\u200b\u4ee3\u7801\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/colossalai_overview/","title":"Colossal-AI \u200b\u603b\u89c8","text":"<p>\u200b\u4f5c\u8005\u200b: Shenggui Li, Siqi Mai</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/colossalai_overview/#colossal-ai_1","title":"\u5173\u4e8e\u200b Colossal-AI","text":"<p>\u200b\u968f\u7740\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u7684\u200b\u53d1\u5c55\u200b\uff0c\u200b\u5411\u200b\u65b0\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b\u8f6c\u53d8\u200b\u662f\u200b\u975e\u5e38\u200b\u91cd\u8981\u200b\u7684\u200b\u3002\u200b\u6ca1\u6709\u200b\u5e76\u884c\u200b\u548c\u200b\u4f18\u5316\u200b\u7684\u200b\u4f20\u7edf\u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\u5c06\u200b\u6210\u4e3a\u200b\u8fc7\u53bb\u200b\uff0c\u200b\u65b0\u200b\u7684\u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\u662f\u200b\u4f7f\u200b\u8bad\u7ec3\u200b\u5927\u89c4\u6a21\u200b\u6a21\u578b\u200b\u9ad8\u6548\u200b\u548c\u200b\u8282\u7701\u6210\u672c\u200b\u7684\u200b\u5173\u952e\u200b\u3002</p> <p>Colossal-AI \u200b\u662f\u200b\u4e00\u4e2a\u200b\u96c6\u6210\u200b\u7684\u200b\u7cfb\u7edf\u200b\uff0c\u200b\u4e3a\u200b\u7528\u6237\u200b\u63d0\u4f9b\u200b\u4e00\u5957\u200b\u7efc\u5408\u200b\u7684\u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u627e\u5230\u200b\u5e38\u89c1\u200b\u7684\u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\uff0c\u200b\u5982\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u548c\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u7684\u200b\u5e76\u884c\u200b\u6280\u672f\u200b\uff0c\u200b\u5305\u62ec\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u3001\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b\u4e0d\u540c\u200b\u7684\u200b\u591a\u7ef4\u200b\u5206\u5e03\u5f0f\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u7b97\u6cd5\u200b\u6765\u200b\u4f18\u5316\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u8fd8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e0d\u540c\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f7f\u200b\u7528\u6237\u200b\u80fd\u591f\u200b\u6709\u6548\u200b\u5730\u200b\u8de8\u200b\u8282\u70b9\u200b\u6269\u5c55\u200b\u4ed6\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u9ad8\u7ea7\u200b\u529f\u80fd\u200b\uff0c\u200b\u5982\u200b\u5378\u8f7d\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u6559\u7a0b\u200b\u6587\u6863\u200b\u4e2d\u200b\u627e\u5230\u200b\u8be6\u7ec6\u200b\u7684\u200b\u5185\u5bb9\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/colossalai_overview/#colossal-ai_2","title":"Colossal-AI \u200b\u7684\u200b\u4f7f\u7528","text":"<p>\u200b\u6211\u4eec\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u4f7f\u200b Colossal-AI \u200b\u6613\u4e8e\u200b\u4f7f\u7528\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5bf9\u200b\u7528\u6237\u200b\u7684\u200b\u4ee3\u7801\u200b\u4e0d\u200b\u4ea7\u751f\u200b\u5e72\u6270\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4f7f\u7528\u200bColossal-AI\uff0c\u200b\u8fd9\u91cc\u200b\u6709\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u4e00\u822c\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u3002</p> Workflow <ol> <li>\u200b\u51c6\u5907\u200b\u4e00\u4e2a\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u6307\u5b9a\u200b\u60a8\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b\u529f\u80fd\u200b\u548c\u200b\u53c2\u6570\u200b\u3002</li> <li>\u200b\u7528\u200b <code>colossalai.launch</code> \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u540e\u200b\u7aef\u200b\u3002</li> <li>\u200b\u7528\u200b <code>colossalai.booster</code> \u200b\u5c06\u200b\u8bad\u7ec3\u200b\u7279\u5f81\u200b\u6ce8\u5165\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\uff08\u200b\u5982\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\uff09\u200b\u4e2d\u200b\u3002</li> <li>\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6d4b\u8bd5\u200b.</li> </ol> <p>\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b<code>\u200b\u57fa\u672c\u200b\u6559\u7a0b\u200b</code>\u200b\u90e8\u5206\u200b\u4ecb\u7ecd\u200b\u6574\u4e2a\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/colossalai_overview/#_1","title":"\u672a\u6765\u200b\u8ba1\u5212","text":"<p>Colossal-AI \u200b\u7cfb\u7edf\u200b\u5c06\u4f1a\u200b\u8fdb\u4e00\u6b65\u200b\u62d3\u5c55\u200b\u548c\u200b\u4f18\u5316\u200b\uff0c\u200b\u5305\u62ec\u200b\u4f46\u200b\u4e0d\u200b\u9650\u4e8e\u200b:</p> <ol> <li>\u200b\u5206\u5e03\u5f0f\u200b\u64cd\u4f5c\u200b\u7684\u200b\u4f18\u5316\u200b</li> <li>\u200b\u5f02\u6784\u200b\u7cfb\u7edf\u200b\u8bad\u7ec3\u200b\u7684\u200b\u4f18\u5316\u200b</li> <li>\u200b\u4ece\u200b\u6a21\u578b\u200b\u5927\u5c0f\u200b\u7684\u200b\u7ef4\u5ea6\u200b\u5207\u5165\u200b\uff0c\u200b\u63d0\u5347\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u5e76\u200b\u7ef4\u6301\u200b\u7cbe\u5ea6\u200b</li> <li>\u200b\u62d3\u5c55\u200b\u73b0\u6709\u200b\u7684\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b</li> </ol> <p>\u200b\u6211\u4eec\u200b\u59cb\u7ec8\u200b\u6b22\u8fce\u200b\u793e\u533a\u200b\u7684\u200b\u5efa\u8bae\u200b\u548c\u200b\u8ba8\u8bba\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u975e\u5e38\u200b\u613f\u610f\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200bGitHub \u200b\u63d0\u200b issue \uff0c\u200b\u6216\u200b\u5728\u200b\u8bba\u575b\u200b\u4e0a\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u8ba8\u8bba\u200b\u4e3b\u9898\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/distributed_training/","title":"\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3","text":"<p>\u200b\u4f5c\u8005\u200b: Shenggui Li, Siqi Mai</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/distributed_training/#_2","title":"\u4ec0\u4e48\u200b\u662f\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\uff1f","text":"\u56fe\u7247\u200b\u6765\u6e90\u200b: Towards Data Science <p>\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u7531\u200b\u591a\u4e2a\u200b\u8f6f\u4ef6\u200b\u7ec4\u4ef6\u200b\u7ec4\u6210\u200b\uff0c\u200b\u5728\u200b\u591a\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f20\u7edf\u200b\u7684\u200b\u6570\u636e\u5e93\u200b\u8fd0\u884c\u200b\u5728\u200b\u4e00\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u3002\u200b\u968f\u7740\u200b\u6570\u636e\u91cf\u200b\u7684\u200b\u7206\u53d1\u5f0f\u200b\u589e\u957f\u200b\uff0c\u200b\u5355\u53f0\u200b\u673a\u5668\u200b\u5df2\u7ecf\u200b\u4e0d\u80fd\u200b\u4e3a\u200b\u4f01\u4e1a\u200b\u63d0\u4f9b\u200b\u7406\u60f3\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u7279\u522b\u200b\u662f\u200b\u5728\u200b\u53cc\u5341\u200b\u4e00\u200b\u8fd9\u6837\u200b\u7684\u200b\u7f51\u7edc\u200b\u72c2\u6b22\u8282\u200b\uff0c\u200b\u7f51\u7edc\u6d41\u91cf\u200b\u4f1a\u200b\u51fa\u4e4e\u610f\u6599\u200b\u7684\u200b\u5927\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5e94\u5bf9\u200b\u8fd9\u79cd\u200b\u538b\u529b\u200b\uff0c\u200b\u73b0\u4ee3\u200b\u9ad8\u6027\u80fd\u200b\u6570\u636e\u5e93\u200b\u88ab\u200b\u8bbe\u8ba1\u200b\u6210\u5728\u200b\u591a\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u8fd0\u884c\u200b\uff0c\u200b\u5b83\u4eec\u200b\u5171\u540c\u200b\u4e3a\u200b\u7528\u6237\u200b\u63d0\u4f9b\u200b\u9ad8\u200b\u541e\u5410\u91cf\u200b\u548c\u200b\u4f4e\u200b\u5ef6\u8fdf\u200b\u3002</p> <p>\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u7684\u200b\u4e00\u4e2a\u200b\u91cd\u8981\u200b\u8bc4\u4ef7\u200b\u6307\u6807\u200b\u662f\u200b\u53ef\u6269\u5c55\u6027\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5f53\u200b\u6211\u4eec\u200b\u5728\u200b4\u200b\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u4e00\u4e2a\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u81ea\u7136\u200b\u5e0c\u671b\u200b\u8be5\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u7684\u200b\u8fd0\u884c\u200b\u901f\u5ea6\u200b\u80fd\u200b\u63d0\u9ad8\u200b4\u200b\u500d\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u7531\u4e8e\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\u548c\u200b\u786c\u4ef6\u200b\u6027\u80fd\u200b\u7684\u200b\u5dee\u5f02\u200b\uff0c\u200b\u5f88\u96be\u200b\u5b9e\u73b0\u200b\u7ebf\u6027\u200b\u63d0\u901f\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5f53\u200b\u6211\u4eec\u200b\u5b9e\u73b0\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u65f6\u200b\uff0c\u200b\u5fc5\u987b\u200b\u8003\u8651\u200b\u5982\u4f55\u200b\u4f7f\u200b\u5176\u200b\u66f4\u200b\u5feb\u200b\u3002\u200b\u826f\u597d\u200b\u7684\u200b\u8bbe\u8ba1\u200b\u548c\u200b\u7cfb\u7edf\u4f18\u5316\u200b\u7684\u200b\u7b97\u6cd5\u200b\u53ef\u4ee5\u200b\u5e2e\u52a9\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u826f\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u6709\u65f6\u200b\uff0c\u200b\u751a\u81f3\u200b\u6709\u200b\u53ef\u80fd\u200b\u5b9e\u73b0\u200b\u7ebf\u6027\u200b\u548c\u200b\u8d85\u200b\u7ebf\u6027\u200b\u63d0\u901f\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/distributed_training/#_3","title":"\u4e3a\u4ec0\u4e48\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff1f","text":"<p>\u200b\u65e9\u200b\u5728\u200b2012\u200b\u5e74\u200b\uff0cAlexNet \u200b\u5c31\u200b\u8d62\u5f97\u200b\u4e86\u200bImageNet\u200b\u6bd4\u8d5b\u200b\u7684\u200b\u51a0\u519b\u200b\uff0c\u200b\u800c\u200b\u5b83\u200b\u662f\u200b\u5728\u200b\u4e24\u5f20\u200b GTX 580 3GB GPU \u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u3002\u200b\u4eca\u5929\u200b\uff0c\u200b\u5927\u591a\u6570\u200b\u51fa\u73b0\u200b\u5728\u200b\u9876\u7ea7\u200b\u4eba\u5de5\u667a\u80fd\u200b\u4f1a\u8bae\u200b\u4e0a\u200b\u7684\u200b\u6a21\u578b\u200b\u90fd\u200b\u662f\u200b\u5728\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u3002\u200b\u5f53\u200b\u7814\u7a76\u200b\u4eba\u5458\u200b\u548c\u200b\u5de5\u7a0b\u5e08\u200b\u5f00\u53d1\u200b\u4eba\u5de5\u667a\u80fd\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u65e0\u7591\u200b\u662f\u200b\u4e00\u79cd\u200b\u5e38\u89c1\u200b\u7684\u200b\u505a\u6cd5\u200b\u3002\u200b\u8fd9\u4e00\u200b\u8d8b\u52bf\u200b\u80cc\u540e\u200b\u6709\u200b\u51e0\u4e2a\u200b\u539f\u56e0\u200b\u3002</p> <ol> <li>\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u8fc5\u901f\u200b\u589e\u52a0\u200b\u30022015\u200b\u5e74\u200b\u7684\u200b ResNet50 \u200b\u6709\u200b2000\u200b\u4e07\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c 2018\u200b\u5e74\u200b\u7684\u200b BERT-Large\u200b\u6709\u200b3.45\u200b\u4ebf\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c2018\u200b\u5e74\u200b\u7684\u200b GPT-2 \u200b\u6709\u200b15\u200b\u4ebf\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u800c\u200b2020\u200b\u5e74\u200b\u7684\u200b GPT-3 \u200b\u6709\u200b1750\u200b\u4ebf\u4e2a\u200b\u53c2\u6570\u200b\u3002\u200b\u5f88\u200b\u660e\u663e\u200b\uff0c\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u968f\u7740\u200b\u65f6\u95f4\u200b\u7684\u200b\u63a8\u79fb\u200b\u5448\u200b\u6307\u6570\u200b\u7ea7\u200b\u589e\u957f\u200b\u3002\u200b\u76ee\u524d\u200b\u6700\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u5df2\u7ecf\u200b\u8d85\u8fc7\u200b\u4e86\u200b1000\u200b\u591a\u4ebf\u200b\u4e2a\u200b\u53c2\u6570\u200b\u3002\u200b\u800c\u200b\u4e0e\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b\u6a21\u578b\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u8d85\u5927\u578b\u200b\u6a21\u578b\u200b\u901a\u5e38\u200b\u80fd\u200b\u63d0\u4f9b\u200b\u66f4\u4f18\u8d8a\u200b\u7684\u200b\u6027\u80fd\u200b\u3002</li> </ol> \u200b\u56fe\u7247\u200b\u6765\u6e90\u200b: HuggingFace <ol> <li> <p>\u200b\u6570\u636e\u200b\u96c6\u200b\u89c4\u6a21\u200b\u8fc5\u901f\u200b\u589e\u52a0\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u5927\u591a\u6570\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u5f00\u53d1\u8005\u200b\u6765\u8bf4\u200b\uff0cMNIST \u200b\u548c\u200b CIFAR10 \u200b\u6570\u636e\u200b\u96c6\u200b\u5f80\u5f80\u200b\u662f\u200b\u4ed6\u4eec\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u524d\u200b\u51e0\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4e0e\u200b\u8457\u540d\u200b\u7684\u200b ImageNet \u200b\u6570\u636e\u200b\u96c6\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u6570\u636e\u200b\u96c6\u200b\u975e\u5e38\u200b\u5c0f\u200b\u3002\u200b\u8c37\u6b4c\u200b\u751a\u81f3\u200b\u6709\u200b\u81ea\u5df1\u200b\u7684\u200b\uff08\u200b\u672a\u200b\u516c\u5e03\u200b\u7684\u200b\uff09JFT-300M \u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u5b83\u200b\u6709\u200b\u5927\u7ea6\u200b3\u200b\u4ebf\u5f20\u200b\u56fe\u7247\u200b\uff0c\u200b\u8fd9\u6bd4\u200b ImageNet-1k \u200b\u6570\u636e\u200b\u96c6\u5927\u200b\u4e86\u200b\u8fd1\u200b300\u200b\u500d\u200b\u3002</p> </li> <li> <p>\u200b\u8ba1\u7b97\u80fd\u529b\u200b\u8d8a\u6765\u8d8a\u200b\u5f3a\u200b\u3002\u200b\u968f\u7740\u200b\u534a\u5bfc\u4f53\u200b\u884c\u4e1a\u200b\u7684\u200b\u8fdb\u6b65\u200b\uff0c\u200b\u663e\u5361\u200b\u53d8\u5f97\u200b\u8d8a\u6765\u8d8a\u200b\u5f3a\u5927\u200b\u3002\u200b\u7531\u4e8e\u200b\u6838\u200b\u7684\u200b\u6570\u91cf\u200b\u589e\u591a\u200b\uff0cGPU\u200b\u662f\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u7b97\u529b\u200b\u8d44\u6e90\u200b\u3002\u200b\u4ece\u200b2012\u200b\u5e74\u200b\u7684\u200b K10 GPU \u200b\u5230\u200b2020\u200b\u5e74\u200b\u7684\u200b A100 GPU\uff0c\u200b\u8ba1\u7b97\u80fd\u529b\u200b\u5df2\u7ecf\u200b\u589e\u52a0\u200b\u4e86\u200b\u51e0\u767e\u500d\u200b\u3002\u200b\u8fd9\u4f7f\u200b\u6211\u4eec\u200b\u80fd\u591f\u200b\u66f4\u5feb\u200b\u5730\u200b\u6267\u884c\u200b\u8ba1\u7b97\u200b\u5bc6\u96c6\u578b\u200b\u4efb\u52a1\u200b\uff0c\u200b\u800c\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6b63\u662f\u200b\u8fd9\u6837\u200b\u4e00\u9879\u200b\u4efb\u52a1\u200b\u3002</p> </li> </ol> <p>\u200b\u5982\u4eca\u200b\uff0c\u200b\u6211\u4eec\u200b\u63a5\u89e6\u200b\u5230\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u592a\u200b\u5927\u200b\uff0c\u200b\u4ee5\u81f4\u4e8e\u200b\u65e0\u6cd5\u200b\u88c5\u5165\u200b\u4e00\u4e2a\u200bGPU\uff0c\u200b\u800c\u200b\u6570\u636e\u200b\u96c6\u200b\u4e5f\u200b\u53ef\u80fd\u200b\u5927\u5230\u200b\u8db3\u4ee5\u200b\u5728\u200b\u4e00\u4e2a\u200bGPU\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u4e00\u767e\u5929\u200b\u3002\u200b\u8fd9\u65f6\u200b\uff0c\u200b\u53ea\u6709\u200b\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u5e76\u884c\u200b\u5316\u200b\u6280\u672f\u200b\u5728\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u624d\u80fd\u200b\u5b8c\u6210\u200b\u5e76\u200b\u52a0\u5feb\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4ee5\u200b\u8ffd\u6c42\u200b\u5728\u200b\u5408\u7406\u200b\u7684\u200b\u65f6\u95f4\u200b\u5185\u200b\u83b7\u5f97\u200b\u60f3\u8981\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/distributed_training/#_4","title":"\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u7684\u200b\u57fa\u672c\u6982\u5ff5","text":"<p>\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u9700\u8981\u200b\u591a\u53f0\u200b\u673a\u5668\u200b/GPU\u3002\u200b\u5728\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8bbe\u5907\u200b\u4e4b\u95f4\u200b\u4f1a\u200b\u6709\u200b\u901a\u4fe1\u200b\u3002\u200b\u4e3a\u4e86\u200b\u66f4\u597d\u200b\u5730\u200b\u7406\u89e3\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6709\u200b\u51e0\u4e2a\u200b\u91cd\u8981\u200b\u7684\u200b\u672f\u8bed\u200b\u9700\u8981\u200b\u6211\u4eec\u200b\u4e86\u89e3\u200b\u6e05\u695a\u200b\u3002</p> <ul> <li>host: \u200b\u4e3b\u673a\u200b(host)\u200b\u662f\u200b\u901a\u4fe1\u200b\u7f51\u7edc\u200b\u4e2d\u200b\u7684\u200b\u4e3b\u8981\u200b\u8bbe\u5907\u200b\u3002\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u65f6\u200b\uff0c\u200b\u7ecf\u5e38\u200b\u9700\u8981\u200b\u5b83\u200b\u4f5c\u4e3a\u200b\u4e00\u4e2a\u200b\u53c2\u6570\u200b\u3002</li> <li>port: \u200b\u8fd9\u91cc\u200b\u7684\u200b\u7aef\u53e3\u200b(port)\u200b\u4e3b\u8981\u200b\u662f\u200b\u6307\u200b\u4e3b\u673a\u200b\u4e0a\u200b\u7528\u4e8e\u200b\u901a\u4fe1\u200b\u7684\u200b\u4e3b\u200b\u7aef\u53e3\u200b\u3002</li> <li>rank: \u200b\u5728\u200b\u7f51\u7edc\u200b\u4e2d\u200b\u8d4b\u4e88\u200b\u8bbe\u5907\u200b\u7684\u200b\u552f\u4e00\u200bID\u3002</li> <li>world size: \u200b\u7f51\u7edc\u200b\u4e2d\u200b\u8bbe\u5907\u200b\u7684\u200b\u6570\u91cf\u200b\u3002</li> <li>process group: \u200b\u8fdb\u7a0b\u200b\u7ec4\u200b(process group)\u200b\u662f\u200b\u4e00\u4e2a\u200b\u901a\u4fe1\u200b\u7f51\u7edc\u200b\uff0c\u200b\u5305\u62ec\u200b\u8bbe\u5907\u200b\u7684\u200b\u4e00\u4e2a\u200b\u5b50\u96c6\u200b\u3002\u200b\u603b\u662f\u200b\u6709\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\uff0c\u200b\u5b83\u200b\u5305\u542b\u200b\u6240\u6709\u200b\u7684\u200b\u8bbe\u5907\u200b\u3002\u200b\u4e00\u4e2a\u200b\u5b50\u96c6\u200b\u7684\u200b\u8bbe\u5907\u200b\u53ef\u4ee5\u200b\u5f62\u6210\u200b\u4e00\u4e2a\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u5b83\u4eec\u200b\u53ea\u200b\u5728\u200b\u7ec4\u5185\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\u3002</li> </ul> \u200b\u4e00\u4e2a\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u7684\u200b\u4f8b\u5b50\u200b <p>\u200b\u4e3a\u4e86\u200b\u8bf4\u660e\u200b\u8fd9\u4e9b\u200b\u6982\u5ff5\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5047\u8bbe\u200b\u6211\u4eec\u200b\u6709\u200b2\u200b\u53f0\u200b\u673a\u5668\u200b\uff08\u200b\u4e5f\u200b\u79f0\u4e3a\u200b\u8282\u70b9\u200b\uff09\uff0c\u200b\u6bcf\u53f0\u200b\u673a\u5668\u200b\u6709\u200b4\u200b\u4e2a\u200b GPU\u3002\u200b\u5f53\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u4e24\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u57fa\u672c\u4e0a\u200b\u542f\u52a8\u200b\u4e86\u200b8\u200b\u4e2a\u200b\u8fdb\u7a0b\u200b\uff08\u200b\u6bcf\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u6709\u200b4\u200b\u4e2a\u200b\u8fdb\u7a0b\u200b\uff09\uff0c\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u88ab\u200b\u7ed1\u5b9a\u200b\u5230\u200b\u4e00\u4e2a\u200b GPU \u200b\u4e0a\u200b\u3002</p> <p>\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u4e4b\u524d\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u6307\u5b9a\u200b\u4e3b\u673a\u200b\uff08\u200b\u4e3b\u200b\u5730\u5740\u200b\uff09\u200b\u548c\u200b\u7aef\u53e3\u200b\uff08\u200b\u4e3b\u200b\u7aef\u53e3\u200b\uff09\u3002\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u4e3b\u673a\u200b\u4e3a\u200b\u8282\u70b9\u200b0\uff0c\u200b\u7aef\u53e3\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u6570\u5b57\u200b\uff0c\u200b\u5982\u200b29500\u3002\u200b\u6240\u6709\u200b\u7684\u200b8\u200b\u4e2a\u200b\u8fdb\u7a0b\u200b\u5c06\u200b\u5bfb\u627e\u200b\u5730\u5740\u200b\u548c\u200b\u7aef\u53e3\u200b\u5e76\u200b\u76f8\u4e92\u8fde\u63a5\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u5c06\u200b\u88ab\u200b\u521b\u5efa\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\u7684\u200b world size \u200b\u4e3a\u200b8\uff0c\u200b\u7ec6\u8282\u200b\u5982\u4e0b\u200b\u3002</p> process ID rank Node index GPU index 0 0 0 0 1 1 0 1 2 2 0 2 3 3 0 3 4 4 1 0 5 5 1 1 6 6 1 2 7 7 1 3 <p>\u200b\u6211\u4eec\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u65b0\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\u53ef\u4ee5\u200b\u5305\u542b\u200b\u4efb\u4f55\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u5b50\u96c6\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u53ea\u200b\u5305\u542b\u200b\u5076\u6570\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u7ec4\u200b:</p> process ID rank Node index GPU index 0 0 0 0 2 1 0 2 4 2 1 0 6 3 1 2 <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0crank \u200b\u662f\u200b\u76f8\u5bf9\u200b\u4e8e\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\u800c\u8a00\u200b\u7684\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u8fdb\u7a0b\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u4e2d\u200b\u53ef\u4ee5\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b rank\u3002\u200b\u6700\u5927\u200b\u7684\u200b rank \u200b\u59cb\u7ec8\u200b\u662f\u200b <code>world size of the process group - 1</code>\u3002</p> <p>\u200b\u5728\u200b\u8fdb\u7a0b\u200b\u7ec4\u4e2d\u200b\uff0c\u200b\u5404\u200b\u8fdb\u7a0b\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4e24\u79cd\u200b\u65b9\u5f0f\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\u3002 1. peer-to-peer: \u200b\u4e00\u4e2a\u200b\u8fdb\u7a0b\u200b\u5411\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u8fdb\u7a0b\u200b\u53d1\u9001\u6570\u636e\u200b\u3002 2. collective: \u200b\u4e00\u7ec4\u200b\u8fdb\u7a0b\u200b\u4e00\u8d77\u200b\u6267\u884c\u200b\u5206\u6563\u200b\u3001\u200b\u805a\u96c6\u200b\u3001all-reduce\u3001\u200b\u5e7f\u64ad\u200b\u7b49\u200b\u64cd\u4f5c\u200b\u3002</p> Collective communication\uff0c \u200b\u6765\u6e90\u200b: PyTorch distributed tutorial"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/","title":"\u5e76\u884c\u200b\u6280\u672f","text":"<p>\u200b\u4f5c\u8005\u200b: Shenggui Li, Siqi Mai</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_2","title":"\u7b80\u4ecb","text":"<p>\u200b\u968f\u7740\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u7684\u200b\u53d1\u5c55\u200b\uff0c\u200b\u5bf9\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u9700\u6c42\u200b\u8d8a\u6765\u8d8a\u200b\u5927\u200b\u3002\u200b\u8fd9\u200b\u662f\u56e0\u4e3a\u200b\u6a21\u578b\u200b\u548c\u200b\u6570\u636e\u200b\u96c6\u200b\u8d8a\u6765\u8d8a\u200b\u5927\u200b\uff0c\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u575a\u6301\u200b\u4f7f\u7528\u200b\u5355\u200b GPU \u200b\u8bad\u7ec3\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u7684\u200b\u7b49\u5f85\u200b\u5c06\u4f1a\u200b\u6210\u4e3a\u200b\u4e00\u573a\u200b\u5669\u68a6\u200b\u3002\u200b\u5728\u200b\u672c\u8282\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5bf9\u200b\u73b0\u6709\u200b\u7684\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\u8fdb\u884c\u200b\u7b80\u8981\u200b\u4ecb\u7ecd\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5bf9\u200b\u8fd9\u200b\u7bc7\u6587\u7ae0\u200b\u8fdb\u884c\u200b\u8865\u5145\u200b\uff0c\u200b\u6b22\u8fce\u200b\u5728\u200bGitHub\u200b\u8bba\u575b\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8ba8\u8bba\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_3","title":"\u6570\u636e\u200b\u5e76\u884c","text":"<p>\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u662f\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u5e76\u884c\u200b\u5f62\u5f0f\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5f88\u200b\u7b80\u5355\u200b\u3002\u200b\u5728\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\uff0c\u200b\u6570\u636e\u200b\u96c6\u200b\u88ab\u200b\u5206\u5272\u200b\u6210\u200b\u51e0\u4e2a\u200b\u788e\u7247\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u788e\u7247\u200b\u88ab\u200b\u5206\u914d\u200b\u5230\u200b\u4e00\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u3002\u200b\u8fd9\u200b\u76f8\u5f53\u4e8e\u200b\u6cbf\u200b\u6279\u6b21\u200b\u7ef4\u5ea6\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u8fdb\u884c\u200b\u5e76\u884c\u200b\u5316\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u5c06\u200b\u6301\u6709\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b\u6a21\u578b\u200b\u526f\u672c\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u5206\u914d\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u788e\u7247\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5728\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u4e4b\u540e\u200b\uff0c\u200b\u6a21\u578b\u200b\u7684\u200b\u68af\u5ea6\u200b\u5c06\u200b\u88ab\u200b\u5168\u90e8\u200b\u51cf\u5c11\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u5728\u200b\u4e0d\u540c\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u7684\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u80fd\u591f\u200b\u4fdd\u6301\u200b\u540c\u6b65\u200b\u3002</p> \u200b\u6570\u636e\u200b\u5e76\u884c"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_4","title":"\u6a21\u578b\u200b\u5e76\u884c","text":"<p>\u200b\u5728\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u660e\u663e\u200b\u7684\u200b\u7279\u70b9\u200b\u662f\u200b\u6bcf\u4e2a\u200b GPU \u200b\u6301\u6709\u200b\u6574\u4e2a\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u7684\u200b\u526f\u672c\u200b\u3002\u200b\u8fd9\u200b\u5c31\u200b\u5e26\u6765\u200b\u4e86\u200b\u5197\u4f59\u200b\u95ee\u9898\u200b\u3002\u200b\u53e6\u200b\u4e00\u79cd\u200b\u5e76\u884c\u200b\u6a21\u5f0f\u200b\u662f\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\uff0c\u200b\u5373\u200b\u6a21\u578b\u200b\u88ab\u200b\u5206\u5272\u200b\u5e76\u200b\u5206\u5e03\u200b\u5728\u200b\u4e00\u4e2a\u200b\u8bbe\u5907\u200b\u9635\u5217\u200b\u4e0a\u200b\u3002\u200b\u901a\u5e38\u200b\u6709\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u5e76\u884c\u200b\uff1a\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u3002\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u662f\u200b\u5728\u200b\u4e00\u4e2a\u200b\u64cd\u4f5c\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u5e76\u884c\u8ba1\u7b97\u200b\uff0c\u200b\u5982\u200b\u77e9\u9635\u200b-\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u3002\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u662f\u200b\u5728\u200b\u5404\u5c42\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u5e76\u884c\u8ba1\u7b97\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u4ece\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u89d2\u5ea6\u200b\u6765\u770b\u200b\uff0c\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u770b\u4f5c\u200b\u662f\u200b\u5c42\u200b\u5185\u200b\u5e76\u884c\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u770b\u4f5c\u200b\u662f\u200b\u5c42\u95f4\u200b\u5e76\u884c\u200b\u3002</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_5","title":"\u5f20\u91cf\u200b\u5e76\u884c","text":"<p>\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u662f\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u5f20\u91cf\u200b\u6cbf\u200b\u7279\u5b9a\u200b\u7ef4\u5ea6\u200b\u5206\u6210\u200b <code>N</code> \u200b\u5757\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u53ea\u200b\u6301\u6709\u200b\u6574\u4e2a\u200b\u5f20\u91cf\u200b\u7684\u200b <code>1/N</code>\uff0c\u200b\u540c\u65f6\u200b\u4e0d\u200b\u5f71\u54cd\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u7684\u200b\u6b63\u786e\u6027\u200b\u3002\u200b\u8fd9\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u7684\u200b\u901a\u4fe1\u200b\u6765\u200b\u786e\u4fdd\u200b\u7ed3\u679c\u200b\u7684\u200b\u6b63\u786e\u6027\u200b\u3002</p> <p>\u200b\u4ee5\u200b\u4e00\u822c\u200b\u7684\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u4e3a\u4f8b\u200b\uff0c\u200b\u5047\u8bbe\u200b\u6211\u4eec\u200b\u6709\u200b <code>C = AB</code>\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5c06\u200bB\u200b\u6cbf\u7740\u200b\u5217\u200b\u5206\u5272\u200b\u6210\u200b <code>[B0 B1 B2 ... Bn]</code>\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u6301\u6709\u200b\u4e00\u5217\u200b\u3002\u200b\u7136\u540e\u200b\u6211\u4eec\u200b\u5c06\u200b <code>A</code> \u200b\u4e0e\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b <code>B</code> \u200b\u4e2d\u200b\u7684\u200b\u6bcf\u200b\u4e00\u5217\u200b\u76f8\u4e58\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5f97\u5230\u200b <code>[AB0 AB1 AB2 ... ABn]</code> \u3002\u200b\u6b64\u523b\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u4ecd\u7136\u200b\u6301\u6709\u200b\u4e00\u90e8\u5206\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8bbe\u5907\u200b(rank=0)\u200b\u6301\u6709\u200b <code>AB0</code>\u3002\u200b\u4e3a\u4e86\u200b\u786e\u4fdd\u200b\u7ed3\u679c\u200b\u7684\u200b\u6b63\u786e\u6027\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u6536\u96c6\u200b\u5168\u90e8\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u5e76\u200b\u6cbf\u5217\u7ef4\u200b\u4e32\u8054\u200b\u5f20\u91cf\u200b\u3002\u200b\u901a\u8fc7\u200b\u8fd9\u79cd\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u6211\u4eec\u200b\u80fd\u591f\u200b\u5c06\u200b\u5f20\u91cf\u200b\u5206\u5e03\u200b\u5728\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u540c\u65f6\u200b\u786e\u4fdd\u200b\u8ba1\u7b97\u200b\u6d41\u7a0b\u200b\u4fdd\u6301\u200b\u6b63\u786e\u200b\u3002</p> \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b <p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5373\u200b 1D\u30012D\u30012.5D \u200b\u548c\u200b 3D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b<code>\u200b\u9ad8\u7ea7\u200b\u6559\u7a0b\u200b</code>\u200b\u4e2d\u200b\u8be6\u7ec6\u200b\u8ba8\u8bba\u200b\u5b83\u4eec\u200b\u3002</p> <p>\u200b\u76f8\u5173\u200b\u6587\u7ae0\u200b: - GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding - Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism - An Efficient 2D Method for Training Super-Large Deep Learning Models - 2.5-dimensional distributed model training - Maximizing Parallelism in Distributed Training for Huge Neural Networks</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_6","title":"\u6d41\u6c34\u7ebf\u200b\u5e76\u884c","text":"<p>\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4e00\u822c\u6765\u8bf4\u200b\u5f88\u200b\u5bb9\u6613\u200b\u7406\u89e3\u200b\u3002\u200b\u8bf7\u200b\u60a8\u200b\u56de\u5fc6\u200b\u4e00\u4e0b\u200b\u60a8\u200b\u7684\u200b\u8ba1\u7b97\u673a\u200b\u7ed3\u6784\u200b\u8bfe\u7a0b\u200b\uff0c\u200b\u8fd9\u200b\u786e\u5b9e\u200b\u5b58\u5728\u200b\u4e8e\u200b CPU \u200b\u8bbe\u8ba1\u200b\u4e2d\u200b\u3002</p> \u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b <p>\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\uff0c\u200b\u6a21\u578b\u200b\u6309\u5c42\u200b\u5206\u5272\u200b\u6210\u200b\u82e5\u5e72\u5757\u200b\uff0c\u200b\u6bcf\u5757\u200b\u90fd\u200b\u4ea4\u7ed9\u200b\u4e00\u4e2a\u200b\u8bbe\u5907\u200b\u3002\u200b\u5728\u200b\u524d\u200b\u5411\u200b\u4f20\u9012\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u5c06\u200b\u4e2d\u95f4\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u4f20\u9012\u200b\u7ed9\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u9636\u6bb5\u200b\u3002\u200b\u5728\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u5c06\u200b\u8f93\u5165\u200b\u5f20\u91cf\u200b\u7684\u200b\u68af\u5ea6\u200b\u4f20\u56de\u200b\u7ed9\u200b\u524d\u200b\u4e00\u4e2a\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\u3002\u200b\u8fd9\u200b\u5141\u8bb8\u200b\u8bbe\u5907\u200b\u540c\u65f6\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u5e76\u200b\u589e\u52a0\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u7684\u200b\u541e\u5410\u91cf\u200b\u3002\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u4e00\u4e2a\u200b\u7f3a\u70b9\u200b\u662f\u200b\uff0c\u200b\u4f1a\u200b\u6709\u200b\u4e00\u4e9b\u200b\u8bbe\u5907\u200b\u53c2\u4e0e\u200b\u8ba1\u7b97\u200b\u7684\u200b\u5192\u6ce1\u200b\u65f6\u95f4\u200b\uff0c\u200b\u5bfc\u81f4\u200b\u8ba1\u7b97\u8d44\u6e90\u200b\u7684\u200b\u6d6a\u8d39\u200b\u3002</p> Source: GPipe <p>\u200b\u76f8\u5173\u200b\u6587\u7ae0\u200b: - PipeDream: Fast and Efficient Pipeline Parallel DNN Training - GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism - Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism - Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_7","title":"\u4f18\u5316\u200b\u5668\u200b\u76f8\u5173\u200b\u7684\u200b\u5e76\u884c","text":"<p>\u200b\u53e6\u200b\u4e00\u79cd\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\u76f8\u5173\u200b\uff0c\u200b\u76ee\u524d\u200b\u8fd9\u79cd\u200b\u5e76\u884c\u200b\u6700\u200b\u6d41\u884c\u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b <code>ZeRO</code>\uff0c\u200b\u5373\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b\u3002 ZeRO \u200b\u5728\u200b\u4e09\u4e2a\u200b\u5c42\u9762\u200b\u4e0a\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u4ee5\u200b\u6d88\u9664\u200b\u5185\u5b58\u200b\u5197\u4f59\u200b\uff08ZeRO\u200b\u9700\u8981\u200b\u8fdb\u884c\u200bfp16\u200b\u8bad\u7ec3\u200b\uff09\u3002</p> <ul> <li>Level 1: \u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5728\u200b\u5404\u200b\u8fdb\u7a0b\u200b\u4e2d\u200b\u88ab\u200b\u5212\u5206\u200b\u3002</li> <li>Level 2: \u200b\u7528\u4e8e\u200b\u66f4\u65b0\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u7684\u200b32\u200b\u4f4d\u200b\u68af\u5ea6\u200b\u4e5f\u200b\u88ab\u200b\u5212\u5206\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u53ea\u200b\u5b58\u50a8\u200b\u4e0e\u5176\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5212\u5206\u200b\u76f8\u5bf9\u200b\u5e94\u200b\u7684\u200b\u68af\u5ea6\u200b\u3002</li> <li>Level 3: 16\u200b\u4f4d\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u5728\u200b\u5404\u200b\u8fdb\u7a0b\u200b\u4e2d\u200b\u88ab\u200b\u5212\u5206\u200b\u3002</li> </ul> <p>\u200b\u76f8\u5173\u200b\u6587\u7ae0\u200b: - ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</p>"},{"location":"2-%E6%A6%82%E5%BF%B5/paradigms_of_parallelism/#_8","title":"\u5f02\u6784\u200b\u7cfb\u7edf\u200b\u7684\u200b\u5e76\u884c","text":"<p>\u200b\u4e0a\u8ff0\u200b\u65b9\u6cd5\u200b\u901a\u5e38\u200b\u9700\u8981\u200b\u5927\u91cf\u200b\u7684\u200b GPU \u200b\u6765\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4eba\u4eec\u200b\u5e38\u5e38\u200b\u5ffd\u7565\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u4e0e\u200b GPU \u200b\u76f8\u6bd4\u200b\uff0cCPU \u200b\u7684\u200b\u5185\u5b58\u200b\u8981\u200b\u5927\u5f97\u591a\u200b\u3002\u200b\u5728\u200b\u4e00\u4e2a\u200b\u5178\u578b\u200b\u7684\u200b\u670d\u52a1\u5668\u200b\u4e0a\u200b\uff0cCPU \u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u62e5\u6709\u200b\u51e0\u767e\u200bGB\u200b\u7684\u200b\u5185\u5b58\u200b\uff0c\u200b\u800c\u200b\u6bcf\u4e2a\u200b GPU \u200b\u901a\u5e38\u200b\u53ea\u6709\u200b16\u200b\u6216\u200b32GB\u200b\u7684\u200b\u5185\u5b58\u200b\u3002\u200b\u8fd9\u200b\u4fc3\u4f7f\u200b\u4eba\u4eec\u200b\u601d\u8003\u200b\u4e3a\u4ec0\u4e48\u200b CPU \u200b\u5185\u5b58\u200b\u6ca1\u6709\u200b\u88ab\u200b\u7528\u4e8e\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u6700\u8fd1\u200b\u7684\u200b\u8fdb\u5c55\u200b\u662f\u200b\u4f9d\u9760\u200b CPU \u200b\u751a\u81f3\u200b\u662f\u200b NVMe \u200b\u78c1\u76d8\u200b\u6765\u200b\u8bad\u7ec3\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u3002\u200b\u4e3b\u8981\u200b\u7684\u200b\u60f3\u6cd5\u200b\u662f\u200b\uff0c\u200b\u5728\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u5f20\u91cf\u200b\u65f6\u200b\uff0c\u200b\u5c06\u200b\u5176\u200b\u5378\u8f7d\u200b\u56de\u200b CPU \u200b\u5185\u5b58\u200b\u6216\u200b NVMe \u200b\u78c1\u76d8\u200b\u3002\u200b\u901a\u8fc7\u200b\u4f7f\u7528\u200b\u5f02\u6784\u200b\u7cfb\u7edf\u200b\u67b6\u6784\u200b\uff0c\u200b\u6709\u200b\u53ef\u80fd\u200b\u5728\u200b\u4e00\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u5bb9\u7eb3\u200b\u4e00\u4e2a\u200b\u5de8\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</p> \u200b\u5f02\u6784\u200b\u7cfb\u7edf\u200b <p>\u200b\u76f8\u5173\u200b\u6587\u7ae0\u200b: - ZeRO-Offload: Democratizing Billion-Scale Model Training - ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning - PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_api/","title":"Booster API","text":"<p>\u200b\u4f5c\u8005\u200b: Mingyan Jiang, Jianghai Chen, Baizhou Zhang</p> <p>\u200b\u9884\u5907\u200b\u77e5\u8bc6\u200b:</p> <ul> <li>\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b</li> <li>Colossal-AI \u200b\u603b\u89c8\u200b</li> </ul> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b</p> <ul> <li>\u200b\u4f7f\u7528\u200bBooster\u200b\u5728\u200bCIFAR-10\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200bResNet</li> <li>\u200b\u4f7f\u7528\u200bBooster\u200b\u5728\u200bRedPajama\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200bLlama-1/2</li> </ul>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_api/#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u5728\u200b\u6211\u4eec\u200b\u7684\u200b\u65b0\u200b\u8bbe\u8ba1\u200b\u4e2d\u200b\uff0c <code>colossalai.booster</code> \u200b\u4ee3\u66ff\u200b <code>colossalai.initialize</code> \u200b\u5c06\u200b\u7279\u5f81\u200b(\u200b\u4f8b\u5982\u200b\uff0c\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u3001\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b)\u200b\u65e0\u7f1d\u200b\u6ce8\u5165\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u4e2d\u200b\u3002 \u200b\u4f7f\u7528\u200b booster API, \u200b\u60a8\u200b\u53ef\u4ee5\u200b\u66f4\u200b\u53cb\u597d\u200b\u5730\u200b\u5c06\u200b\u6211\u4eec\u200b\u7684\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u6574\u5408\u200b\u5230\u200b\u5f85\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e2d\u200b. \u200b\u8c03\u7528\u200b <code>colossalai.booster</code> \u200b\u662f\u200b\u60a8\u200b\u8fdb\u5165\u200b\u8bad\u7ec3\u200b\u6d41\u7a0b\u200b\u524d\u200b\u7684\u200b\u6b63\u5e38\u200b\u64cd\u4f5c\u200b\u3002 \u200b\u5728\u200b\u4e0b\u9762\u200b\u7684\u200b\u7ae0\u8282\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b <code>colossalai.booster</code> \u200b\u662f\u200b\u5982\u4f55\u200b\u5de5\u4f5c\u200b\u7684\u200b\u4ee5\u53ca\u200b\u4f7f\u7528\u200b\u65f6\u200b\u6211\u4eec\u200b\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u7ec6\u8282\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_api/#booster","title":"Booster \u200b\u63d2\u4ef6","text":"<p>Booster \u200b\u63d2\u4ef6\u200b\u662f\u200b\u7ba1\u7406\u200b\u5e76\u884c\u200b\u914d\u7f6e\u200b\u7684\u200b\u91cd\u8981\u200b\u7ec4\u4ef6\u200b\uff08eg\uff1agemini \u200b\u63d2\u4ef6\u200b\u5c01\u88c5\u200b\u4e86\u200b gemini \u200b\u52a0\u901f\u200b\u65b9\u6848\u200b\uff09\u3002\u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u7684\u200b\u63d2\u4ef6\u200b\u5982\u4e0b\u200b\uff1a</p> <p>HybridParallelPlugin: HybirdParallelPlugin \u200b\u63d2\u4ef6\u200b\u5c01\u88c5\u200b\u4e86\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7684\u200b\u52a0\u901f\u200b\u89e3\u51b3\u65b9\u6848\u200b\u3002\u200b\u5b83\u200b\u63d0\u4f9b\u200b\u7684\u200b\u63a5\u53e3\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u4e24\u79cd\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\uff08DDP, Zero\uff09\u200b\u95f4\u200b\u8fdb\u884c\u200b\u4efb\u610f\u200b\u7684\u200b\u7ec4\u5408\u200b\u3002</p> <p>GeminiPlugin: GeminiPlugin \u200b\u63d2\u4ef6\u200b\u5c01\u88c5\u200b\u4e86\u200b gemini \u200b\u52a0\u901f\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff0c\u200b\u5373\u200b\u57fa\u4e8e\u200b\u5757\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b ZeRO \u200b\u4f18\u5316\u200b\u65b9\u6848\u200b\u3002</p> <p>TorchDDPPlugin: TorchDDPPlugin \u200b\u63d2\u4ef6\u200b\u5c01\u88c5\u200b\u4e86\u200bPytorch\u200b\u7684\u200bDDP\u200b\u52a0\u901f\u200b\u65b9\u6848\u200b\uff0c\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u6a21\u578b\u200b\u7ea7\u522b\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8de8\u591a\u673a\u200b\u8fd0\u884c\u200b\u3002</p> <p>LowLevelZeroPlugin: LowLevelZeroPlugin \u200b\u63d2\u4ef6\u200b\u5c01\u88c5\u200b\u4e86\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b\u7684\u200b 1/2 \u200b\u9636\u6bb5\u200b\u3002\u200b\u9636\u6bb5\u200b 1\uff1a\u200b\u5207\u5206\u200b\u4f18\u5316\u200b\u5668\u200b\u53c2\u6570\u200b\uff0c\u200b\u5206\u53d1\u200b\u5230\u200b\u5404\u200b\u5e76\u53d1\u200b\u8fdb\u7a0b\u200b\u6216\u200b\u5e76\u53d1\u200b GPU \u200b\u4e0a\u200b\u3002\u200b\u9636\u6bb5\u200b 2\uff1a\u200b\u5207\u5206\u200b\u4f18\u5316\u200b\u5668\u200b\u53c2\u6570\u200b\u53ca\u200b\u68af\u5ea6\u200b\uff0c\u200b\u5206\u53d1\u200b\u5230\u200b\u5404\u200b\u5e76\u53d1\u200b\u8fdb\u7a0b\u200b\u6216\u200b\u5e76\u53d1\u200b GPU \u200b\u4e0a\u200b\u3002</p> <p>TorchFSDPPlugin: TorchFSDPPlugin\u200b\u5c01\u88c5\u200b\u4e86\u200b Pytorch\u200b\u7684\u200bFSDP\u200b\u52a0\u901f\u200b\u65b9\u6848\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff08ZeroDP\uff09\u200b\u7684\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u82e5\u60f3\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u63d2\u4ef6\u200b\u7684\u200b\u7528\u6cd5\u200b\u7ec6\u8282\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200bBooster \u200b\u63d2\u4ef6\u200b\u7ae0\u8282\u200b\u3002</p> <p>\u200b\u6709\u200b\u4e00\u4e9b\u200b\u63d2\u4ef6\u200b\u652f\u6301\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\uff0c\u200b\u5b83\u200b\u80fd\u200b\u8282\u7701\u200b\u521d\u59cb\u5316\u200b\u5927\u200b\u6a21\u578b\u200b\u65f6\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u3002\u200b\u8be6\u60c5\u8bf7\u200b\u53c2\u8003\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_api/#booster_1","title":"Booster \u200b\u63a5\u53e3","text":"<p>{{ autodoc:colossalai.booster.Booster }}</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_api/#_2","title":"\u4f7f\u7528\u200b\u65b9\u6cd5\u200b\u53ca\u200b\u793a\u4f8b","text":"<p>\u200b\u5728\u200b\u4f7f\u7528\u200b colossalai \u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u5728\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u7684\u200b\u5f00\u5934\u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\uff0c\u200b\u5e76\u200b\u521b\u5efa\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u3001\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3001\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b\u7b49\u200b\u5bf9\u8c61\u200b\u3002\u200b\u4e4b\u540e\u200b\uff0c\u200b\u8c03\u7528\u200b<code>booster.boost</code> \u200b\u5c06\u200b\u7279\u5f81\u200b\u6ce8\u5165\u200b\u5230\u200b\u8fd9\u4e9b\u200b\u5bf9\u8c61\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u7684\u200b booster API \u200b\u53bb\u200b\u8fdb\u884c\u200b\u60a8\u200b\u63a5\u4e0b\u6765\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6d41\u7a0b\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u4f2a\u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\uff0c\u200b\u5c06\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u7684\u200b booster API \u200b\u8fdb\u884c\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b:</p> <pre><code>import torch\nfrom torch.optim import SGD\nfrom torchvision.models import resnet18\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import TorchDDPPlugin\n\ndef train():\n    # launch colossalai\n    colossalai.launch(config=dict(), rank=rank, world_size=world_size, port=port, host='localhost')\n\n    # create plugin and objects for training\n    plugin = TorchDDPPlugin()\n    booster = Booster(plugin=plugin)\n    model = resnet18()\n    criterion = lambda x: x.mean()\n    optimizer = SGD((model.parameters()), lr=0.001)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n\n    # use booster.boost to wrap the training objects\n    model, optimizer, criterion, _, scheduler = booster.boost(model, optimizer, criterion, lr_scheduler=scheduler)\n\n    # do training as normal, except that the backward should be called by booster\n    x = torch.randn(4, 3, 224, 224)\n    x = x.to('cuda')\n    output = model(x)\n    loss = criterion(output)\n    booster.backward(loss, optimizer)\n    optimizer.clip_grad_by_norm(1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n    # checkpointing using booster api\n    save_path = \"./model\"\n    booster.save_model(model, save_path, shard=True, size_per_shard=10, use_safetensors=True)\n\n    new_model = resnet18()\n    booster.load_model(new_model, save_path)\n</code></pre> <p>\u200b\u66f4\u200b\u591a\u200b\u7684\u200bBooster\u200b\u8bbe\u8ba1\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b\u8fd9\u200b\u4e00\u9875\u200b\u9762\u200b</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/","title":"Booster Checkpoint","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b: - Booster API</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u6211\u4eec\u200b\u5728\u200b\u4e4b\u524d\u200b\u7684\u200b\u6559\u7a0b\u200b\u4e2d\u200b\u4ecb\u7ecd\u200b\u4e86\u200b Booster API\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b booster \u200b\u4fdd\u5b58\u200b\u548c\u200b\u52a0\u8f7d\u200b checkpoint\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/#checkpoint","title":"\u6a21\u578b\u200b Checkpoint","text":"<p>{{ autodoc:colossalai.booster.Booster.save_model }}</p> <p>\u200b\u6a21\u578b\u200b\u5728\u200b\u4fdd\u5b58\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002 <code>checkpoint</code> \u200b\u662f\u200b\u8981\u200b\u4fdd\u5b58\u200b\u7684\u200b checkpoint \u200b\u7684\u200b\u8def\u5f84\u200b\u3002 \u200b\u5982\u679c\u200b <code>shard=False</code>\uff0c\u200b\u5b83\u200b\u5c31\u662f\u200b\u6587\u4ef6\u200b\u3002 \u200b\u5426\u5219\u200b, \u200b\u5b83\u200b\u5c31\u662f\u200b\u6587\u4ef6\u5939\u200b\u3002\u200b\u5982\u679c\u200b <code>shard=True</code>\uff0ccheckpoint \u200b\u5c06\u200b\u4ee5\u200b\u5206\u7247\u200b\u65b9\u5f0f\u200b\u4fdd\u5b58\u200b\uff0c\u200b\u5728\u200b checkpoint \u200b\u592a\u5927\u800c\u200b\u65e0\u6cd5\u200b\u4fdd\u5b58\u200b\u5728\u200b\u5355\u4e2a\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u65f6\u4f1a\u200b\u5f88\u200b\u5b9e\u7528\u200b\u3002\u200b\u6211\u4eec\u200b\u7684\u200b\u5206\u7247\u200b checkpoint \u200b\u683c\u5f0f\u200b\u4e0e\u200b huggingface/transformers \u200b\u517c\u5bb9\u200b\uff0c\u200b\u6240\u4ee5\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200bhuggingface\u200b\u7684\u200b<code>from_pretrained</code>\u200b\u65b9\u6cd5\u200b\u4ece\u200b\u5206\u7247\u200bcheckpoint\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u3002</p> <p>{{ autodoc:colossalai.booster.Booster.load_model }}</p> <p>\u200b\u6a21\u578b\u200b\u5728\u200b\u52a0\u8f7d\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002\u200b\u5b83\u4f1a\u200b\u81ea\u52a8\u68c0\u6d4b\u200b checkpoint \u200b\u683c\u5f0f\u200b\uff0c\u200b\u5e76\u200b\u4ee5\u200b\u76f8\u5e94\u200b\u7684\u200b\u65b9\u5f0f\u200b\u52a0\u8f7d\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4ece\u200bHuggingface\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f46\u200b\u6a21\u578b\u200b\u592a\u200b\u5927\u200b\u4ee5\u81f3\u4e8e\u200b\u65e0\u6cd5\u200b\u5728\u200b\u5355\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u901a\u8fc7\u200b\u201cfrom_pretrained\u201d\u200b\u76f4\u63a5\u200b\u52a0\u8f7d\u200b\uff0c\u200b\u63a8\u8350\u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b\u5c06\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u672c\u5730\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u5c01\u88c5\u200b\u6a21\u578b\u200b\u540e\u200b\u4f7f\u7528\u200b<code>booster.load</code>\u200b\u76f4\u63a5\u200b\u4ece\u200b\u672c\u5730\u200b\u8def\u5f84\u200b\u52a0\u8f7d\u200b\u3002\u200b\u4e3a\u4e86\u200b\u907f\u514d\u200b\u5185\u5b58\u4e0d\u8db3\u200b\uff0c\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u5728\u200b<code>Lazy Initialization</code>\u200b\u7684\u200b\u73af\u5883\u200b\u4e0b\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u793a\u4f8b\u200b\u4f2a\u200b\u4ee3\u7801\u200b\uff1a <pre><code>from colossalai.lazy import LazyInitContext\nfrom huggingface_hub import snapshot_download\n...\n\n# Initialize model under lazy init context\ninit_ctx = LazyInitContext(default_device=get_current_device)\nwith init_ctx:\n     model = LlamaForCausalLM(config)\n\n...\n\n# Wrap the model through Booster.boost\nmodel, optimizer, _, _, _ = booster.boost(model, optimizer)\n\n# download huggingface pretrained model to local directory.\nmodel_dir = snapshot_download(repo_id=\"lysandre/arxiv-nlp\")\n\n# load model using booster.load\nbooster.load(model, model_dir)\n...\n</code></pre></p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/#checkpoint_1","title":"\u4f18\u5316\u200b\u5668\u200b Checkpoint","text":"<p>{{ autodoc:colossalai.booster.Booster.save_optimizer }}</p> <p>\u200b\u4f18\u5316\u200b\u5668\u200b\u5728\u200b\u4fdd\u5b58\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002</p> <p>{{ autodoc:colossalai.booster.Booster.load_optimizer }}</p> <p>\u200b\u4f18\u5316\u200b\u5668\u200b\u5728\u200b\u52a0\u8f7d\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/#checkpoint_2","title":"\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b Checkpoint","text":"<p>{{ autodoc:colossalai.booster.Booster.save_lr_scheduler }}</p> <p>\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u5728\u200b\u4fdd\u5b58\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002 <code>checkpoint</code> \u200b\u662f\u200b checkpoint \u200b\u6587\u4ef6\u200b\u7684\u200b\u672c\u5730\u200b\u8def\u5f84\u200b.</p> <p>{{ autodoc:colossalai.booster.Booster.load_lr_scheduler }}</p> <p>\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u5728\u200b\u52a0\u8f7d\u200b\u524d\u200b\u5fc5\u987b\u200b\u88ab\u200b <code>colossalai.booster.Booster</code> \u200b\u5c01\u88c5\u200b\u3002 <code>checkpoint</code> \u200b\u662f\u200b checkpoint \u200b\u6587\u4ef6\u200b\u7684\u200b\u672c\u5730\u200b\u8def\u5f84\u200b.</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_checkpoint/#checkpoint_3","title":"Checkpoint \u200b\u8bbe\u8ba1","text":"<p>\u200b\u6709\u5173\u200b Checkpoint \u200b\u8bbe\u8ba1\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u6211\u4eec\u200b\u7684\u200b\u8ba8\u8bba\u200b A Unified Checkpoint System Design.</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/","title":"Booster \u200b\u63d2\u4ef6","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu, Baizhou Zhang, Pengtai Xu</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b: - Booster API</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u6b63\u5982\u200b Booster API \u200b\u4e2d\u200b\u63d0\u5230\u200b\u7684\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b booster \u200b\u63d2\u4ef6\u200b\u6765\u81ea\u200b\u5b9a\u4e49\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b booster \u200b\u63d2\u4ef6\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u73b0\u5728\u200b\u63d0\u4f9b\u200b\u4ee5\u4e0b\u200b\u63d2\u4ef6\u200b:</p> <ul> <li>Torch DDP \u200b\u63d2\u4ef6\u200b: \u200b\u5b83\u200b\u5305\u88c5\u200b\u4e86\u200b <code>torch.nn.parallel.DistributedDataParallel</code> \u200b\u5e76\u4e14\u200b\u53ef\u200b\u7528\u4e8e\u200b\u4f7f\u7528\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002</li> <li>Torch FSDP \u200b\u63d2\u4ef6\u200b: \u200b\u5b83\u200b\u5305\u88c5\u200b\u4e86\u200b <code>torch.distributed.fsdp.FullyShardedDataParallel</code> \u200b\u5e76\u4e14\u200b\u53ef\u200b\u7528\u4e8e\u200b\u4f7f\u7528\u200b Zero-dp \u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002</li> <li>Low Level Zero \u200b\u63d2\u4ef6\u200b: \u200b\u5b83\u200b\u5305\u88c5\u200b\u4e86\u200b <code>colossalai.zero.low_level.LowLevelZeroOptimizer</code>\uff0c\u200b\u53ef\u200b\u7528\u4e8e\u200b\u4f7f\u7528\u200b Zero-dp \u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002\u200b\u5b83\u200b\u4ec5\u200b\u652f\u6301\u200b Zero \u200b\u9636\u6bb5\u200b1\u200b\u548c\u200b\u9636\u6bb5\u200b2\u3002</li> <li>Gemini \u200b\u63d2\u4ef6\u200b: \u200b\u5b83\u200b\u5305\u88c5\u200b\u4e86\u200b Gemini\uff0cGemini \u200b\u5b9e\u73b0\u200b\u4e86\u200b\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u548c\u200b\u5f02\u6784\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b Zero-3\u3002</li> <li>Hybrid Parallel \u200b\u63d2\u4ef6\u200b: \u200b\u5b83\u200b\u4e3a\u200bShardformer\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u7ba1\u7406\u5668\u200b\uff0c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8fd0\u7b97\u200b\uff0cTorchDDP\u200b\u4ee5\u53ca\u200bZero-1/Zero-2\u200b\u529f\u80fd\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7edf\u4e00\u200b\u4e14\u200b\u7b80\u6d01\u200b\u7684\u200b\u63a5\u53e3\u200b\u3002\u200b\u4f7f\u7528\u200b\u8be5\u200b\u63d2\u4ef6\u200b\u53ef\u4ee5\u200b\u7b80\u5355\u200b\u9ad8\u6548\u200b\u5730\u200b\u5b9e\u73b0\u200btransformer\u200b\u6a21\u578b\u200b\u5728\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff08DDP, Zero\uff09\u200b\u95f4\u200b\u4efb\u610f\u200b\u7ec4\u5408\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7b56\u7565\u200b\uff0c\u200b\u540c\u65f6\u200b\u652f\u6301\u200b\u591a\u79cd\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u548c\u200b\u5185\u5b58\u200b\u7684\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u3002\u200b\u6709\u5173\u200b\u8fd9\u4e9b\u200b\u8bad\u7ec3\u200b\u7b56\u7565\u200b\u548c\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u7684\u200b\u5177\u4f53\u200b\u4fe1\u606f\u200b\u5c06\u200b\u5728\u200b\u4e0b\u200b\u4e00\u7ae0\u200b\u4e2d\u200b\u9610\u8ff0\u200b\u3002</li> </ul> <p>\u200b\u66f4\u200b\u591a\u200b\u63d2\u4ef6\u200b\u5373\u5c06\u200b\u63a8\u51fa\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#_2","title":"\u63d2\u4ef6\u200b\u9009\u62e9","text":"<ul> <li>Torch DDP \u200b\u63d2\u4ef6\u200b: \u200b\u9002\u7528\u200b\u4e8e\u200b\u53c2\u6570\u200b\u5c11\u4e8e\u200b 20 \u200b\u4ebf\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u4f8b\u5982\u200b Bert-3m\u3001GPT2-1.5b\uff09\u3002</li> <li>Torch FSDP \u200b\u63d2\u4ef6\u200b / Low Level Zero \u200b\u63d2\u4ef6\u200b: \u200b\u9002\u7528\u200b\u4e8e\u200b\u53c2\u6570\u200b\u5c11\u4e8e\u200b 100 \u200b\u4ebf\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u4f8b\u5982\u200b GPTJ-6b\u3001MegatronLM-8b\uff09\u3002</li> <li>Gemini \u200b\u63d2\u4ef6\u200b: \u200b\u9002\u5408\u200b\u53c2\u6570\u200b\u8d85\u8fc7\u200b 100 \u200b\u4ebf\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u4f8b\u5982\u200b TuringNLG-17b\uff09\uff0c\u200b\u4e14\u200b\u8de8\u200b\u8282\u70b9\u200b\u5e26\u5bbd\u200b\u9ad8\u200b\u3001\u200b\u4e2d\u200b\u5c0f\u89c4\u6a21\u200b\u96c6\u7fa4\u200b\uff08\u200b\u5343\u5361\u200b\u4ee5\u4e0b\u200b\uff09\u200b\u7684\u200b\u573a\u666f\u200b\uff08\u200b\u4f8b\u5982\u200b Llama2-70b\uff09\u3002</li> <li>Hybrid Parallel \u200b\u63d2\u4ef6\u200b: \u200b\u9002\u5408\u200b\u53c2\u6570\u200b\u8d85\u8fc7\u200b 600 \u200b\u4ebf\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u8d85\u957f\u200b\u5e8f\u5217\u200b\u3001\u200b\u8d85\u5927\u200b\u8bcd\u8868\u200b\u7b49\u200b\u7279\u6b8a\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e14\u200b\u8de8\u200b\u8282\u70b9\u200b\u5e26\u5bbd\u200b\u4f4e\u200b\u3001\u200b\u5927\u89c4\u6a21\u200b\u96c6\u7fa4\u200b\uff08\u200b\u5343\u5361\u200b\u4ee5\u4e0a\u200b\uff09\u200b\u7684\u200b\u573a\u666f\u200b\uff08\u200b\u4f8b\u5982\u200b GPT3-175b\u3001Bloom-176b\uff09\u3002</li> </ul>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#_3","title":"\u63d2\u4ef6","text":""},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#low-level-zero","title":"Low Level Zero \u200b\u63d2\u4ef6","text":"<p>\u200b\u8be5\u200b\u63d2\u4ef6\u200b\u5b9e\u73b0\u200b\u4e86\u200b Zero-1 \u200b\u548c\u200b Zero-2\uff08\u200b\u4f7f\u7528\u200b/\u200b\u4e0d\u200b\u4f7f\u7528\u200b CPU \u200b\u5378\u8f7d\u200b\uff09\uff0c\u200b\u4f7f\u7528\u200b<code>reduce</code>\u200b\u548c\u200b<code>gather</code>\u200b\u6765\u200b\u540c\u6b65\u200b\u68af\u5ea6\u200b\u548c\u200b\u6743\u91cd\u200b\u3002</p> <p>Zero-1 \u200b\u53ef\u4ee5\u200b\u770b\u4f5c\u200b\u662f\u200b Torch DDP \u200b\u66f4\u597d\u200b\u7684\u200b\u66ff\u4ee3\u54c1\u200b\uff0c\u200b\u5185\u5b58\u200b\u6548\u7387\u200b\u66f4\u9ad8\u200b\uff0c\u200b\u901f\u5ea6\u200b\u66f4\u200b\u5feb\u200b\u3002\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u5f88\u200b\u5bb9\u6613\u200b\u5730\u200b\u7528\u4e8e\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u3002</p> <p>Zero-2 \u200b\u4e0d\u200b\u652f\u6301\u200b\u5c40\u90e8\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u575a\u6301\u200b\u4f7f\u7528\u200b\uff0c\u200b\u867d\u7136\u200b\u53ef\u4ee5\u200b\u79ef\u7d2f\u200b\u68af\u5ea6\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u80fd\u200b\u964d\u4f4e\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u3002\u200b\u4e5f\u5c31\u662f\u8bf4\u200b\uff0c\u200b\u540c\u65f6\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u548c\u200b Zero-2 \u200b\u5e76\u200b\u4e0d\u662f\u200b\u4e00\u4e2a\u200b\u597d\u200b\u4e3b\u610f\u200b\u3002</p> <p>{{ autodoc:colossalai.booster.plugin.LowLevelZeroPlugin }}</p> <p>\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u6d4b\u8bd5\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u4e3b\u6d41\u200b\u6a21\u578b\u200b\u7684\u200b\u517c\u5bb9\u6027\u200b\uff0c\u200b\u53ef\u80fd\u200b\u4e0d\u200b\u652f\u6301\u200b\u4ee5\u4e0b\u200b\u6a21\u578b\u200b\uff1a</p> <ul> <li><code>timm.models.convit_base</code></li> <li>dlrm and deepfm models in <code>torchrec</code></li> </ul> <p>\u200b\u517c\u5bb9\u6027\u95ee\u9898\u200b\u5c06\u200b\u5728\u200b\u672a\u6765\u200b\u4fee\u590d\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#gemini","title":"Gemini \u200b\u63d2\u4ef6","text":"<p>\u200b\u8fd9\u4e2a\u200b\u63d2\u4ef6\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u548c\u200b\u5f02\u6784\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b Zero-3\u3002\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u8bad\u7ec3\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u800c\u200b\u4e0d\u4f1a\u200b\u635f\u5931\u200b\u592a\u200b\u591a\u200b\u901f\u5ea6\u200b\u3002\u200b\u5b83\u200b\u4e5f\u200b\u4e0d\u200b\u652f\u6301\u200b\u5c40\u90e8\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b Gemini \u200b\u6587\u6863\u200b.</p> <p>{{ autodoc:colossalai.booster.plugin.GeminiPlugin }}</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#hybrid-parallel","title":"Hybrid Parallel \u200b\u63d2\u4ef6","text":"<p>\u200b\u8fd9\u4e2a\u200b\u63d2\u4ef6\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u591a\u79cd\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7b56\u7565\u200b\u548c\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u7684\u200b\u7ec4\u5408\u200b\u3002Hybrid Parallel\u200b\u63d2\u4ef6\u200b\u652f\u6301\u200b\u7684\u200b\u529f\u80fd\u200b\u5927\u81f4\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u5206\u4e3a\u200b\u4ee5\u4e0b\u200b\u56db\u4e2a\u200b\u90e8\u5206\u200b\uff1a</p> <ol> <li>Shardformer: Shardformer\u200b\u8d1f\u8d23\u200b\u5728\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4e0b\u200b\u5207\u5206\u200b\u6a21\u578b\u200b\u7684\u200b\u903b\u8f91\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u524d\u5411\u200b/\u200b\u540e\u200b\u5411\u200b\u65b9\u6cd5\u200b\u7684\u200b\u91cd\u8f7d\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u63d2\u4ef6\u200b\u4e3a\u200bShardformer\u200b\u529f\u80fd\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u6613\u7528\u200b\u7684\u200b\u63a5\u53e3\u200b\u3002\u200b\u4e0e\u6b64\u540c\u65f6\u200b\uff0cShardformer\u200b\u8fd8\u200b\u8d1f\u8d23\u200b\u5c06\u200b\u5305\u62ec\u200bfused normalization, flash attention (xformers), JIT\u200b\u548c\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u5728\u5185\u200b\u7684\u200b\u5404\u7c7b\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u878d\u5165\u200b\u91cd\u8f7d\u200b\u540e\u200b\u7684\u200b\u524d\u200b\u5411\u200b/\u200b\u540e\u200b\u5411\u200b\u65b9\u6cd5\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200bShardformer\u200b\u7684\u200b\u4fe1\u606f\u200b\u8bf7\u200b\u53c2\u8003\u200b Shardformer\u200b\u6587\u6863\u200b\u3002\u200b\u4e0b\u56fe\u200b\u5c55\u793a\u200b\u4e86\u200bShardformer\u200b\u4e0e\u200bHybrid Parallel\u200b\u63d2\u4ef6\u200b\u6240\u200b\u652f\u6301\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</li> </ol> <ol> <li> <p>\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u63d2\u4ef6\u200b\u652f\u6301\u200bfp16/bf16\u200b\u7684\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u7684\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u6587\u6863\u200b\u3002</p> </li> <li> <p>Torch DDP: \u200b\u5f53\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u548c\u200bZero\u200b\u4e0d\u200b\u88ab\u200b\u4f7f\u7528\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u63d2\u4ef6\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u91c7\u7528\u200bPytorch DDP\u200b\u4f5c\u4e3a\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7684\u200b\u7b56\u7565\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200bTorch DDP\u200b\u7684\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u8bf7\u200b\u53c2\u8003\u200b Pytorch DDP \u200b\u6587\u6863\u200b\u3002</p> </li> <li> <p>Zero: \u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u63d2\u4ef6\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5c06\u200b<code>zero_stage</code>\u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u4e3a\u200b1\u200b\u6216\u200b2\u200b\u6765\u200b\u8ba9\u200b\u63d2\u4ef6\u200b\u91c7\u7528\u200bZero 1/2\u200b\u4f5c\u4e3a\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7684\u200b\u7b56\u7565\u200b\u3002Zero 1\u200b\u53ef\u4ee5\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u540c\u65f6\u200b\u4f7f\u7528\u200b, \u200b\u800c\u200bZero 2\u200b\u5219\u200b\u4e0d\u200b\u53ef\u4ee5\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u540c\u65f6\u200b\u4f7f\u7528\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200bZero\u200b\u7684\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u8bf7\u200b\u53c2\u8003\u200b Low Level Zero \u200b\u63d2\u4ef6\u200b.</p> </li> </ol> <p>\u26a0 \u200b\u5728\u200b\u4f7f\u7528\u200b\u8be5\u200b\u63d2\u4ef6\u200b\u7684\u200b\u65f6\u5019\u200b, \u200b\u53ea\u6709\u200b\u652f\u6301\u200bShardformer\u200b\u7684\u200b\u90e8\u5206\u200bHuggingface transformers\u200b\u6a21\u578b\u200b\u624d\u200b\u80fd\u591f\u200b\u4f7f\u7528\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u3001\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u3002Llama 1\u3001Llama 2\u3001OPT\u3001Bloom\u3001Bert\u200b\u4ee5\u53ca\u200bGPT2\u200b\u7b49\u200b\u4e3b\u6d41\u200btransformers\u200b\u6a21\u578b\u200b\u5747\u200b\u5df2\u200b\u652f\u6301\u200bShardformer\u3002</p> <p>{{ autodoc:colossalai.booster.plugin.HybridParallelPlugin }}</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#torch-ddp","title":"Torch DDP \u200b\u63d2\u4ef6","text":"<p>\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b Pytorch \u200b\u6587\u6863\u200b.</p> <p>{{ autodoc:colossalai.booster.plugin.TorchDDPPlugin }}</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/booster_plugins/#torch-fsdp","title":"Torch FSDP \u200b\u63d2\u4ef6","text":"<p>\u26a0 \u200b\u5982\u679c\u200b torch \u200b\u7248\u672c\u200b\u4f4e\u4e8e\u200b 1.12.0\uff0c\u200b\u6b64\u200b\u63d2\u4ef6\u200b\u5c06\u200b\u4e0d\u53ef\u200b\u7528\u200b\u3002</p> <p>\u26a0 \u200b\u8be5\u200b\u63d2\u4ef6\u200b\u73b0\u5728\u200b\u8fd8\u200b\u4e0d\u200b\u652f\u6301\u200b\u4fdd\u5b58\u200b/\u200b\u52a0\u8f7d\u200b\u5206\u7247\u200b\u7684\u200b\u6a21\u578b\u200b checkpoint\u3002</p> <p>\u26a0 \u200b\u8be5\u200b\u63d2\u4ef6\u200b\u73b0\u5728\u200b\u8fd8\u200b\u4e0d\u200b\u652f\u6301\u200b\u4f7f\u7528\u200b\u4e86\u200bmulti params group\u200b\u7684\u200boptimizer\u3002</p> <p>\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b Pytorch \u200b\u6587\u6863\u200b.</p> <p>{{ autodoc:colossalai.booster.plugin.TorchFSDPPlugin }}</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/command_line_tool/","title":"\u547d\u4ee4\u884c\u200b\u5de5\u5177","text":"<p>\u200b\u4f5c\u8005\u200b: Shenggui Li</p> <p>\u200b\u9884\u5907\u200b\u77e5\u8bc6\u200b: - Distributed Training - Colossal-AI Overview</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/command_line_tool/#_2","title":"\u7b80\u4ecb","text":"<p>Colossal-AI\u200b\u7ed9\u200b\u7528\u6237\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u547d\u4ee4\u884c\u200b\u5de5\u5177\u200b\uff0c\u200b\u76ee\u524d\u200b\u547d\u4ee4\u884c\u200b\u5de5\u5177\u200b\u53ef\u4ee5\u200b\u7528\u6765\u200b\u652f\u6301\u200b\u4ee5\u4e0b\u200b\u529f\u80fd\u200b\u3002 - \u200b\u68c0\u67e5\u200bColossal-AI\u200b\u662f\u5426\u200b\u5b89\u88c5\u200b\u6b63\u786e\u200b - \u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b - \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/command_line_tool/#_3","title":"\u5b89\u88c5\u200b\u68c0\u67e5","text":"<p>\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>colossalai check -i</code>\u200b\u8fd9\u4e2a\u200b\u547d\u4ee4\u200b\u6765\u200b\u68c0\u67e5\u200b\u76ee\u524d\u200b\u73af\u5883\u200b\u91cc\u200b\u7684\u200b\u7248\u672c\u200b\u517c\u5bb9\u6027\u200b\u4ee5\u53ca\u200bCUDA Extension\u200b\u7684\u200b\u72b6\u6001\u200b\u3002</p> Check Installation Demo"},{"location":"3-%E5%9F%BA%E7%A1%80/command_line_tool/#_4","title":"\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3","text":"<p>\u200b\u5728\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>colossalai run</code>\u200b\u6765\u200b\u542f\u52a8\u200b\u5355\u200b\u8282\u70b9\u200b\u6216\u8005\u200b\u591a\u200b\u8282\u70b9\u200b\u7684\u200b\u591a\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u8be6\u7ec6\u200b\u7684\u200b\u5185\u5bb9\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b\u542f\u52a8\u200b Colossal-AI\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/","title":"\u542f\u52a8\u200b Colossal-AI","text":"<p>\u200b\u4f5c\u8005\u200b: Chuanrui Wang, Shenggui Li, Siqi Mai</p> <p>\u200b\u9884\u5907\u200b\u77e5\u8bc6\u200b: - \u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b - Colossal-AI \u200b\u603b\u89c8\u200b</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u6b63\u5982\u200b\u6211\u4eec\u200b\u5728\u200b\u524d\u9762\u200b\u7684\u200b\u6559\u7a0b\u200b\u4e2d\u200b\u6240\u200b\u63d0\u5230\u200b\u7684\u200b\uff0c\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u51c6\u5907\u200b\u597d\u540e\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u4e3a\u200b Colossal-AI \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u3002\u200b\u6211\u4eec\u200b\u628a\u200b\u8fd9\u4e2a\u200b\u8fc7\u7a0b\u200b\u79f0\u4e3a\u200b <code>launch</code>\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u670d\u52a1\u5668\u200b\u4e0a\u200b\u542f\u52a8\u200b Colossal-AI\uff0c\u200b\u4e0d\u7ba1\u200b\u662f\u200b\u5c0f\u578b\u200b\u7684\u200b\u8fd8\u662f\u200b\u5927\u578b\u200b\u7684\u200b\u3002</p> <p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u51e0\u79cd\u200b\u542f\u52a8\u200b\u65b9\u6cd5\u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u540e\u200b\u7aef\u200b\u3002 \u200b\u5728\u200b\u5927\u591a\u6570\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>colossalai.launch</code> \u200b\u548c\u200b <code>colossalai.get_default_parser</code> \u200b\u6765\u200b\u901a\u8fc7\u200b\u547d\u4ee4\u884c\u200b\u4f20\u9012\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4f7f\u7528\u200b SLURM\u3001OpenMPI \u200b\u548c\u200b PyTorch \u200b\u7b49\u200b\u542f\u52a8\u200b\u5de5\u5177\u200b\uff0c\u200b\u6211\u4eec\u200b\u4e5f\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u51e0\u4e2a\u200b\u542f\u52a8\u200b\u7684\u200b\u8f85\u52a9\u200b\u65b9\u6cd5\u200b\u4ee5\u4fbf\u200b\u60a8\u200b\u7684\u200b\u4f7f\u7528\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4ece\u200b\u8fd9\u4e9b\u200b\u542f\u52a8\u200b\u5de5\u5177\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u73af\u5883\u53d8\u91cf\u200b\u4e2d\u200b\u8bbf\u95ee\u200b rank \u200b\u548c\u200b world size \u200b\u5927\u5c0f\u200b\u3002</p> <p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u542f\u52a8\u200b Colossal-AI \u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u540e\u200b\u7aef\u200b\uff1a - \u200b\u7528\u200b colossalai.launch \u200b\u542f\u52a8\u200b - \u200b\u7528\u200b Colossal-AI\u200b\u547d\u4ee4\u884c\u200b \u200b\u542f\u52a8\u200b - \u200b\u7528\u200b SLURM \u200b\u542f\u52a8\u200b - \u200b\u7528\u200b OpenMPI \u200b\u542f\u52a8\u200b</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#_2","title":"\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883","text":"<p>\u200b\u4e3a\u4e86\u200b\u542f\u52a8\u200b Colossal-AI\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u4e24\u7c7b\u200b\u53c2\u6570\u200b: 1. \u200b\u914d\u7f6e\u6587\u4ef6\u200b 2. \u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b</p> <p>\u200b\u65e0\u8bba\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u4f55\u79cd\u200b\u542f\u52a8\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u662f\u200b\u5fc5\u987b\u200b\u8981\u6c42\u200b\u7684\u200b\uff0c\u200b\u800c\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\u6709\u200b\u53ef\u80fd\u200b\u4f9d\u200b\u60c5\u51b5\u200b\u800c\u5b9a\u200b\u3002\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u53ef\u4ee5\u200b\u662f\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u6216\u200b Python dictionary \u200b\u7684\u200b\u5f62\u5f0f\u200b\u3002\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u547d\u4ee4\u884c\u200b\u6216\u200b\u591a\u200b\u8fdb\u7a0b\u200b\u542f\u52a8\u5668\u200b\u4f20\u9012\u200b\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#_3","title":"\u547d\u4ee4\u884c\u200b\u89e3\u6790\u5668","text":"<p>\u200b\u5728\u200b\u4f7f\u7528\u200b <code>launch</code> \u200b\u4e4b\u524d\u200b, \u200b\u6211\u4eec\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u4e86\u89e3\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u54ea\u4e9b\u200b\u53c2\u6570\u200b\u6765\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b\u3002 \u200b\u5982\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b \u200b\u4e2d\u200b <code>\u200b\u57fa\u672c\u6982\u5ff5\u200b</code> \u200b\u4e00\u8282\u200b\u6240\u8ff0\u200b \uff0c\u200b\u6d89\u53ca\u200b\u7684\u200b\u91cd\u8981\u200b\u53c2\u6570\u200b\u662f\u200b:</p> <ol> <li>host</li> <li>port</li> <li>rank</li> <li>world_size</li> <li>backend</li> </ol> <p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u547d\u4ee4\u884c\u200b\u89e3\u6790\u5668\u200b\uff0c\u200b\u5b83\u200b\u5df2\u7ecf\u200b\u63d0\u524d\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b <code>colossalai.get_default_parser()</code> \u200b\u6765\u200b\u83b7\u5f97\u200b\u8fd9\u4e2a\u200b\u89e3\u6790\u5668\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u89e3\u6790\u5668\u200b\u901a\u5e38\u200b\u4e0e\u200b <code>colossalai.launch</code> \u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002</p> <pre><code># add these lines in your train.py\nimport colossalai\n\n# get default parser\nparser = colossalai.get_default_parser()\n\n# if you want to add your own arguments\nparser.add_argument(...)\n\n# parse arguments\nargs = parser.parse_args()\n</code></pre> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u7ec8\u7aef\u200b\u4f20\u5165\u200b\u4ee5\u4e0b\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u3002 <pre><code>python train.py --host &lt;host&gt; --rank &lt;rank&gt; --world_size &lt;world_size&gt; --port &lt;port&gt; --backend &lt;backend&gt;\n</code></pre></p> <p><code>backend</code> \u200b\u662f\u200b\u7528\u6237\u200b\u53ef\u9009\u200b\u7684\u200b\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u662f\u200b nccl\u3002</p>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#_4","title":"\u672c\u5730\u200b\u542f\u52a8","text":"<p>\u200b\u4e3a\u4e86\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u901a\u7528\u200b\u7684\u200b <code>colossalai.launch</code> API\u3002<code>colossalai.launch</code> \u200b\u51fd\u6570\u200b\u63a5\u6536\u200b\u4e0a\u9762\u200b\u5217\u51fa\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u901a\u4fe1\u200b\u7f51\u7edc\u200b\u4e2d\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u7ec4\u200b\u3002\u200b\u65b9\u4fbf\u200b\u8d77\u200b\u89c1\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u51fd\u6570\u200b\u901a\u5e38\u200b\u4e0e\u200b\u9ed8\u8ba4\u200b\u89e3\u6790\u5668\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002</p> <pre><code>import colossalai\n\n# parse arguments\nargs = colossalai.get_default_parser().parse_args()\n\n# launch distributed environment\ncolossalai.launch(config=args.config,\n                  rank=args.rank,\n                  world_size=args.world_size,\n                  host=args.host,\n                  port=args.port,\n                  backend=args.backend\n)\n</code></pre>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#colossal-ai_1","title":"\u7528\u200b Colossal-AI\u200b\u547d\u4ee4\u884c\u200b\u5de5\u5177\u200b \u200b\u542f\u52a8","text":"<p>\u200b\u4e3a\u4e86\u200b\u66f4\u597d\u200b\u5730\u200b\u652f\u6301\u200b\u5355\u200b\u8282\u70b9\u200b\u4ee5\u53ca\u200b\u591a\u200b\u8282\u70b9\u200b\u7684\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b\u5c01\u88c5\u200bPyTorch\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u66f4\u52a0\u200b\u65b9\u4fbf\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u3002 PyTorch\u200b\u81ea\u5e26\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u9700\u8981\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u90fd\u200b\u542f\u52a8\u200b\u547d\u4ee4\u200b\u624d\u80fd\u200b\u542f\u52a8\u200b\u591a\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u800c\u200b\u6211\u4eec\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u53ea\u200b\u9700\u8981\u200b\u4e00\u6b21\u200b\u8c03\u7528\u200b\u5373\u53ef\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u5728\u200b\u4ee3\u7801\u200b\u91cc\u200b\u6307\u5b9a\u200b\u6211\u4eec\u200b\u7684\u200b\u542f\u52a8\u200b\u65b9\u5f0f\u200b\u3002\u200b\u7531\u4e8e\u200b\u8fd9\u4e2a\u200b\u542f\u52a8\u5668\u200b\u662f\u200bPyTorch\u200b\u542f\u52a8\u5668\u200b\u7684\u200b\u5c01\u88c5\u200b\uff0c\u200b\u90a3\u4e48\u200b\u6211\u4eec\u200b\u81ea\u7136\u800c\u7136\u200b\u5e94\u8be5\u200b\u4f7f\u7528\u200b<code>colossalai.launch_from_torch</code>\u3002 \u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u5982\u200b rank, world size, host \u200b\u548c\u200b port \u200b\u90fd\u200b\u662f\u200b\u7531\u200b PyTorch \u200b\u542f\u52a8\u5668\u200b\u8bbe\u7f6e\u200b\u7684\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b\u4e2d\u200b\u8bfb\u53d6\u200b\u3002</p> <p>config.py <pre><code>BATCH_SIZE = 512\nLEARNING_RATE = 3e-3\nWEIGHT_DECAY = 0.3\nNUM_EPOCHS = 2\n</code></pre> train.py <pre><code>import colossalai\n\ncolossalai.launch_from_torch(\n    config=\"./config.py\",\n)\n...\n</code></pre></p> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u5728\u200b\u7ec8\u7aef\u200b\u4f7f\u7528\u200b<code>colossalai run</code>\u200b\u6765\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u3002\u200b\u4e0b\u9762\u200b\u7684\u200b\u547d\u4ee4\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5f53\u524d\u200b\u673a\u5668\u200b\u4e0a\u200b\u542f\u52a8\u200b\u4e00\u4e2a\u200b4\u200b\u5361\u200b\u7684\u200b\u8bad\u7ec3\u4efb\u52a1\u200b\u3002 \u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b<code>nproc_per_node</code>\u200b\u6765\u200b\u8c03\u6574\u200b\u4f7f\u7528\u200b\u7684\u200bGPU\u200b\u7684\u200b\u6570\u91cf\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u6539\u53d8\u200b<code>master_port</code>\u200b\u7684\u200b\u53c2\u6570\u200b\u6765\u200b\u9009\u62e9\u200b\u901a\u4fe1\u200b\u7684\u200b\u7aef\u53e3\u200b\u3002</p> <pre><code># \u200b\u5728\u200b\u5f53\u524d\u200b\u8282\u70b9\u200b\u4e0a\u200b\u542f\u52a8\u200b4\u200b\u5361\u200b\u8bad\u7ec3\u200b \uff08\u200b\u9ed8\u8ba4\u200b\u4f7f\u7528\u200b29500\u200b\u7aef\u53e3\u200b\uff09\ncolossalai run --nproc_per_node 4 train.py\n\n# \u200b\u5728\u200b\u5f53\u524d\u200b\u8282\u70b9\u200b\u4e0a\u200b\u542f\u52a8\u200b4\u200b\u5361\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u4e0d\u540c\u200b\u7684\u200b\u7aef\u53e3\u200b\ncolossalai run --nproc_per_node 4 --master_port 29505 test.py\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5728\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u96c6\u7fa4\u200b\uff0c\u200b\u5e76\u4e14\u200b\u60f3\u200b\u8fdb\u884c\u200b\u591a\u200b\u8282\u70b9\u200b\u7684\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u4f7f\u7528\u200bColossal-AI\u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u5de5\u5177\u200b\u8fdb\u884c\u200b\u4e00\u952e\u200b\u542f\u52a8\u200b\u3002\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e24\u79cd\u200b\u65b9\u5f0f\u200b\u6765\u200b\u542f\u52a8\u200b\u591a\u200b\u8282\u70b9\u200b\u4efb\u52a1\u200b</p> <ul> <li>\u200b\u901a\u8fc7\u200b<code>--hosts</code>\u200b\u6765\u200b\u542f\u52a8\u200b</li> </ul> <p>\u200b\u8fd9\u4e2a\u200b\u65b9\u5f0f\u200b\u9002\u5408\u200b\u8282\u70b9\u200b\u6570\u4e0d\u591a\u200b\u7684\u200b\u60c5\u51b5\u200b\u3002\u200b\u5047\u8bbe\u200b\u6211\u4eec\u200b\u6709\u200b\u4e24\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u5206\u522b\u200b\u4e3a\u200b<code>host</code>\u200b\u548c\u200b<code>host2</code>\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u8fdb\u884c\u200b\u591a\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\u3002 \u200b\u6bd4\u8d77\u200b\u5355\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u591a\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\u9700\u8981\u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b<code>--master_addr</code> \uff08\u200b\u5728\u200b\u5355\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\u4e2d\u200b<code>master_addr</code>\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b<code>127.0.0.1</code>\uff09\u3002</p> <p>:::caution</p> <p>\u200b\u591a\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c<code>master_addr</code>\u200b\u4e0d\u80fd\u200b\u4e3a\u200b<code>localhost</code>\u200b\u6216\u8005\u200b<code>127.0.0.1</code>\uff0c\u200b\u5b83\u200b\u5e94\u8be5\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u540d\u5b57\u200b\u6216\u8005\u200bIP\u200b\u5730\u5740\u200b\u3002</p> <p>:::</p> <pre><code># \u200b\u5728\u200b\u4e24\u4e2a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\ncolossalai run --nproc_per_node 4 --host host1,host2 --master_addr host1 test.py\n</code></pre> <ul> <li>\u200b\u901a\u8fc7\u200b<code>--hostfile</code>\u200b\u6765\u200b\u542f\u52a8\u200b</li> </ul> <p>\u200b\u8fd9\u4e2a\u200b\u65b9\u5f0f\u200b\u9002\u7528\u200b\u4e8e\u200b\u8282\u70b9\u200b\u6570\u200b\u5f88\u5927\u200b\u7684\u200b\u60c5\u51b5\u200b\u3002host file\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u6587\u672c\u6587\u4ef6\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u6587\u4ef6\u200b\u91cc\u200b\u5217\u51fa\u200b\u4e86\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u7684\u200b\u8282\u70b9\u200b\u7684\u200b\u540d\u5b57\u200b\u3002 \u200b\u5728\u200b\u4e00\u4e2a\u200b\u96c6\u7fa4\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u7528\u200b\u8282\u70b9\u200b\u7684\u200b\u5217\u8868\u200b\u4e00\u822c\u200b\u7531\u200bSLURM\u200b\u6216\u8005\u200bPBS Pro\u200b\u8fd9\u6837\u200b\u7684\u200b\u96c6\u7fa4\u200b\u8d44\u6e90\u7ba1\u7406\u200b\u5668\u6765\u200b\u63d0\u4f9b\u200b\u3002\u200b\u6bd4\u5982\u200b\uff0c\u200b\u5728\u200bSLURM\u200b\u4e2d\u200b\uff0c \u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4ece\u200b<code>SLURM_NODELIST</code>\u200b\u8fd9\u4e2a\u200b\u73af\u5883\u53d8\u91cf\u200b\u4e2d\u200b\u83b7\u53d6\u200b\u5230\u200b\u5f53\u524d\u200b\u5206\u914d\u200b\u5217\u8868\u200b\u3002\u200b\u5728\u200bPBS Pro\u200b\u4e2d\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u73af\u5883\u53d8\u91cf\u200b\u4e3a\u200b<code>PBS_NODEFILE</code>\u3002 \u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b<code>echo $SLURM_NODELIST</code> \u200b\u6216\u8005\u200b <code>cat $PBS_NODEFILE</code> \u200b\u6765\u200b\u5c1d\u8bd5\u200b\u4e00\u4e0b\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u6ca1\u6709\u200b\u8fd9\u6837\u200b\u7684\u200b\u96c6\u7fa4\u200b\u7ba1\u7406\u5668\u200b\uff0c \u200b\u90a3\u4e48\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u81ea\u5df1\u200b\u624b\u52a8\u200b\u5199\u200b\u4e00\u4e2a\u200b\u8fd9\u6837\u200b\u7684\u200b\u6587\u672c\u6587\u4ef6\u200b\u5373\u53ef\u200b\u3002</p> <p>\u200b\u63d0\u4f9b\u200b\u7ed9\u200bColossal-AI\u200b\u7684\u200bhost file\u200b\u9700\u8981\u200b\u9075\u5faa\u200b\u4ee5\u4e0b\u200b\u683c\u5f0f\u200b\uff0c\u200b\u6bcf\u200b\u4e00\u884c\u200b\u90fd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u540d\u5b57\u200b\u3002</p> <pre><code>host1\nhost2\n</code></pre> <p>\u200b\u5982\u679c\u200bhost file\u200b\u51c6\u5907\u200b\u597d\u200b\u4e86\u200b\uff0c\u200b\u90a3\u4e48\u200b\u6211\u4eec\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5f00\u59cb\u200b\u591a\u200b\u8282\u70b9\u200b\u8bad\u7ec3\u200b\u4e86\u200b\u3002\u200b\u548c\u200b\u4f7f\u7528\u200b<code>--host</code>\u200b\u4e00\u6837\u200b\uff0c\u200b\u4f60\u200b\u4e5f\u200b\u9700\u8981\u200b\u6307\u5b9a\u200b\u4e00\u4e2a\u200b<code>master_addr</code>\u3002 \u200b\u5f53\u200b\u4f7f\u7528\u200bhost file\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4e00\u4e9b\u200b\u989d\u5916\u200b\u7684\u200b\u53c2\u6570\u200b\uff1a - <code>--include</code>: \u200b\u8bbe\u7f6e\u200b\u4f60\u200b\u60f3\u8981\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u7684\u200b\u8282\u70b9\u200b\u3002\u200b\u6bd4\u5982\u200b\uff0c\u200b\u4f60\u200b\u7684\u200bhost file\u200b\u91cc\u200b\u6709\u200b8\u200b\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u4f46\u662f\u200b\u4f60\u200b\u53ea\u200b\u60f3\u200b\u7528\u200b\u5176\u4e2d\u200b\u7684\u200b6\u200b\u4e2a\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\uff0c   \u200b\u4f60\u200b\u53ef\u4ee5\u200b\u6dfb\u52a0\u200b<code>--include host1,host2,host3,...,host6</code>\uff0c\u200b\u8fd9\u6837\u200b\u8bad\u7ec3\u4efb\u52a1\u200b\u53ea\u4f1a\u200b\u5728\u200b\u8fd9\u200b6\u200b\u4e2a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u542f\u52a8\u200b\u3002</p> <ul> <li><code>--exclude</code>: \u200b\u8bbe\u7f6e\u200b\u4f60\u200b\u60f3\u200b\u6392\u9664\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e4b\u5916\u200b\u7684\u200b\u8282\u70b9\u200b\u3002\u200b\u5f53\u200b\u4f60\u200b\u7684\u200b\u67d0\u200b\u4e00\u4e9b\u200b\u8282\u70b9\u200b\u574f\u6389\u200b\u65f6\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\u4f1a\u200b\u6bd4\u8f83\u200b\u6709\u7528\u200b\u3002\u200b\u6bd4\u5982\u200b\u5047\u5982\u200bhost1\u200b\u7684\u200bGPU\u200b\u6709\u200b\u4e00\u4e9b\u200b\u95ee\u9898\u200b\uff0c\u200b\u65e0\u6cd5\u200b\u6b63\u5e38\u200b\u4f7f\u7528\u200b\uff0c   \u200b\u90a3\u4e48\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>--exclude host1</code>\u200b\u6765\u200b\u5c06\u200b\u5176\u200b\u6392\u9664\u200b\u5728\u5916\u200b\uff0c\u200b\u8fd9\u6837\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u8bad\u7ec3\u4efb\u52a1\u200b\u5c31\u200b\u53ea\u4f1a\u200b\u5728\u200b\u5269\u4f59\u200b\u7684\u200b\u8282\u70b9\u200b\u4e0a\u200b\u542f\u52a8\u200b\u3002</li> </ul> <pre><code># \u200b\u4f7f\u7528\u200bhostfile\u200b\u542f\u52a8\u200b\ncolossalai run --nproc_per_node 4 --hostfile ./hostfile --master_addr host1  test.py\n\n# \u200b\u53ea\u200b\u4f7f\u7528\u200b\u90e8\u5206\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\ncolossalai run --nproc_per_node 4 --hostfile ./hostfile --master_addr host1  --include host1 test.py\n\n# \u200b\u4e0d\u200b\u4f7f\u7528\u200b\u67d0\u4e9b\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\ncolossalai run --nproc_per_node 4 --hostfile ./hostfile --master_addr host1  --exclude host2 test.py\n</code></pre>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#slurm","title":"\u7528\u200b SLURM \u200b\u542f\u52a8","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u662f\u200b\u5728\u200b\u4e00\u4e2a\u200b\u7531\u200b SLURM \u200b\u8c03\u5ea6\u200b\u5668\u200b\u7ba1\u7406\u200b\u7684\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\uff0c \u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>srun</code> \u200b\u542f\u52a8\u5668\u200b\u6765\u200b\u542f\u52a8\u200b\u60a8\u200b\u7684\u200b Colossal-AI \u200b\u811a\u672c\u200b\u3002\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u8f85\u52a9\u200b\u51fd\u6570\u200b <code>launch_from_slurm</code> \u200b\u6765\u200b\u4e0e\u200b SLURM \u200b\u8c03\u5ea6\u200b\u5668\u200b\u517c\u5bb9\u200b\u3002 <code>launch_from_slurm</code> \u200b\u4f1a\u200b\u81ea\u52a8\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b <code>SLURM_PROCID</code> \u200b\u548c\u200b <code>SLURM_NPROCS</code> \u200b\u4e2d\u200b\u5206\u522b\u200b\u8bfb\u53d6\u200b rank \u200b\u548c\u200b world size \uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u5b83\u4eec\u200b\u6765\u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u540e\u200b\u7aef\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u4e2d\u200b\u5c1d\u8bd5\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\u3002</p> <pre><code>import colossalai\n\ncolossalai.launch_from_slurm(\n    config=&lt;CONFIG&gt;,\n    host=args.host,\n    port=args.port\n)\n</code></pre> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5728\u200b\u7ec8\u7aef\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u547d\u4ee4\u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u3002</p> <pre><code>srun python train.py --host &lt;master_node&gt; --port 29500\n</code></pre>"},{"location":"3-%E5%9F%BA%E7%A1%80/launch_colossalai/#openmpi","title":"\u7528\u200b OpenMPI \u200b\u542f\u52a8","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5bf9\u200bOpenMPI\u200b\u6bd4\u8f83\u200b\u719f\u6089\u200b\uff0c\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>launch_from_openmpi</code> \u3002 <code>launch_from_openmpi</code> \u200b\u4f1a\u200b\u81ea\u52a8\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b <code>OMPI_COMM_WORLD_LOCAL_RANK</code>\uff0c <code>MPI_COMM_WORLD_RANK</code> \u200b\u548c\u200b <code>OMPI_COMM_WORLD_SIZE</code> \u200b\u4e2d\u200b\u5206\u522b\u200b\u8bfb\u53d6\u200blocal rank\u3001global rank \u200b\u548c\u200b world size\uff0c\u200b\u5e76\u200b\u5229\u7528\u200b\u5b83\u4eec\u200b\u6765\u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u540e\u200b\u7aef\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u4e2d\u200b\u5c1d\u8bd5\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\u3002 <pre><code>colossalai.launch_from_openmpi(\n    config=&lt;CONFIG&gt;,\n    host=args.host,\n    port=args.port\n)\n</code></pre></p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u7528\u200b OpenMPI \u200b\u542f\u52a8\u200b\u591a\u4e2a\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u793a\u4f8b\u200b\u547d\u4ee4\u200b\u3002 <pre><code>mpirun --hostfile &lt;my_hostfile&gt; -np &lt;num_process&gt; python train.py --host &lt;node name or ip&gt; --port 29500\n</code></pre></p> <ul> <li>--hostfile: \u200b\u6307\u5b9a\u200b\u4e00\u4e2a\u200b\u8981\u200b\u8fd0\u884c\u200b\u7684\u200b\u4e3b\u673a\u200b\u5217\u8868\u200b\u3002</li> <li>--np: \u200b\u8bbe\u7f6e\u200b\u603b\u5171\u200b\u8981\u200b\u542f\u52a8\u200b\u7684\u200b\u8fdb\u7a0b\u200b\uff08GPU\uff09\u200b\u7684\u200b\u6570\u91cf\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b --np 4\uff0c4\u200b\u4e2a\u200b python \u200b\u8fdb\u7a0b\u200b\u5c06\u200b\u88ab\u200b\u521d\u59cb\u5316\u200b\u4ee5\u200b\u8fd0\u884c\u200b train.py\u3002</li> </ul>"},{"location":"4-%E7%89%B9%E7%82%B9/1D_tensor_parallel/","title":"1D \u200b\u5f20\u91cf\u200b\u5e76\u884c","text":"<p>\u200b\u4f5c\u8005\u200b: Zhengda Bian, Yongbin Li</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - Tensor Parallelism with Shardformer</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</p>"},{"location":"4-%E7%89%B9%E7%82%B9/1D_tensor_parallel/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u5c06\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u5212\u5206\u200b\u5230\u200b\u591a\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u8d1f\u8377\u200b\u3002 Megatron-LM \u200b\u4ecb\u7ecd\u200b\u4e86\u200b\u4e00\u79cd\u200b\u9ad8\u6548\u200b\u7684\u200b\u4e00\u7ef4\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u5316\u200b\u5b9e\u73b0\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ee5\u200b\u4e00\u4e2a\u200b\u7ebf\u6027\u200b\u5c42\u4e3a\u4f8b\u200b\uff0c\u200b\u5b83\u200b\u5305\u62ec\u200b\u4e00\u4e2a\u200b GEMM \\(Y = XA\\)\u3002 \u200b\u7ed9\u5b9a\u200b2\u200b\u4e2a\u200b\u5904\u7406\u5668\u200b\uff0c\u200b\u6211\u4eec\u200b\u628a\u200b\u5217\u200b \\(A\\) \u200b\u5212\u5206\u200b\u4e3a\u200b \\([A_1 ~ A_2]\\), \u200b\u5e76\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5904\u7406\u5668\u200b\u4e0a\u200b\u8ba1\u7b97\u200b \\(Y_i = XA_i\\) , \u200b\u7136\u540e\u200b\u5f62\u6210\u200b \\([Y_1 ~ Y_2] = [XA_1 ~ XA_2]\\). \u200b\u8fd9\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u5217\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b\u3002</p> <p>\u200b\u5f53\u200b\u7b2c\u4e8c\u4e2a\u200b\u7ebf\u6027\u200b\u5c42\u200b \\(Z=YB\\) \u200b\u8ddf\u968f\u200b\u4e0a\u8ff0\u200b\u5217\u200b\u5e76\u884c\u200b\u5c42\u200b\u7684\u200b\u65f6\u5019\u200b, \u200b\u6211\u4eec\u200b\u628a\u200b \\(B\\) \u200b\u5212\u5206\u200b\u4e3a\u200b $$ \\left[\\begin{matrix} B_1 \\ B_2 \\end{matrix} \\right] ``` \u200b\u8fd9\u200b\u5c31\u662f\u200b\u6240\u8c13\u200b\u7684\u200b\u884c\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b. $$</p> <p>\u200b\u4e3a\u4e86\u200b\u8ba1\u7b97\u200b $$ Z = [Y_1 ~ Y_2] \\left[\\begin{matrix} B_1 \\ B_2 \\end{matrix} \\right] $$ \u200b\u6211\u4eec\u200b\u9996\u5148\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5904\u7406\u5668\u200b\u4e0a\u200b\u8ba1\u7b97\u200b \\(Y_iB_i\\) \u200b\u7136\u540e\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200ball-reduce\u200b\u64cd\u4f5c\u200b\u5c06\u200b\u7ed3\u679c\u200b\u6c47\u603b\u200b\u4e3a\u200b \\(Z=Y_1B_1+Y_2B_2\\)\u3002</p> <p>\u200b\u6211\u4eec\u200b\u8fd8\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5728\u200b\u540e\u200b\u5411\u200b\u8ba1\u7b97\u200b\u4e2d\u200b\uff0c\u200b\u5217\u200b\u5e76\u884c\u200b\u7ebf\u6027\u200b\u5c42\u200b\u9700\u8981\u200b\u805a\u5408\u200b\u8f93\u5165\u200b\u5f20\u91cf\u200b \\(X\\), \u200b\u56e0\u4e3a\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5904\u7406\u5668\u200b \\(i\\) \u200b\u4e0a\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u6709\u200b \\(\\dot{X_i}=\\dot{Y_i}A_i^T\\)\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u5404\u200b\u5904\u7406\u5668\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200ball-reduce\uff0c\u200b\u5f97\u5230\u200b \\(\\dot{X}=\\dot{Y}A^T=\\dot{Y_1}A_1^T+\\dot{Y_2}A_2^T\\)\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/1D_tensor_parallel/#_2","title":"\u6548\u7387","text":"<p>\u200b\u7ed9\u5b9a\u200b \\(P\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b, \u200b\u6211\u4eec\u200b\u5c55\u73b0\u200b\u7406\u8bba\u200b\u4e0a\u200b\u7684\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u73af\u5f62\u200b\u7b97\u6cd5\u200b\u7684\u200b1D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u7684\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u3002</p> \u200b\u8ba1\u7b97\u200b \u200b\u5185\u5b58\u200b (\u200b\u53c2\u6570\u200b) \u200b\u5185\u5b58\u200b (activations) \u200b\u901a\u4fe1\u200b (\u200b\u5e26\u5bbd\u200b) \u200b\u901a\u4fe1\u200b (\u200b\u65f6\u5ef6\u200b) \\(O(1/P)\\) \\(O(1/P)\\) \\(O(1)\\) \\(O(2(P-1)/P)\\) \\(O(2(P-1))\\)"},{"location":"4-%E7%89%B9%E7%82%B9/1D_tensor_parallel/#_3","title":"\u4f7f\u7528","text":"<p>\u200b\u5728\u200bColossalAI\u200b\u6700\u65b0\u200b\u7684\u200b\u7248\u672c\u200b\u4e2d\u200b\uff0c1D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7531\u200b<code>Shardformer</code>\u200b\u529f\u80fd\u200b\u5b9e\u73b0\u200b\u3002 \u200b\u5173\u4e8e\u200b<code>Shardformer</code>\u200b\u7684\u200b\u539f\u7406\u200b\u548c\u200b\u7528\u6cd5\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b\u5f53\u524d\u76ee\u5f55\u200b\u4e0b\u200b\u7684\u200bShardformer\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/2D_tensor_parallel/","title":"2D \u200b\u5f20\u91cf\u200b\u5e76\u884c","text":"<p>\u200b\u4f5c\u8005\u200b: Zhengda Bian, Yongbin Li</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - 1D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - ColossalAI-Examples - 2D Tensor Parallelism</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - An Efficient 2D Method for Training Super-Large Deep Learning Models</p>"},{"location":"4-%E7%89%B9%E7%82%B9/2D_tensor_parallel/#_1","title":"\u5f15\u8a00","text":"<p>1D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u6ca1\u6709\u200b\u5bf9\u200b activations \u200b\u8fdb\u884c\u200b\u5212\u5206\u200b\uff0c\u200b\u5c31\u200b\u5927\u89c4\u6a21\u200b\u6a21\u578b\u200b\u800c\u8a00\u200b\uff0c\u200b\u8fd9\u200b\u4e5f\u200b\u4f1a\u200b\u6d88\u8017\u200b\u5927\u91cf\u200b\u7684\u200b\u5185\u5b58\u200b\u3002 \u200b\u4e3a\u4e86\u200b\u5e73\u5747\u5206\u914d\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u8d1f\u8377\u200b\uff0c\u200b\u5728\u200b SUMMA\uff08\u200b\u53ef\u200b\u6269\u5c55\u200b\u7684\u200b\u901a\u7528\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u7b97\u6cd5\u200b\uff09\u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u200b\uff0c 2D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b \u200b\u88ab\u200b\u5f15\u5165\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u8fd8\u662f\u200b\u4ee5\u200b\u7ebf\u6027\u200b\u5c42\u200b \\(Y = XA\\) \u200b\u4e3a\u4f8b\u200b\u3002 \u200b\u7ed9\u5b9a\u200b \\(P=q\\times q\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b\uff08\u200b\u5fc5\u8981\u6761\u4ef6\u200b\uff09, \u200b\u5982\u200b \\(q=2\\), \u200b\u6211\u4eec\u200b\u628a\u200b\u8f93\u5165\u200b \\(X\\) \u200b\u548c\u200b\u6743\u91cd\u200bA \\(A\\) \u200b\u90fd\u200b\u5212\u5206\u200b\u4e3a\u200b</p> \\[ \\left[\\begin{matrix} X_{00} &amp; X_{01} \\\\ X_{10} &amp; X_{11} \\end{matrix} \\right] \\text{~and~} \\left[\\begin{matrix} A_{00} &amp; A_{01} \\\\ A_{10} &amp; A_{11} \\end{matrix} \\right]. \\] <p>\u200b\u8be5\u200b\u8ba1\u7b97\u200b\u5305\u62ec\u200b \\(q\\) \u200b\u6b65\u200b\u3002 \u200b\u5f53\u200b \\(t=1\\) \u200b\u65f6\u200b, \\(X_{i0}\\) \u200b\u5728\u200b\u5176\u884c\u200b\u4e2d\u200b\u88ab\u200b\u5e7f\u64ad\u200b, \u200b\u800c\u200b \\(A_{0j}\\) \u200b\u5728\u200b\u5176\u5217\u200b\u4e2d\u200b\u88ab\u200b\u5e7f\u64ad\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u6211\u4eec\u200b\u6709\u200b</p> \\[ \\left[\\begin{matrix} X_{00},A_{00} &amp; X_{00},A_{01} \\\\ X_{10},A_{00} &amp; X_{10},A_{01} \\end{matrix} \\right]. \\] <p>\u200b\u7136\u540e\u200b\u6211\u4eec\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5904\u7406\u5668\u200b \\((i, j)\\) \u200b\u4e0a\u5c06\u200b \\(X_{i0}\\) \u200b\u548c\u200b \\(A_{0j}\\) \u200b\u76f8\u4e58\u200b\u4e3a\u200b</p> \\[ \\left[\\begin{matrix} X_{00}A_{00} &amp; X_{00}A_{01} \\\\ X_{10}A_{00} &amp; X_{10}A_{01} \\end{matrix} \\right] (1). \\] <p>\u200b\u540c\u6837\u200b\uff0c\u200b\u5f53\u200b \\(t=2\\) \u200b\u65f6\u200b, \\(X_{i1}\\) \u200b\u5728\u200b\u5176\u884c\u200b\u4e2d\u200b\u88ab\u200b\u5e7f\u64ad\u200b, \\(A_{1j}\\) \u200b\u5728\u200b\u5176\u5217\u200b\u4e2d\u200b\u88ab\u200b\u5e7f\u64ad\u200b, \u200b\u6211\u4eec\u200b\u5c06\u200b\u5b83\u4eec\u200b\u76f8\u4e58\u200b\u4e3a\u200b</p> \\[ \\left[\\begin{matrix} X_{01}A_{10} &amp; X_{01}A_{11} \\\\ X_{11}A_{10} &amp; X_{11}A_{11} \\end{matrix} \\right] (2). \\] <p>\u200b\u901a\u8fc7\u200b\u5c06\u200b \\((1)\\) \u200b\u548c\u200b \\((2)\\) \u200b\u76f8\u52a0\u200b\uff0c\u200b\u6211\u4eec\u200b\u6709\u200b</p> \\[ Y = XA = \\left[\\begin{matrix} X_{00}A_{00}+X_{01}A_{10} &amp; X_{00}A_{01}+X_{01}A_{11} \\\\ X_{10}A_{00}+X_{11}A_{10} &amp; X_{10}A_{01}+X_{11}A_{11} \\end{matrix} \\right]. \\]"},{"location":"4-%E7%89%B9%E7%82%B9/2D_tensor_parallel/#_2","title":"\u6548\u7387","text":"<p>\u200b\u7ed9\u5b9a\u200b \\(P=q\\times q\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b, \u200b\u6211\u4eec\u200b\u5c55\u73b0\u200b\u7406\u8bba\u200b\u4e0a\u200b\u7684\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u73af\u5f62\u200b\u7b97\u6cd5\u200b\u7684\u200b2D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u7684\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u3002</p> \u200b\u8ba1\u7b97\u200b \u200b\u5185\u5b58\u200b (\u200b\u53c2\u6570\u200b) \u200b\u5185\u5b58\u200b (activations) \u200b\u901a\u4fe1\u200b (\u200b\u5e26\u5bbd\u200b) \u200b\u901a\u4fe1\u200b (\u200b\u65f6\u5ef6\u200b) \\(O(1/q^2)\\) \\(O(1/q^2)\\) \\(O(1/q^2)\\) \\(O(6(q-1)/q)\\) \\(O(6(q-1))\\)"},{"location":"4-%E7%89%B9%E7%82%B9/2D_tensor_parallel/#_3","title":"\u4f7f\u7528","text":"<p>ColossalAI\u200b\u7684\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\u8fd8\u200b\u6682\u200b\u4e0d\u200b\u652f\u6301\u200b2D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u4f46\u200b2D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u529f\u80fd\u200b\u4f1a\u200b\u5728\u200b\u672a\u6765\u200b\u7684\u200b\u7248\u672c\u200b\u88ab\u200b\u96c6\u6210\u200b\u5165\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\u3002\u200b\u5173\u4e8e\u200b<code>Shardformer</code>\u200b\u7684\u200b\u539f\u7406\u200b\u548c\u200b\u7528\u6cd5\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b\u5f53\u524d\u76ee\u5f55\u200b\u4e0b\u200b\u7684\u200bShardformer\u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u5bf9\u4e8e\u200b\u8001\u200b\u7248\u672c\u200bColossalAI\u200b\u7684\u200b\u7528\u6237\u200b\uff0c2D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u7528\u6cd5\u200b\u8bf7\u200b\u53c2\u8003\u200bColossalAI-Examples - 2D Tensor Parallelism\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/2p5D_tensor_parallel/","title":"2.5D \u200b\u5f20\u91cf\u200b\u5e76\u884c","text":"<p>\u200b\u4f5c\u8005\u200b: Zhengda Bian, Yongbin Li</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - 1D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b - 2D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - ColossalAI-Examples - 2.5D Tensor Parallelism</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - 2.5-dimensional distributed model training</p>"},{"location":"4-%E7%89%B9%E7%82%B9/2p5D_tensor_parallel/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u4e0e\u200b\u4e00\u7ef4\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u4e8c\u7ef4\u200b\u5e76\u884c\u200b\u964d\u4f4e\u200b\u4e86\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\uff0c\u200b\u4f46\u200b\u53ef\u80fd\u200b\u5f15\u5165\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u901a\u4fe1\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c2.5D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b \u200b\u5728\u200b 2.5D SUMMA \u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u200b\u88ab\u200b\u63d0\u51fa\u200b\uff0c\u200b\u5b83\u200b\u901a\u8fc7\u200b\u4f7f\u7528\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u8bbe\u5907\u200b\u6765\u200b\u51cf\u5c11\u200b\u901a\u4fe1\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u8fd8\u662f\u200b\u4ee5\u200b\u7ebf\u6027\u200b\u5c42\u200b \\(Y = XA\\) \u200b\u4e3a\u4f8b\u200b\u3002 \u200b\u7ed9\u5b9a\u200b \\(P=q \\times q \\times d\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b\uff08\u200b\u5fc5\u8981\u6761\u4ef6\u200b\uff09, \u200b\u5982\u200b \\(q=d=2\\), \u200b\u6211\u4eec\u200b\u628a\u200b\u8f93\u5165\u200b \\(X\\) \u200b\u5212\u5206\u200b\u4e3a\u200b \\(d\\times q\\) \u200b\u884c\u200b\u548c\u200b \\(q\\) \u200b\u5217\u200b</p> <p>$$ \\left[\\begin{matrix} X_{00} &amp; X_{01} \\ X_{10} &amp; X_{11} \\ X_{20} &amp; X_{21} \\ X_{30} &amp; X_{31}\\end{matrix} \\right], $$ \u200b\u5b83\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u91cd\u5851\u200b\u4e3a\u200b \\(d\\) \u200b\u5c42\u200b</p> \\[ \\left[\\begin{matrix} X_{00} &amp; X_{01} \\\\ X_{10} &amp; X_{11} \\end{matrix} \\right] \\text{~and~}\\left[\\begin{matrix} X_{20} &amp; X_{21} \\\\ X_{30} &amp; X_{31} \\end{matrix} \\right]. \\] <p>\u200b\u53e6\u5916\u200b\uff0c\u200b\u6743\u91cd\u200b \\(A\\) \u200b\u88ab\u200b\u5206\u5272\u200b\u4e3a\u200b</p> \\[ \\left[\\begin{matrix} A_{00} &amp; A_{01} \\\\ A_{10} &amp; A_{11} \\end{matrix} \\right]. \\] <p>\u200b\u5bf9\u4e8e\u200b \\(X\\) \u200b\u76f8\u5173\u200b\u7684\u200b\u6bcf\u200b\u4e00\u5c42\u200b, \u200b\u6211\u4eec\u200b\u4f7f\u7528\u200bSUMMA\u200b\u7b97\u6cd5\u200b\u5c06\u200b \\(X\\) \u200b\u4e0e\u200b \\(A\\) \u200b\u76f8\u4e58\u200b\u3002 \u200b\u7136\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u5f97\u5230\u200b\u8f93\u51fa\u200b</p> \\[ \\left[\\begin{matrix} Y_{00}=X_{00}A_{00}+X_{01}A_{10} &amp; Y_{01}=X_{00}A_{01}+X_{01}A_{11} \\\\ Y_{10}=X_{10}A_{00}+X_{11}A_{10} &amp; Y_{11}=X_{10}A_{01}+X_{11}A_{11} \\end{matrix} \\right] \\text{~and~} $$ $$ \\left[\\begin{matrix} Y_{20}=X_{20}A_{00}+X_{21}A_{10} &amp; Y_{21}=X_{20}A_{01}+X_{21}A_{11} \\\\ Y_{30}=X_{30}A_{00}+X_{31}A_{10} &amp; Y_{31}=X_{30}A_{01}+X_{31}A_{11} \\end{matrix} \\right]. \\]"},{"location":"4-%E7%89%B9%E7%82%B9/2p5D_tensor_parallel/#_2","title":"\u6548\u7387","text":"<p>\u200b\u7ed9\u5b9a\u200b \\(P=q \\times q \\times d\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b, \u200b\u6211\u4eec\u200b\u5c55\u73b0\u200b\u7406\u8bba\u200b\u4e0a\u200b\u7684\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u73af\u5f62\u200b\u7b97\u6cd5\u200b\u7684\u200b2.5D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u7684\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u3002</p> \u200b\u8ba1\u7b97\u200b \u200b\u5185\u5b58\u200b (\u200b\u53c2\u6570\u200b) \u200b\u5185\u5b58\u200b (activations) \u200b\u901a\u4fe1\u200b (\u200b\u5e26\u5bbd\u200b) \u200b\u901a\u4fe1\u200b (\u200b\u65f6\u5ef6\u200b) \\(O(1/dq^2)\\) \\(O(1/q^2)\\) \\(O(1/dq^2)\\) \\(\\small O(3(q-1)(d+1)/dq)\\) \\(O(6(q-1))\\)"},{"location":"4-%E7%89%B9%E7%82%B9/2p5D_tensor_parallel/#_3","title":"\u4f7f\u7528","text":"<p>ColossalAI\u200b\u7684\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\u8fd8\u200b\u6682\u200b\u4e0d\u200b\u652f\u6301\u200b2.5D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u4f46\u200b2.5D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u529f\u80fd\u200b\u4f1a\u200b\u5728\u200b\u672a\u6765\u200b\u7684\u200b\u7248\u672c\u200b\u88ab\u200b\u96c6\u6210\u200b\u5165\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\u3002\u200b\u5173\u4e8e\u200b<code>Shardformer</code>\u200b\u7684\u200b\u539f\u7406\u200b\u548c\u200b\u7528\u6cd5\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b\u5f53\u524d\u76ee\u5f55\u200b\u4e0b\u200b\u7684\u200bShardformer\u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u5bf9\u4e8e\u200b\u8001\u200b\u7248\u672c\u200bColossalAI\u200b\u7684\u200b\u7528\u6237\u200b\uff0c2.5D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u7528\u6cd5\u200b\u8bf7\u200b\u53c2\u8003\u200bColossalAI-Examples - 2.5D Tensor Parallelism\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/3D_tensor_parallel/","title":"3D \u200b\u5f20\u91cf\u200b\u5e76\u884c","text":"<p>\u200b\u4f5c\u8005\u200b: Zhengda Bian, Yongbin Li</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - 1D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b - 2D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - ColossalAI-Examples - 3D Tensor Parallelism</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Maximizing Parallelism in Distributed Training for Huge Neural Networks</p>"},{"location":"4-%E7%89%B9%E7%82%B9/3D_tensor_parallel/#_1","title":"\u5f15\u8a00","text":"<p>3D \u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b \u200b\u662f\u200b\u4e00\u79cd\u200b\u5c06\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u6a21\u578b\u200b\u7684\u200b\u8ba1\u7b97\u200b\u5e76\u884c\u200b\u5316\u200b\uff0c\u200b\u4ee5\u200b\u671f\u671b\u200b\u83b7\u5f97\u6700\u4f73\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u4f18\u5316\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u8fd8\u662f\u200b\u4ee5\u200b\u7ebf\u6027\u200b\u5c42\u200b \\(Y = XA\\) \u200b\u4e3a\u4f8b\u200b\u3002 \u200b\u7ed9\u5b9a\u200b \\(P=q \\times q \\times q\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b\uff08\u200b\u5fc5\u8981\u6761\u4ef6\u200b\uff09, \u200b\u5982\u200b \\(q=2\\), \u200b\u6211\u4eec\u200b\u628a\u200b\u8f93\u5165\u200b \\(X\\) \u200b\u548c\u200b\u6743\u91cd\u200b \\(A\\) \u200b\u5212\u5206\u200b\u4e3a\u200b</p> <p>$$ \\left[\\begin{matrix}             X_{000} &amp; X_{001} \\             X_{010} &amp; X_{011} \\             X_{100} &amp; X_{101} \\             X_{110} &amp; X_{111} \\end{matrix} \\right] \\text{~and~} \\left[\\begin{matrix}             A_{000} &amp; A_{001} &amp; A_{010} &amp; A_{011} \\             A_{100} &amp; A_{101} &amp; A_{110} &amp; A_{111} \\end{matrix} \\right] \\text{~respectively,}$$ \u200b\u5176\u4e2d\u200b\u6bcf\u4e2a\u200b \\(X_{ijl}\\) \u200b\u548c\u200b \\(A_{lji}\\) \u200b\u90fd\u200b\u88ab\u200b\u5b58\u50a8\u200b\u5728\u200b\u5904\u7406\u5668\u200b \\((i,j,l)\\) \u200b\u4e0a\u200b, \u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p> </p> <p>\u200b\u7136\u540e\u200b\u6211\u4eec\u200b\u5728\u200b \\((i, 0...q,l)\\) \u200b\u4e0a\u200b\u6536\u96c6\u200b \\(X_{ijl}\\), \u200b\u4ee5\u53ca\u200b\u5728\u200b\\((0...q, j, l)\\) \u200b\u4e0a\u200b\u6536\u96c6\u200b \\(A_{lji}\\)\u3002 \u200b\u56e0\u6b64\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5904\u7406\u5668\u200b \\((i,j,l)\\) \u200b\u4e0a\u200b\u90fd\u200b\u6709\u200b \\(X_{il}\\) \u200b\u548c\u200b \\(A_{lj}\\) \u200b\u4ee5\u200b\u83b7\u5f97\u200b \\(X_{il}A_{lj}\\)\u3002 \u200b\u6700\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b \\((i, j, 0...q)\\) \u200b\u5bf9\u200b\u7ed3\u679c\u200b\u8fdb\u884c\u200b reduce-scatter \u200b\u5f97\u5230\u200b \\(Y_{ijl}\\), \u200b\u5f62\u6210\u200b $$ Y= \\left[\\begin{matrix}             Y_{000} &amp; Y_{001} \\             Y_{010} &amp; Y_{011} \\             Y_{100} &amp; Y_{101} \\             Y_{110} &amp; Y_{111} \\end{matrix} \\right]. $$</p> <p>\u200b\u6211\u4eec\u200b\u8fd8\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5728\u200b\u540e\u200b\u5411\u200b\u4f20\u64ad\u200b\u4e2d\u200b, \u200b\u6211\u4eec\u200b\u9700\u8981\u200b all-gather \u200b\u68af\u5ea6\u200b \\(\\dot{Y_{ijl}}\\), \u200b\u7136\u540e\u200b reduce-scatter \u200b\u68af\u5ea6\u200b \\(\\dot{X_{il}}=\\dot{Y_{ij}}A_{lj}^T\\) and \\(\\dot{A_{lj}}=X_{il}^T\\dot{Y_{ij}}\\)\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/3D_tensor_parallel/#_2","title":"\u6548\u7387","text":"<p>\u200b\u7ed9\u5b9a\u200b \\(P=q \\times q \\times q\\) \u200b\u4e2a\u200b\u5904\u7406\u5668\u200b, \u200b\u6211\u4eec\u200b\u5c55\u73b0\u200b\u7406\u8bba\u200b\u4e0a\u200b\u7684\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u73af\u5f62\u200b\u7b97\u6cd5\u200b\u7684\u200b3D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u7684\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u3002</p> \u200b\u8ba1\u7b97\u200b \u200b\u5185\u5b58\u200b (\u200b\u53c2\u6570\u200b) \u200b\u5185\u5b58\u200b (activations) \u200b\u901a\u4fe1\u200b (\u200b\u5e26\u5bbd\u200b) \u200b\u901a\u4fe1\u200b (\u200b\u65f6\u5ef6\u200b) \\(O(1/q^3)\\) \\(O(1/q^3)\\) \\(O(1/q^3)\\) \\(O(6(q-1)/q^3)\\) \\(O(6(q-1))\\)"},{"location":"4-%E7%89%B9%E7%82%B9/3D_tensor_parallel/#_3","title":"\u4f7f\u7528","text":"<p>ColossalAI\u200b\u7684\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\u8fd8\u200b\u6682\u200b\u4e0d\u200b\u652f\u6301\u200b3D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u4f46\u200b3D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u529f\u80fd\u200b\u4f1a\u200b\u5728\u200b\u672a\u6765\u200b\u7684\u200b\u7248\u672c\u200b\u88ab\u200b\u96c6\u6210\u200b\u5165\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\u3002\u200b\u5173\u4e8e\u200b<code>Shardformer</code>\u200b\u7684\u200b\u539f\u7406\u200b\u548c\u200b\u7528\u6cd5\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b\u5f53\u524d\u76ee\u5f55\u200b\u4e0b\u200b\u7684\u200bShardformer\u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u5bf9\u4e8e\u200b\u8001\u200b\u7248\u672c\u200bColossalAI\u200b\u7684\u200b\u7528\u6237\u200b\uff0c3D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u7528\u6cd5\u200b\u8bf7\u200b\u53c2\u8003\u200bColossalAI-Examples - 3D Tensor Parallelism\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/cluster_utils/","title":"\u96c6\u7fa4\u200b\u5b9e\u7528\u7a0b\u5e8f","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b: - \u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b</p>"},{"location":"4-%E7%89%B9%E7%82%B9/cluster_utils/#_2","title":"\u5f15\u8a00","text":"<p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5b9e\u7528\u7a0b\u5e8f\u200b\u7c7b\u200b <code>colossalai.cluster.DistCoordinator</code> \u200b\u6765\u200b\u534f\u8c03\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5b83\u200b\u5bf9\u4e8e\u200b\u83b7\u53d6\u200b\u6709\u5173\u200b\u96c6\u7fa4\u200b\u7684\u200b\u5404\u79cd\u200b\u4fe1\u606f\u200b\u5f88\u200b\u6709\u7528\u200b\uff0c\u200b\u4f8b\u5982\u200b\u8282\u70b9\u200b\u6570\u200b\u3001\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u6570\u7b49\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/cluster_utils/#api","title":"API \u200b\u53c2\u8003","text":"<p>{{ autodoc:colossalai.cluster.DistCoordinator }}</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/","title":"\u68af\u5ea6\u200b\u7d2f\u79ef","text":"<p>\u200b\u4f5c\u8005\u200b: Mingyan Jiang, Baizhou Zhang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - \u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u4f7f\u7528\u200bBooster</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#_2","title":"\u5f15\u8a00","text":"<p>\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u662f\u200b\u4e00\u79cd\u200b\u5e38\u89c1\u200b\u7684\u200b\u589e\u5927\u200b\u8bad\u7ec3\u200b batch size \u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002 \u200b\u5728\u200b\u8bad\u7ec3\u200b\u5927\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u5185\u5b58\u200b\u7ecf\u5e38\u200b\u4f1a\u200b\u6210\u4e3a\u200b\u74f6\u9888\u200b\uff0c\u200b\u5e76\u4e14\u200b batch size \u200b\u901a\u5e38\u200b\u4f1a\u200b\u5f88\u5c0f\u200b\uff08\u200b\u5982\u200b2\uff09\uff0c\u200b\u8fd9\u200b\u5bfc\u81f4\u200b\u6536\u655b\u6027\u200b\u65e0\u6cd5\u200b\u4fdd\u8bc1\u200b\u3002\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u5c06\u200b\u591a\u6b21\u200b\u8fed\u4ee3\u200b\u7684\u200b\u68af\u5ea6\u200b\u7d2f\u52a0\u200b\uff0c\u200b\u5e76\u200b\u4ec5\u200b\u5728\u200b\u8fbe\u5230\u200b\u9884\u8bbe\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b\u65f6\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#_3","title":"\u4f7f\u7528","text":"<p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u975e\u5e38\u7b80\u5355\u200b\uff0cbooster\u200b\u63d0\u4f9b\u200bno_sync\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u4e0a\u4e0b\u6587\u200b\u7ba1\u7406\u5668\u200b\uff0c\u200b\u5728\u200b\u8be5\u200b\u4e0a\u4e0b\u6587\u200b\u7ba1\u7406\u5668\u200b\u4e0b\u200b\u53d6\u6d88\u200b\u540c\u6b65\u200b\u5e76\u4e14\u200b\u7d2f\u79ef\u200b\u68af\u5ea6\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#_4","title":"\u5b9e\u4f8b","text":"<p>\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u6b21\u6570\u200b\u88ab\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b4\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#1-trainpy","title":"\u6b65\u9aa4\u200b 1. \u200b\u5728\u200b train.py \u200b\u5bfc\u5165\u200b\u76f8\u5173\u200b\u5e93","text":"<p>\u200b\u521b\u5efa\u200btrain.py\u200b\u5e76\u200b\u5bfc\u5165\u200b\u5fc5\u8981\u200b\u4f9d\u8d56\u200b\u3002 <code>torch</code> \u200b\u7684\u200b\u7248\u672c\u200b\u5e94\u200b\u4e0d\u200b\u4f4e\u4e8e\u200b1.8.1\u3002</p> <pre><code>import os\nfrom pathlib import Path\n\nimport torch\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet18\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import TorchDDPPlugin\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.cluster.dist_coordinator import priority_execution\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#2","title":"\u6b65\u9aa4\u200b 2. \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883","text":"<p>\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5feb\u901f\u200b\u6f14\u793a\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>launch_from_torch</code>\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b Launch Colossal-AI\u200b\u4f7f\u7528\u200b\u5176\u4ed6\u200b\u521d\u59cb\u5316\u200b\u65b9\u6cd5\u200b\u3002</p> <pre><code># initialize distributed setting\nparser = colossalai.get_default_parser()\nargs = parser.parse_args()\n\n# launch from torch\ncolossalai.launch_from_torch(config=dict())\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#3","title":"\u6b65\u9aa4\u200b 3. \u200b\u521b\u5efa\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6","text":"<p>\u200b\u6784\u5efa\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u3001\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3001\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u6574\u5668\u200b\u548c\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b\u3002\u200b\u6ce8\u610f\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u8def\u5f84\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b<code>DATA</code>\u200b\u83b7\u5f97\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>export DATA=/path/to/data</code> \u200b\u6216\u200b <code>Path(os.environ['DATA'])</code>\uff0c\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\u8bbe\u7f6e\u200b\u8def\u5f84\u200b\u3002\u200b\u6570\u636e\u200b\u5c06\u4f1a\u200b\u88ab\u200b\u81ea\u52a8\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u8be5\u200b\u8def\u5f84\u200b\u3002</p> <pre><code># define the training hyperparameters\nBATCH_SIZE = 128\nGRADIENT_ACCUMULATION = 4\n\n# build resnet\nmodel = resnet18(num_classes=10)\n\n# build dataloaders\nwith priority_execution():\n    train_dataset = CIFAR10(root=Path(os.environ.get('DATA', './data')),\n                            download=True,\n                            transform=transforms.Compose([\n                                transforms.RandomCrop(size=32, padding=4),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n                            ]))\n\n# build criterion\ncriterion = torch.nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#4","title":"\u6b65\u9aa4\u200b 4. \u200b\u6ce8\u5165\u200b\u7279\u6027","text":"<p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b<code>TorchDDPPlugin</code>\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5e76\u200b\u4f5c\u4e3a\u200b\u53c2\u200b\u5b9e\u4f8b\u200b\u5316\u200b<code>Booster</code>\uff0c \u200b\u8c03\u7528\u200b<code>booster.boost</code>\u200b\u6ce8\u5165\u200b\u7279\u6027\u200b\u3002</p> <pre><code>plugin = TorchDDPPlugin()\nbooster = Booster(plugin=plugin)\ntrain_dataloader = plugin.prepare_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nmodel, optimizer, criterion, train_dataloader, _ = booster.boost(model=model,\n                                                                    optimizer=optimizer,\n                                                                    criterion=criterion,\n                                                                    dataloader=train_dataloader)\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#5-booster","title":"\u6b65\u9aa4\u200b 5. \u200b\u4f7f\u7528\u200bbooster\u200b\u8bad\u7ec3","text":"<p>\u200b\u4f7f\u7528\u200bbooster\u200b\u6784\u5efa\u200b\u4e00\u4e2a\u200b\u666e\u901a\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\uff0c\u200b\u9a8c\u8bc1\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002 <code>param_by_iter</code> \u200b\u8bb0\u5f55\u200b\u5206\u5e03\u200b\u8bad\u7ec3\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002 <pre><code>optimizer.zero_grad()\nfor idx, (img, label) in enumerate(train_dataloader):\n        sync_context = booster.no_sync(model)\n        img = img.cuda()\n        label = label.cuda()\n        if idx % (GRADIENT_ACCUMULATION - 1) != 0:\n            with sync_context:\n                output = model(img)\n                train_loss = criterion(output, label)\n                train_loss = train_loss / GRADIENT_ACCUMULATION\n                booster.backward(train_loss, optimizer)\n        else:\n            output = model(img)\n            train_loss = criterion(output, label)\n            train_loss = train_loss / GRADIENT_ACCUMULATION\n            booster.backward(train_loss, optimizer)\n            optimizer.step()\n            optimizer.zero_grad()\n\n        ele_1st = next(model.parameters()).flatten()[0]\n        param_by_iter.append(str(ele_1st.item()))\n\n        if idx != 0 and idx % (GRADIENT_ACCUMULATION - 1) == 0:\n            break\n\n    for iteration, val in enumerate(param_by_iter):\n        print(f'iteration {iteration} - value: {val}')\n\n    if param_by_iter[-1] != param_by_iter[0]:\n        print('The parameter is only updated in the last iteration')\n</code></pre></p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#6","title":"\u6b65\u9aa4\u200b 6. \u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u811a\u672c","text":"<p>\u200b\u4e3a\u4e86\u200b\u9a8c\u8bc1\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u53ea\u200b\u68c0\u67e5\u200b\u53c2\u6570\u503c\u200b\u7684\u200b\u53d8\u5316\u200b\u3002\u200b\u5f53\u200b\u8bbe\u7f6e\u200b\u68af\u5ea6\u200b\u7d2f\u52a0\u200b\u65f6\u200b\uff0c\u200b\u4ec5\u200b\u5728\u200b\u6700\u540e\u200b\u4e00\u6b65\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u8fd0\u884c\u200b\u811a\u672c\u200b\uff1a <pre><code>colossalai run --nproc_per_node 1 train.py\n</code></pre></p> <p>\u200b\u4f60\u200b\u5c06\u200b\u4f1a\u200b\u770b\u5230\u200b\u7c7b\u4f3c\u200b\u4e0b\u65b9\u200b\u7684\u200b\u6587\u672c\u200b\u8f93\u51fa\u200b\u3002\u200b\u8fd9\u200b\u5c55\u73b0\u200b\u4e86\u200b\u68af\u5ea6\u200b\u867d\u7136\u200b\u5728\u200b\u524d\u200b3\u200b\u4e2a\u200b\u8fed\u4ee3\u200b\u4e2d\u200b\u88ab\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4f46\u200b\u76f4\u5230\u200b\u6700\u540e\u200b\u4e00\u6b21\u200b\u8fed\u4ee3\u200b\uff0c\u200b\u53c2\u6570\u200b\u624d\u200b\u88ab\u200b\u66f4\u65b0\u200b\u3002</p> <pre><code>iteration 0, first 10 elements of param: tensor([-0.0208,  0.0189,  0.0234,  0.0047,  0.0116, -0.0283,  0.0071, -0.0359, -0.0267, -0.0006], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)\niteration 1, first 10 elements of param: tensor([-0.0208,  0.0189,  0.0234,  0.0047,  0.0116, -0.0283,  0.0071, -0.0359, -0.0267, -0.0006], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)\niteration 2, first 10 elements of param: tensor([-0.0208,  0.0189,  0.0234,  0.0047,  0.0116, -0.0283,  0.0071, -0.0359, -0.0267, -0.0006], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)\niteration 3, first 10 elements of param: tensor([-0.0141,  0.0464,  0.0507,  0.0321,  0.0356, -0.0150,  0.0172, -0.0118, 0.0222,  0.0473], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_accumulation_with_booster/#gemini","title":"\u5728\u200bGemini\u200b\u63d2\u4ef6\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u7d2f\u79ef","text":"<p>\u200b\u76ee\u524d\u200b\u652f\u6301\u200b<code>no_sync()</code>\u200b\u65b9\u6cd5\u200b\u7684\u200b\u63d2\u4ef6\u200b\u5305\u62ec\u200b <code>TorchDDPPlugin</code> \u200b\u548c\u200b <code>LowLevelZeroPlugin</code>\uff08\u200b\u9700\u8981\u200b\u8bbe\u7f6e\u200b\u53c2\u6570\u200b<code>stage</code>\u200b\u4e3a\u200b1\uff09. <code>GeminiPlugin</code> \u200b\u4e0d\u200b\u652f\u6301\u200b <code>no_sync()</code> \u200b\u65b9\u6cd5\u200b, \u200b\u4f46\u662f\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u548c\u200b<code>pytorch</code>\u200b\u7c7b\u4f3c\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6765\u200b\u4f7f\u7528\u200b\u540c\u6b65\u200b\u7684\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u5f00\u542f\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u529f\u80fd\u200b\uff0c\u200b\u5728\u200b\u521d\u59cb\u5316\u200b<code>GeminiPlugin</code>\u200b\u7684\u200b\u65f6\u5019\u200b\u9700\u8981\u200b\u5c06\u200b\u53c2\u6570\u200b<code>enable_gradient_accumulation</code>\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>True</code>\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b <code>GeminiPlugin</code> \u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u7684\u200b\u4f2a\u200b\u4ee3\u7801\u200b\u7247\u6bb5\u200b:</p> <pre><code>...\nplugin = GeminiPlugin(..., enable_gradient_accumulation=True)\nbooster = Booster(plugin=plugin)\n...\n\n...\nfor idx, (input, label) in enumerate(train_dataloader):\n    output = gemini_model(input.cuda())\n    train_loss = criterion(output, label.cuda())\n    train_loss = train_loss / GRADIENT_ACCUMULATION\n    booster.backward(train_loss, gemini_optimizer)\n\n    if idx % (GRADIENT_ACCUMULATION - 1) == 0:\n        gemini_optimizer.step() # zero_grad is automatically done\n...\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/","title":"\u68af\u5ea6\u200b\u88c1\u526a","text":"<p>\u200b\u4f5c\u8005\u200b: Mingyan Jiang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - booster\u200b\u4f7f\u7528\u200b</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - On the difficulty of training Recurrent Neural Networks</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#_2","title":"\u5f15\u8a00","text":"<p>\u200b\u4e3a\u4e86\u200b\u52a0\u5feb\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u548c\u200b\u5bfb\u6c42\u200b\u5168\u5c40\u200b\u6700\u4f18\u200b\u4ee5\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\uff0c\u200b\u8d8a\u6765\u8d8a\u200b\u591a\u200b\u7684\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u88ab\u200b\u63d0\u51fa\u200b\u3002\u200b\u4eba\u4eec\u200b\u901a\u8fc7\u200b\u63a7\u5236\u200b\u5b66\u4e60\u200b\u7387\u6765\u200b\u8c03\u6574\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u7684\u200b\u4e0b\u964d\u200b\u901f\u5ea6\u200b\u3002\u200b\u8fd9\u200b\u4f7f\u5f97\u200b\u68af\u5ea6\u200b\u5411\u91cf\u200b\u5728\u200b\u6bcf\u200b\u4e00\u6b65\u200b\u90fd\u200b\u80fd\u200b\u66f4\u597d\u200b\u5730\u200b\u7edf\u4e00\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4e0b\u964d\u200b\u901f\u5ea6\u200b\u53ef\u4ee5\u200b\u6309\u200b\u9884\u671f\u200b\u88ab\u200b\u63a7\u5236\u200b\u3002 \u200b\u56e0\u6b64\u200b\uff0c\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\uff0c\u200b\u4e00\u79cd\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u68af\u5ea6\u200b\u5411\u91cf\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u4ee5\u200b\u5c06\u200b\u5176\u200b\u9650\u5236\u200b\u5728\u200b\u7edf\u4e00\u200b\u957f\u5ea6\u200b\u7684\u200b\u6280\u672f\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u90a3\u4e9b\u200b\u5e0c\u671b\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u66f4\u597d\u200b\u7684\u200b\u4eba\u200b\u6765\u8bf4\u200b\u662f\u200b\u4e0d\u53ef\u6216\u7f3a\u200b\u7684\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f7f\u7528\u200b Colossal-AI \u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u4e0d\u5fc5\u200b\u62c5\u5fc3\u200b\u5b9e\u73b0\u200b\u68af\u5ea6\u200b\u526a\u88c1\u200b\uff0c\u200b\u6211\u4eec\u200b\u4ee5\u200b\u4e00\u79cd\u200b\u6709\u6548\u200b\u800c\u200b\u65b9\u4fbf\u200b\u7684\u200b\u65b9\u5f0f\u200b\u652f\u6301\u200b\u68af\u5ea6\u200b\u526a\u88c1\u200b\u3002\u200b\u4f60\u200b\u6240\u200b\u9700\u8981\u200b\u7684\u200b\u53ea\u662f\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u589e\u52a0\u200b\u4e00\u4e2a\u200b\u547d\u4ee4\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#colossal-ai","title":"\u4e3a\u4ec0\u4e48\u200b\u5e94\u8be5\u200b\u4f7f\u7528\u200b Colossal-AI \u200b\u4e2d\u200b\u7684\u200b\u68af\u5ea6\u200b\u88c1\u526a","text":"<p>\u200b\u6211\u4eec\u200b\u4e0d\u200b\u5efa\u8bae\u200b\u7528\u6237\u200b\u81ea\u5df1\u200b\u7f16\u5199\u200b\u68af\u5ea6\u200b\u526a\u88c1\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6734\u7d20\u200b\u7684\u200b\u68af\u5ea6\u200b\u526a\u88c1\u200b\u5728\u200b\u5e94\u7528\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u3001\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u3001MoE \u200b\u7b49\u200b\u529f\u80fd\u200b\u65f6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5931\u8d25\u200b\u3002</p> <p>\u200b\u6839\u636e\u200b\u4e0b\u56fe\u200b\uff0c\u200b\u6bcf\u4e2a\u200b GPU \u200b\u53ea\u200b\u62e5\u6709\u200b\u7ebf\u6027\u200b\u5c42\u4e2d\u200b\u6743\u91cd\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\u53c2\u6570\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5f97\u5230\u200b\u7ebf\u6027\u200b\u5c42\u200b\u6743\u91cd\u200b\u7684\u200b\u68af\u5ea6\u200b\u5411\u91cf\u200b\u7684\u200b\u6b63\u786e\u200b\u8303\u6570\u200b\uff0c\u200b\u6bcf\u4e2a\u200b GPU \u200b\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u68af\u5ea6\u200b\u5411\u91cf\u200b\u7684\u200b\u8303\u6570\u200b\u5e94\u8be5\u200b\u76f8\u52a0\u200b\u3002\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u504f\u7f6e\u200b\u7684\u200b\u5206\u5e03\u200b\u4e0d\u540c\u4e8e\u200b\u6743\u91cd\u200b\u7684\u200b\u5206\u5e03\u200b\u3002\u200b\u901a\u4fe1\u200b\u7ec4\u5728\u200b\u6c42\u548c\u200b\u8fd0\u7b97\u200b\u4e2d\u200b\u6709\u6240\u4e0d\u540c\u200b\u3002</p> <p>(\u200b\u6ce8\u200b: \u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u662f\u200b\u65e7\u7248\u672c\u200b\u7684\u200b 2D \u200b\u5e76\u884c\u200b\uff0c\u200b\u5728\u200b\u4ee3\u7801\u200b\u4e2d\u200b\u7684\u200b\u5b9e\u73b0\u200b\u662f\u200b\u4e0d\u200b\u4e00\u6837\u200b\u7684\u200b\u3002\u200b\u4f46\u200b\u8fd9\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f88\u200b\u597d\u200b\u7684\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u80fd\u591f\u200b\u8bf4\u660e\u200b\u5728\u200b\u68af\u5ea6\u200b\u526a\u88c1\u200b\u4e2d\u200b\u7edf\u4e00\u200b\u6240\u6709\u200b\u901a\u4fe1\u200b\u7684\u200b\u56f0\u96be\u200b\u3002)</p> \u200b\u53c2\u6570\u200b\u5206\u5e03\u200b <p>\u200b\u4e0d\u7528\u200b\u62c5\u5fc3\u200b\u5b83\u200b\uff0c\u200b\u56e0\u4e3a\u200b Colossal-AI \u200b\u5df2\u7ecf\u200b\u4e3a\u200b\u4f60\u200b\u5904\u7406\u200b\u597d\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#_3","title":"\u4f7f\u7528","text":"<p>\u200b\u8981\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5728\u200b\u4f7f\u7528\u200bbooster\u200b\u6ce8\u5165\u200b\u7279\u6027\u200b\u4e4b\u540e\u200b\uff0c\u200b\u8c03\u7528\u200boptimizer\u200b\u7684\u200b<code>clip_grad_by_norm</code>\u200b\u6216\u8005\u200b<code>clip_grad_by_value</code>\u200b\u51fd\u6570\u200b\u5373\u53ef\u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#_4","title":"\u5b9e\u4f8b","text":"<p>\u200b\u4e0b\u9762\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\uff0c\u200b\u5728\u200b\u672c\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\u8303\u6570\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b1.0\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#1","title":"\u6b65\u9aa4\u200b 1. \u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u5bfc\u5165\u200b\u76f8\u5173\u200b\u5e93","text":"<p>\u200b\u521b\u5efa\u200b<code>train.py</code>\u200b\u5e76\u200b\u5bfc\u5165\u200b\u76f8\u5173\u200b\u5e93\u200b\u3002</p> <pre><code>import os\nfrom pathlib import Path\n\nimport torch\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet34\nfrom tqdm import tqdm\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import TorchDDPPlugin\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.nn.lr_scheduler import CosineAnnealingLR\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#2","title":"\u6b65\u9aa4\u200b 2. \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883","text":"<p>\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b. \u200b\u4e3a\u4e86\u200b\u5feb\u901f\u200b\u6f14\u793a\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>launch_from_torch</code>. \u200b\u60a8\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b Launch Colossal-AI</p> <pre><code>colossalai.launch_from_torch(config=dict())\nlogger = get_dist_logger()\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#3","title":"\u6b65\u9aa4\u200b 3. \u200b\u521b\u5efa\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6","text":"<p>\u200b\u6784\u5efa\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u3001\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3001\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u6574\u5668\u200b\u548c\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b\u3002\u200b\u6ce8\u610f\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u8def\u5f84\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b<code>DATA</code>\u200b\u83b7\u5f97\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>export DATA=/path/to/data</code> \u200b\u6216\u200b <code>Path(os.environ['DATA'])</code>\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\u8bbe\u7f6e\u200b\u8def\u5f84\u200b\u3002\u200b\u6570\u636e\u200b\u5c06\u4f1a\u200b\u88ab\u200b\u81ea\u52a8\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u8be5\u200b\u8def\u5f84\u200b\u3002 <pre><code># define training hyperparameters\nNUM_EPOCHS = 200\nBATCH_SIZE = 128\nGRADIENT_CLIPPING = 0.1\n# build resnet\nmodel = resnet34(num_classes=10)\n# build dataloaders\ntrain_dataset = CIFAR10(root=Path(os.environ.get('DATA', './data')),\n                        download=True,\n                        transform=transforms.Compose([\n                            transforms.RandomCrop(size=32, padding=4),\n                            transforms.RandomHorizontalFlip(),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n                        ]))\n# build criterion\ncriterion = torch.nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n# lr_scheduler\nlr_scheduler = CosineAnnealingLR(optimizer, total_steps=NUM_EPOCHS)\n</code></pre></p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#4","title":"\u6b65\u9aa4\u200b 4. \u200b\u6ce8\u5165\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\u7279\u6027","text":"<p>\u200b\u521b\u5efa\u200b<code>TorchDDPPlugin</code>\u200b\u5bf9\u8c61\u200b\u5e76\u200b\u521d\u59cb\u5316\u200b<code>Booster</code>, \u200b\u4f7f\u7528\u200bbooster\u200b\u6ce8\u5165\u200b\u76f8\u5173\u200b\u7279\u6027\u200b\u3002 <pre><code>plugin = TorchDDPPlugin()\nbooster = Booster(plugin=plugin)\ntrain_dataloader = plugin.prepare_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nmodel, optimizer, criterion, train_dataloader, lr_scheduler = booster.boost(model,optimizer, criterion,train_dataloader, lr_scheduler)\n</code></pre></p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#5-booster","title":"\u6b65\u9aa4\u200b 5. \u200b\u4f7f\u7528\u200bbooster\u200b\u8bad\u7ec3","text":"<p>\u200b\u4f7f\u7528\u200bbooster\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002 <pre><code># verify gradient clipping\nmodel.train()\nfor idx, (img, label) in enumerate(train_dataloader):\n    img = img.cuda()\n    label = label.cuda()\n\n    model.zero_grad()\n    output = model(img)\n    train_loss = criterion(output, label)\n    booster.backward(train_loss, optimizer)\n    optimizer.clip_grad_by_norm(max_norm=GRADIENT_CLIPPING)\n    optimizer.step()\n    lr_scheduler.step()\n\n    ele_1st = next(model.parameters()).flatten()[0]\n    logger.info(f'iteration {idx}, loss: {train_loss}, 1st element of parameters: {ele_1st.item()}')\n\n    # only run for 4 iterations\n    if idx == 3:\n        break\n</code></pre></p>"},{"location":"4-%E7%89%B9%E7%82%B9/gradient_clipping_with_booster/#6","title":"\u6b65\u9aa4\u200b 6. \u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u811a\u672c","text":"<p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u8fd0\u884c\u200b\u811a\u672c\u200b\uff1a</p> <pre><code>colossalai run --nproc_per_node 1 train.py\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/","title":"\u61d2\u60f0\u200b\u521d\u59cb\u5316","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b: - Train with booster</p>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/#_2","title":"\u7b80\u4ecb","text":"<p>\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u5ef6\u8fdf\u200b\u4e86\u200b\u6a21\u578b\u200b\u7684\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u5b83\u200b\u80fd\u591f\u200b\u8282\u7701\u200b\u5728\u200b\u5927\u200b\u6a21\u578b\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u6709\u200b <code>N</code> \u200b\u5341\u4ebf\u200b\u4e2a\u200b\u53c2\u6570\u200b\u5e76\u4e14\u200b\u4f60\u200b\u7684\u200b\u5185\u5b58\u200b\uff08\u200b\u6216\u200b\u663e\u5b58\u200b\uff09\u200b\u4e3a\u200b <code>M</code> GB, \u200b\u6211\u4eec\u200b\u63a8\u8350\u200b\u60a8\u200b\u5728\u200b <code>4N &gt;= M</code> \u200b\u65f6\u200b\u4f7f\u7528\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u5426\u5219\u200b\uff0c\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u4e0d\u662f\u200b\u5fc5\u987b\u200b\u7684\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/#_3","title":"\u4f7f\u7528","text":"<p>\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u5fc5\u987b\u200b\u4e0e\u200b booster \u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/#api","title":"API \u200b\u53c2\u8003","text":"<p>{{ autodoc:colossalai.lazy.LazyInitContext }}</p>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/#_4","title":"\u4f8b\u5b50","text":"<pre><code>import colossalai\nfrom colossalai.lazy import LazyInitContext\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import GeminiPlugin\n\nfrom transformers import LlamaForCausalLM, LlamaConfig, BertForPreTraining\n\ncolossalai.launch({})\nplugin = GeminiPlugin()\nbooster = Booster(plugin)\n\n# 1. Initialize model from scratch\n# Initialization on cuda will accelerate the initialization process but take more GPU memory.\nwith LazyInitContext(default_device=\"cuda\"):\n    model = LlamaForCausalLM(LlamaConfig(hidden_size=64, intermediate_size=172, num_hidden_layers=4, num_attention_heads=4))\nmodel, *_ = booster.boost(model)\n\n# 2. Initialize model from pretrained\nwith LazyInitContext():\n    model = BertForPreTraining.from_pretrained(\"prajjwal1/bert-tiny\")\nmodel, *_ = booster.boost(model)\n</code></pre> <p>\u26a0\ufe0f \u200b\u4f7f\u7528\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5728\u200b colossalai&gt;0.3.3 \u200b\u6216\u4e3b\u200b\u5206\u652f\u200b\u4e0a\u200b\u652f\u6301\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/lazy_init/#_5","title":"\u9650\u5236","text":"<p>\u200b\u6211\u4eec\u200b\u63d0\u5230\u200b\uff0c\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u5fc5\u987b\u200b\u4e0e\u200b booster \u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002\u200b\u53ea\u6709\u200b\u51e0\u4e2a\u200b\u63d2\u4ef6\u200b\u652f\u6301\u200b\u5b83\u200b\u3002</p> \u200b\u63d2\u4ef6\u200b \u200b\u652f\u6301\u200b\u60c5\u51b5\u200b \u200b\u5907\u6ce8\u200b Gemini \u200b\u662f\u200b Hybrid Parallel \u200b\u662f\u200b Low Level Zero \u200b\u5426\u200b \u200b\u4e0d\u200b\u9700\u8981\u200b Torch DDP \u200b\u5426\u200b \u200b\u4e0d\u200b\u517c\u5bb9\u200b Torch FSDP \u200b\u5426\u200b \u200b\u4e0d\u200b\u517c\u5bb9\u200b <p>\u200b\u4e0d\u662f\u200b\u6240\u6709\u200b\u7684\u200b\u6a21\u578b\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u61d2\u60f0\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u5728\u200b\u67d0\u4e9b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4e00\u90e8\u5206\u200b\u53c2\u6570\u200b/\u200b\u7f13\u51b2\u533a\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u88ab\u200b\u63d0\u524d\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u4f46\u662f\u200b\u4e0d\u7528\u200b\u62c5\u5fc3\u200b\uff0c\u200b\u8fd9\u90e8\u5206\u200b\u901a\u5e38\u200b\u53ea\u200b\u5360\u200b\u6574\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b\u4e00\u5c0f\u90e8\u5206\u200b\u3002</p> <p>\u200b\u5e76\u4e14\u200b\u4e00\u4e9b\u200b\u6a21\u578b\u200b\u5b8c\u5168\u200b\u4e0d\u200b\u652f\u6301\u200b\uff0c\u200b\u4f1a\u200b\u5f15\u53d1\u200b\u9519\u8bef\u200b\u3002\u200b\u6211\u4eec\u200b\u6d4b\u8bd5\u200b\u4e86\u200b torchvision, diffusers, timm, transformers, torchaudio \u200b\u548c\u200b torchrec \u200b\u4e2d\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u6a21\u578b\u200b\u4e0d\u200b\u53d7\u200b\u652f\u6301\u200b\uff1a</p> \u200b\u6a21\u578b\u200b \u200b\u5206\u7c7b\u200b wav2vec2_base torchaudio hubert_base torchaudio ViTModel transformers ViTForMaskedImageModeling transformers ViTForImageClassification transformers Blip2Model transformers Blip2ForConditionalGeneration transformers"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/","title":"\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3","text":"<p>\u200b\u4f5c\u8005\u200b: Mingyan Jiang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b</p> <ul> <li>booster \u200b\u4f7f\u7528\u200b</li> </ul> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b</p> <ul> <li>Accelerating Scientific Computations with Mixed Precision Algorithms</li> </ul>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#_2","title":"\u5f15\u8a00","text":"<p>AMP \u200b\u4ee3\u8868\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u3002 \u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b, \u200b\u6211\u4eec\u200b\u7ed3\u5408\u200b\u4e86\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u7684\u200b\u4e0d\u540c\u200b\u5b9e\u73b0\u200b:</p> <ol> <li>torch.cuda.amp</li> <li>apex.amp</li> <li>naive amp</li> </ol> Colossal-AI \u200b\u652f\u6301\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b \u200b\u652f\u6301\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b fp16 \u200b\u8303\u56f4\u200b AMP_TYPE.TORCH \u2705 \u274c \u200b\u5728\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u671f\u95f4\u200b\uff0c\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u3001\u200b\u6fc0\u6d3b\u200b\u548c\u200b\u68af\u5ea6\u200b\u5411\u4e0b\u200b\u8f6c\u6362\u200b\u81f3\u200b fp16 AMP_TYPE.APEX \u274c \u274c \u200b\u66f4\u200b\u7ec6\u7c92\u5ea6\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b opt_level O0, O1, O2, O3 AMP_TYPE.NAIVE \u2705 \u2705 \u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u3001\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u53cd\u5411\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5168\u90fd\u200b\u5411\u4e0b\u200b\u8f6c\u6362\u200b\u81f3\u200b fp16 <p>\u200b\u524d\u200b\u4e24\u4e2a\u200b\u4f9d\u8d56\u4e8e\u200b PyTorch (1.6 \u200b\u53ca\u200b\u4ee5\u4e0a\u200b) \u200b\u548c\u200b NVIDIA Apex \u200b\u7684\u200b\u539f\u59cb\u200b\u5b9e\u73b0\u200b\u3002\u200b\u6700\u540e\u200b\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u7c7b\u4f3c\u200b Apex O2\u3002\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u65b9\u6cd5\u200b\u4e2d\u200b\uff0cApex-AMP \u200b\u4e0e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4e0d\u200b\u517c\u5bb9\u200b\u3002\u200b\u8fd9\u200b\u662f\u56e0\u4e3a\u200b\u5f20\u91cf\u200b\u662f\u200b\u4ee5\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u65b9\u5f0f\u200b\u5728\u200b\u8bbe\u5907\u200b\u4e4b\u95f4\u200b\u62c6\u5206\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u9700\u8981\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\uff0c\u200b\u4ee5\u200b\u68c0\u67e5\u200b\u6574\u4e2a\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u4e2d\u200b\u662f\u5426\u200b\u51fa\u73b0\u200b inf \u200b\u6216\u200b nan\u3002\u200b\u6211\u4eec\u200b\u4fee\u6539\u200b\u4e86\u200b torch amp \u200b\u5b9e\u73b0\u200b\uff0c\u200b\u4f7f\u200b\u5176\u200b\u73b0\u5728\u200b\u4e0e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u517c\u5bb9\u200b\u3002</p> <p>\u274c\ufe0f fp16 \u200b\u4e0e\u200b ZeRO \u200b\u4e0d\u200b\u517c\u5bb9\u200b</p> <p>\u26a0\ufe0f \u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u76ee\u524d\u200b\u4ec5\u200b\u652f\u6301\u200b naive amp</p> <p>\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b torch AMP\uff0c\u200b\u56e0\u4e3a\u200b\u5728\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u5b83\u200b\u901a\u5e38\u200b\u6bd4\u200b NVIDIA AMP \u200b\u63d0\u4f9b\u200b\u66f4\u597d\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#_3","title":"\u76ee\u5f55","text":"<p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b:</p> <ol> <li>AMP \u200b\u4ecb\u7ecd\u200b</li> <li>Colossal-AI \u200b\u4e2d\u200b\u7684\u200b AMP</li> <li>\u200b\u7ec3\u4e60\u200b\u5b9e\u4f8b\u200b</li> </ol>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#amp","title":"AMP \u200b\u4ecb\u7ecd","text":"<p>\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u662f\u200b\u6df7\u5408\u200b FP16 \u200b\u548c\u200b FP32 \u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u6d6e\u70b9\u200b\u683c\u5f0f\u200b\uff08FP16\uff09\u200b\u5177\u6709\u200b\u8f83\u200b\u4f4e\u200b\u7684\u200b\u7b97\u6cd5\u200b\u590d\u6742\u5ea6\u200b\u548c\u200b\u8f83\u200b\u9ad8\u200b\u7684\u200b\u8ba1\u7b97\u200b\u6548\u7387\u200b\u3002\u200b\u6b64\u5916\u200b\uff0cFP16 \u200b\u4ec5\u200b\u9700\u8981\u200b FP32 \u200b\u6240\u200b\u9700\u200b\u7684\u200b\u4e00\u534a\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\uff0c\u200b\u5e76\u200b\u8282\u7701\u200b\u4e86\u200b\u5185\u5b58\u200b\u548c\u200b\u7f51\u7edc\u5e26\u5bbd\u200b\uff0c\u200b\u4ece\u800c\u200b\u4e3a\u200b\u5927\u200b batch size \u200b\u548c\u200b\u5927\u200b\u6a21\u578b\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u66f4\u200b\u591a\u200b\u5185\u5b58\u200b\u3002</p> <p>\u200b\u7136\u800c\u200b\uff0c\u200b\u8fd8\u6709\u200b\u5176\u4ed6\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5982\u200b\u7f29\u51cf\u200b\uff0c\u200b\u9700\u8981\u200b FP32 \u200b\u7684\u200b\u52a8\u6001\u200b\u8303\u56f4\u200b\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u6570\u503c\u200b\u6ea2\u51fa\u200b/\u200b\u4e0b\u6ea2\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u6211\u4eec\u200b\u5f15\u5165\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u5c1d\u8bd5\u200b\u5c06\u200b\u6bcf\u4e2a\u200b\u64cd\u4f5c\u200b\u4e0e\u5176\u200b\u76f8\u5e94\u200b\u7684\u200b\u6570\u636e\u7c7b\u578b\u200b\u76f8\u5339\u914d\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u4ee5\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u5e76\u200b\u63d0\u9ad8\u200b\u8bad\u7ec3\u200b\u6548\u7387\u200b\u3002</p> AMP \u200b\u793a\u610f\u56fe\u200b (\u200b\u56fe\u7247\u200b\u6765\u81ea\u200b PatrickStar \u200b\u8bba\u6587\u200b)"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#colossal-ai-amp","title":"Colossal-AI \u200b\u4e2d\u200b\u7684\u200b AMP","text":"<p>\u200b\u6211\u4eec\u200b\u652f\u6301\u200b\u4e09\u79cd\u200b AMP \u200b\u8bad\u7ec3\u65b9\u6cd5\u200b\uff0c\u200b\u5e76\u200b\u5141\u8bb8\u200b\u7528\u6237\u200b\u5728\u200b\u6ca1\u6709\u200b\u6539\u53d8\u200b\u4ee3\u7801\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4f7f\u7528\u200b AMP \u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002booster \u200b\u652f\u6301\u200b amp \u200b\u7279\u6027\u200b\u6ce8\u5165\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u8981\u200b\u4f7f\u7528\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5219\u200b\u5728\u200b\u521b\u5efa\u200b booster \u200b\u5b9e\u4f8b\u200b\u65f6\u200b\u6307\u5b9a\u200b<code>mixed_precision</code>\u200b\u53c2\u6570\u200b;\u200b\u540e\u7eed\u200b\u5c06\u4f1a\u200b\u62d3\u5c55\u200b<code>bf16</code>,<code>pf8</code>\u200b\u7684\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b.</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#booster","title":"booster \u200b\u542f\u52a8\u200b\u65b9\u5f0f","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u521b\u5efa\u200b booster \u200b\u5b9e\u4f8b\u200b\u65f6\u200b\uff0c\u200b\u6307\u5b9a\u200b<code>mixed_precision=\"fp16\"</code>\u200b\u5373\u200b\u4f7f\u7528\u200b torch amp\u3002</p> <pre><code>\"\"\"\n    \u200b\u521d\u59cb\u5316\u200b\u6620\u5c04\u200b\u5173\u7cfb\u200b\u5982\u4e0b\u200b\uff1a\n    'fp16': torch amp\n    'fp16_apex': apex amp,\n    'bf16': bf16,\n    'fp8': fp8,\n    'fp16_naive': naive amp\n\"\"\"\nfrom colossalai import Booster\nbooster = Booster(mixed_precision='fp16',...)\n</code></pre> <p>\u200b\u6216\u8005\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u81ea\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b<code>FP16TorchMixedPrecision</code>\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5982\u200b</p> <pre><code>from colossalai.mixed_precision import FP16TorchMixedPrecision\nmixed_precision = FP16TorchMixedPrecision(\n    init_scale=2.**16,\n    growth_factor=2.0,\n    backoff_factor=0.5,\n    growth_interval=2000)\nbooster = Booster(mixed_precision=mixed_precision,...)\n</code></pre> <p>\u200b\u5176\u4ed6\u200b\u7c7b\u578b\u200b\u7684\u200b amp \u200b\u4f7f\u7528\u200b\u65b9\u5f0f\u200b\u4e5f\u200b\u662f\u200b\u4e00\u6837\u200b\u7684\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#torch-amp","title":"Torch AMP \u200b\u914d\u7f6e","text":"<p>{{ autodoc:colossalai.booster.mixed_precision.FP16TorchMixedPrecision }}</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#apex-amp","title":"Apex AMP \u200b\u914d\u7f6e","text":"<p>\u200b\u5bf9\u4e8e\u200b\u8fd9\u79cd\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f9d\u9760\u200b Apex \u200b\u5b9e\u73b0\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u3002\u200b\u6211\u4eec\u200b\u652f\u6301\u200b\u8fd9\u4e2a\u200b\u63d2\u4ef6\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5141\u8bb8\u200b\u5bf9\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u7684\u200b\u7c92\u5ea6\u200b\u8fdb\u884c\u200b\u66f4\u200b\u7cbe\u7ec6\u200b\u7684\u200b\u63a7\u5236\u200b\u3002 \u200b\u4f8b\u5982\u200b, O2 \u200b\u6c34\u5e73\u200b (\u200b\u4f18\u5316\u200b\u5668\u200b\u6c34\u5e73\u200b 2) \u200b\u5c06\u200b\u4fdd\u6301\u200b batch normalization \u200b\u4e3a\u200b FP32\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u7ec6\u8282\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b Apex Documentation\u3002</p> <p>{{ autodoc:colossalai.booster.mixed_precision.FP16ApexMixedPrecision }}</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#naive-amp","title":"Naive AMP \u200b\u914d\u7f6e","text":"<p>\u200b\u5728\u200b Naive AMP \u200b\u6a21\u5f0f\u200b\u4e2d\u200b, \u200b\u6211\u4eec\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u540c\u65f6\u200b\u4fdd\u6301\u200b\u4e86\u200b\u4e0e\u200b\u590d\u6742\u200b\u5f20\u91cf\u200b\u548c\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u7684\u200b\u517c\u5bb9\u6027\u200b\u3002\u200b\u8be5\u200b AMP \u200b\u6a21\u5f0f\u200b\u5c06\u200b\u6240\u6709\u200b\u64cd\u4f5c\u200b\u8f6c\u4e3a\u200b FP16 \u3002\u200b\u4e0b\u5217\u200b\u4ee3\u7801\u200b\u5757\u200b\u5c55\u793a\u200b\u4e86\u200b\u8be5\u200b\u6a21\u5f0f\u200b\u7684\u200b booster \u200b\u542f\u52a8\u200b\u65b9\u5f0f\u200b\u3002</p> <p>{{ autodoc:colossalai.booster.mixed_precision.FP16NaiveMixedPrecision }}</p> <p>\u200b\u5f53\u200b\u4f7f\u7528\u200b<code>colossalai.booster</code>\u200b\u65f6\u200b, \u200b\u9996\u5148\u200b\u9700\u8981\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u3001\u200b\u4e00\u4e2a\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u4e00\u4e2a\u200b\u6807\u51c6\u200b\u3002\u200b\u5c06\u200b\u8f93\u51fa\u200b\u6a21\u578b\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5185\u5b58\u200b\u6d88\u8017\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b AMP \u200b\u6a21\u578b\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u6a21\u578b\u200b\u5df2\u7ecf\u200b\u592a\u200b\u5927\u200b\uff0c\u200b\u65e0\u6cd5\u200b\u653e\u7f6e\u200b\u5728\u200b GPU \u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b<code>dtype=torch.float16</code>\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u6216\u8005\u200b\u8bf7\u200b\u5c1d\u8bd5\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u6216\u200b\u5c1d\u8bd5\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u5e76\u884c\u200b\u5316\u200b\u8bad\u7ec3\u200b\u6280\u672f\u200b\uff01</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#_4","title":"\u5b9e\u4f8b","text":"<p>\u200b\u4e0b\u9762\u200b\u6211\u4eec\u200b\u5c06\u200b\u5c55\u73b0\u200b\u5982\u4f55\u200b\u5728\u200b Colossal-AI \u200b\u4f7f\u7528\u200b AMP\u3002\u200b\u5728\u200b\u8be5\u200b\u4f8b\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b Torch AMP.</p>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#1-trainpy","title":"\u6b65\u9aa4\u200b 1. \u200b\u5728\u200b train.py \u200b\u5bfc\u5165\u200b\u76f8\u5173\u200b\u5e93","text":"<p>\u200b\u521b\u5efa\u200b<code>train.py</code>\u200b\u5e76\u200b\u5bfc\u5165\u200b\u5fc5\u8981\u200b\u4f9d\u8d56\u200b. \u200b\u8bf7\u200b\u8bb0\u5f97\u200b\u901a\u8fc7\u200b\u547d\u4ee4\u200b<code>pip install timm scipy</code>\u200b\u5b89\u88c5\u200b<code>scipy</code>\u200b\u548c\u200b<code>timm</code>\u3002</p> <pre><code>import os\nfrom pathlib import Path\n\nimport torch\nfrom timm.models import vit_base_patch16_224\nfrom titans.utils import barrier_context\nfrom torchvision import datasets, transforms\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import TorchDDPPlugin\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.nn.lr_scheduler import LinearWarmupLR\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#2","title":"\u6b65\u9aa4\u200b 2. \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883","text":"<p>\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5feb\u901f\u200b\u6f14\u793a\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>launch_from_torch</code>\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b Launch Colossal-AI \u200b\u4f7f\u7528\u200b\u5176\u4ed6\u200b\u521d\u59cb\u5316\u200b\u65b9\u6cd5\u200b\u3002</p> <pre><code># \u200b\u521d\u59cb\u5316\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\nparser = colossalai.get_default_parser()\nargs = parser.parse_args()\n\n# launch from torch\ncolossalai.launch_from_torch(config=dict())\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#3","title":"\u6b65\u9aa4\u200b 3. \u200b\u521b\u5efa\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6","text":"<p>\u200b\u6784\u5efa\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u3001\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3001\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u6574\u5668\u200b\u548c\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b\u3002\u200b\u6ce8\u610f\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u8def\u5f84\u200b\u4ece\u200b\u73af\u5883\u53d8\u91cf\u200b<code>DATA</code>\u200b\u83b7\u5f97\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>export DATA=/path/to/data</code> \u200b\u6216\u200b <code>Path(os.environ['DATA'])</code> \u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\u8bbe\u7f6e\u200b\u8def\u5f84\u200b\u3002\u200b\u6570\u636e\u200b\u5c06\u4f1a\u200b\u88ab\u200b\u81ea\u52a8\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u8be5\u200b\u8def\u5f84\u200b\u3002</p> <pre><code># define the constants\nNUM_EPOCHS = 2\nBATCH_SIZE = 128\n# build model\nmodel = vit_base_patch16_224(drop_rate=0.1)\n\n# build dataloader\ntrain_dataset = datasets.Caltech101(\n    root=Path(os.environ['DATA']),\n    download=True,\n    transform=transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        Gray2RGB(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                                [0.5, 0.5, 0.5])\n    ]))\n\n# build optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=0.1)\n\n# build loss\ncriterion = torch.nn.CrossEntropyLoss()\n\n# lr_scheduler\nlr_scheduler = LinearWarmupLR(optimizer, warmup_steps=50, total_steps=NUM_EPOCHS)\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#4-amp","title":"\u6b65\u9aa4\u200b 4. \u200b\u63d2\u5165\u200b AMP","text":"<p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b MixedPrecision \u200b\u5bf9\u8c61\u200b\uff08\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff09\u200b\u53ca\u200b torchDDPPlugin \u200b\u5bf9\u8c61\u200b\uff0c\u200b\u8c03\u7528\u200b <code>colossalai.boost</code> \u200b\u5c06\u200b\u6240\u6709\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u8f6c\u4e3a\u200b\u4e3a\u200b FP16 \u200b\u6a21\u5f0f\u200b.</p> <pre><code>plugin = TorchDDPPlugin()\ntrain_dataloader = plugin.prepare_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nbooster = Booster(mixed_precision='fp16', plugin=plugin)\n\n# if you need to customize the config, do like this\n# &gt;&gt;&gt; from colossalai.mixed_precision import FP16TorchMixedPrecision\n# &gt;&gt;&gt; mixed_precision = FP16TorchMixedPrecision(\n# &gt;&gt;&gt;     init_scale=2.**16,\n# &gt;&gt;&gt;     growth_factor=2.0,\n# &gt;&gt;&gt;     backoff_factor=0.5,\n# &gt;&gt;&gt;     growth_interval=2000)\n# &gt;&gt;&gt; plugin = TorchDDPPlugin()\n# &gt;&gt;&gt; booster = Booster(mixed_precision=mixed_precision, plugin=plugin)\n\n# boost model, optimizer, criterion, dataloader, lr_scheduler\nmodel, optimizer, criterion, dataloader, lr_scheduler = booster.boost(model, optimizer, criterion, dataloader, lr_scheduler)\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#5-booster","title":"\u6b65\u9aa4\u200b 5. \u200b\u4f7f\u7528\u200b booster \u200b\u8bad\u7ec3","text":"<p>\u200b\u4f7f\u7528\u200b booster \u200b\u6784\u5efa\u200b\u4e00\u4e2a\u200b\u666e\u901a\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u3002</p> <pre><code>model.train()\nfor epoch in range(NUM_EPOCHS):\n    for img, label in enumerate(train_dataloader):\n        img = img.cuda()\n        label = label.cuda()\n        optimizer.zero_grad()\n        output = model(img)\n        loss = criterion(output, label)\n        booster.backward(loss, optimizer)\n        optimizer.step()\n    lr_scheduler.step()\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/mixed_precision_training_with_booster/#6","title":"\u6b65\u9aa4\u200b 6. \u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u811a\u672c","text":"<p>\u200b\u4f7f\u7528\u200b\u4e0b\u5217\u200b\u547d\u4ee4\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u6539\u53d8\u200b <code>--nproc_per_node</code> \u200b\u4ee5\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u6570\u91cf\u200b\u7684\u200b GPU\u3002</p> <pre><code>colossalai run --nproc_per_node 1 train.py\n</code></pre>"},{"location":"4-%E7%89%B9%E7%82%B9/nvme_offload/","title":"NVMe offload","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b: - \u200b\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b (ZeRO)</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b</p> <ul> <li>ZeRO-Offload: Democratizing Billion-Scale Model Training</li> <li>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</li> </ul>"},{"location":"4-%E7%89%B9%E7%82%B9/nvme_offload/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u5177\u6709\u200b<code>N</code>\u200b\u4e2a\u200b\u53c2\u6570\u200b\uff0c\u200b\u5728\u200b\u4f7f\u7528\u200b Adam \u200b\u65f6\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5177\u6709\u200b<code>8N</code>\u200b\u4e2a\u200b\u53c2\u6570\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u5341\u4ebf\u200b\u89c4\u6a21\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u81f3\u5c11\u200b\u9700\u8981\u200b 32 GB \u200b\u5185\u5b58\u200b\u3002 GPU\u200b\u663e\u5b58\u200b\u9650\u5236\u200b\u4e86\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\uff0c\u200b\u8fd9\u200b\u79f0\u4e3a\u200bGPU\u200b\u663e\u5b58\u200b\u5899\u200b\u3002\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b offload \u200b\u5230\u200b\u78c1\u76d8\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u7a81\u7834\u200b GPU \u200b\u5185\u5b58\u200b\u5899\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7528\u6237\u200b\u53cb\u597d\u200b\u4e14\u200b\u9ad8\u6548\u200b\u7684\u200b\u5f02\u6b65\u200b Tensor I/O \u200b\u5e93\u200b\uff1aTensorNVMe\u3002\u200b\u6709\u200b\u4e86\u200b\u8fd9\u4e2a\u200b\u5e93\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u7b80\u5355\u200b\u5730\u200b\u5b9e\u73b0\u200b NVMe offload\u3002</p> <p>\u200b\u8be5\u5e93\u200b\u4e0e\u200b\u5404\u79cd\u200b\u78c1\u76d8\u200b\uff08HDD\u3001SATA SSD \u200b\u548c\u200b NVMe SSD\uff09\u200b\u517c\u5bb9\u200b\u3002\u200b\u7531\u4e8e\u200b HDD \u200b\u6216\u200b SATA SSD \u200b\u7684\u200b I/O \u200b\u5e26\u5bbd\u200b\u8f83\u200b\u4f4e\u200b\uff0c\u200b\u5efa\u8bae\u200b\u4ec5\u200b\u5728\u200b NVMe \u200b\u78c1\u76d8\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u6b64\u5e93\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f18\u5316\u200b\u53c2\u6570\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u4f18\u5316\u200b\u8fc7\u7a0b\u200b\u5206\u4e3a\u200b\u4e09\u4e2a\u200b\u9636\u6bb5\u200b\uff1a\u200b\u8bfb\u53d6\u200b\u3001\u200b\u8ba1\u7b97\u200b\u548c\u200b offload\u3002\u200b\u6211\u4eec\u200b\u4ee5\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6267\u884c\u200b\u4f18\u5316\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u4ee5\u200b\u91cd\u53e0\u200b\u8ba1\u7b97\u200b\u548c\u200b I/O\u3002</p> \u200b\u4f18\u5316\u200b\u8fc7\u7a0b"},{"location":"4-%E7%89%B9%E7%82%B9/nvme_offload/#_2","title":"\u4f7f\u7528","text":"<p>\u200b\u9996\u5148\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u60a8\u200b\u5b89\u88c5\u200b\u4e86\u200b TensorNVMe:</p> <pre><code>pip install packaging\npip install tensornvme\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u4e3a\u200b Adam (CPUAdam \u200b\u548c\u200b HybridAdam) \u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u7684\u200b NVMe offload\u3002</p> <pre><code>from colossalai.nn.optimizer import CPUAdam, HybridAdam\n\noptimizer = HybridAdam(model.parameters(), lr=1e-3, nvme_offload_fraction=1.0, nvme_offload_dir='./')\n</code></pre> <p><code>nvme_offload_fraction</code> \u200b\u662f\u200b\u8981\u200b offload \u200b\u5230\u200b NVMe \u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u7684\u200b\u6bd4\u4f8b\u200b\u3002 <code>nvme_offload_dir</code> \u200b\u662f\u200b\u4fdd\u5b58\u200b NVMe offload \u200b\u6587\u4ef6\u200b\u7684\u200b\u76ee\u5f55\u200b\u3002\u200b\u5982\u679c\u200b <code>nvme_offload_dir</code> \u200b\u4e3a\u200b <code>None</code>\uff0c\u200b\u5c06\u200b\u4f7f\u7528\u200b\u968f\u673a\u200b\u4e34\u65f6\u200b\u76ee\u5f55\u200b\u3002</p> <p>\u200b\u5b83\u200b\u4e0e\u200b ColossalAI \u200b\u4e2d\u200b\u7684\u200b\u6240\u6709\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\u517c\u5bb9\u200b\u3002</p> <p>\u26a0 \u200b\u5b83\u200b\u53ea\u4f1a\u200b\u5378\u8f7d\u200b\u5728\u200b CPU \u200b\u4e0a\u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u5b83\u200b\u53ea\u4f1a\u200b\u5f71\u54cd\u200b CPU \u200b\u8bad\u7ec3\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b\u5378\u8f7d\u200b\u7684\u200b Zero/Gemini\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/nvme_offload/#examples","title":"Examples","text":"<p>\u200b\u9996\u5148\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ece\u200b\u4e24\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u4f8b\u5b50\u200b\u5f00\u59cb\u200b -- \u200b\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u65b9\u6cd5\u200b\u8bad\u7ec3\u200b GPT\u3002\u200b\u8fd9\u4e9b\u200b\u4f8b\u5b50\u200b\u4f9d\u8d56\u200b<code>transformers</code>\u3002</p> <p>\u200b\u6211\u4eec\u200b\u9996\u5148\u200b\u5e94\u8be5\u200b\u5b89\u88c5\u200b\u4f9d\u8d56\u200b\uff1a</p> <pre><code>pip install psutil transformers\n</code></pre> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bfc\u5165\u200b\u5fc5\u8981\u200b\u7684\u200b\u5305\u200b\u548c\u200b\u6a21\u5757\u200b\uff1a</p> <pre><code>import os\nimport time\nfrom typing import Dict, Optional\nimport psutil\nimport torch\nimport torch.nn as nn\nfrom transformers.models.gpt2.configuration_gpt2 import GPT2Config\nfrom transformers.models.gpt2.modeling_gpt2 import GPT2LMHeadModel\nimport colossalai\nfrom colossalai.nn.optimizer import HybridAdam\nfrom colossalai.utils.model.colo_init_context import ColoInitContext\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import GeminiPlugin\n</code></pre> <p>\u200b\u7136\u540e\u200b\u6211\u4eec\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff1a</p> <pre><code>class GPTLMLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss_fn = nn.CrossEntropyLoss()\n    def forward(self, logits, labels):\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        # Flatten the tokens\n        return self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)),\n                            shift_labels.view(-1))\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u5b9a\u4e49\u200b\u4e00\u4e9b\u200b\u5de5\u5177\u200b\u51fd\u6570\u200b\uff0c\u200b\u7528\u6765\u200b\u751f\u6210\u200b\u968f\u673a\u200b\u6570\u636e\u200b\u3001\u200b\u8ba1\u7b97\u200b\u6a21\u578b\u200b\u53c2\u200b\u6570\u91cf\u200b\u548c\u200b\u83b7\u53d6\u200b\u5f53\u524d\u200b\u8fdb\u7a0b\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\uff1a</p> <pre><code>def get_data(batch_size: int, seq_len: int,\n             vocab_size: int, device: Optional[str] = None) -&gt; Dict[str, torch.Tensor]:\n    device = torch.cuda.current_device() if device is None else device\n    input_ids = torch.randint(vocab_size, (batch_size, seq_len),\n                              device=device)\n    attn_mask = torch.ones_like(input_ids)\n    return dict(input_ids=input_ids, attention_mask=attn_mask)\ndef get_model_numel(model: nn.Module) -&gt; int:\n    return sum(p.numel() for p in model.parameters())\ndef get_mem_usage() -&gt; int:\n    proc = psutil.Process(os.getpid())\n    return proc.memory_info().rss\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u9996\u5148\u200b\u5c1d\u8bd5\u200b\u5728\u200b CPU \u200b\u4e0a\u200b\u8bad\u7ec3\u200b GPT \u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>def train_cpu(nvme_offload_fraction: float = 0.0):\n    config = GPT2Config()\n    model = GPT2LMHeadModel(config)\n    criterion = GPTLMLoss()\n    optimizer = HybridAdam(model.parameters(), nvme_offload_fraction=nvme_offload_fraction)\n    print(f'Model numel: {get_model_numel(model) / 1024**3:.3f} B')\n    start = time.time()\n    for step in range(3):\n        data = get_data(4, 128, config.vocab_size, device='cpu')\n        outputs = model(**data)\n        loss = criterion(outputs.logits, data['input_ids'])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        print(f'[{step}] loss: {loss.item():.3f}')\n    print(f'Time: {time.time() - start:.3f} s')\n    print(f'Mem usage: {get_mem_usage() / 1024**2:.3f} MB')\n</code></pre> <p>\u200b\u4e0d\u200b\u4f7f\u7528\u200b NVME \u200b\u5378\u8f7d\u200b\uff1a</p> <pre><code>train_cpu(0.0)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u5f97\u5230\u200b\u5982\u4e0b\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code>Model numel: 0.116 B\n[0] loss: 10.953\n[1] loss: 10.974\n[2] loss: 10.965\nTime: 7.739 s\nMem usage: 5966.445 MB\n</code></pre> <p>\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b\uff08\u200b\u5168\u91cf\u200b\uff09 NVME \u200b\u5378\u8f7d\u200b\uff1a</p> <pre><code>train_cpu(1.0)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u5f97\u5230\u200b\uff1a</p> <pre><code>Model numel: 0.116 B\n[0] loss: 10.951\n[1] loss: 10.994\n[2] loss: 10.984\nTime: 8.527 s\nMem usage: 4968.016 MB\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200b\u6709\u200b1.16\u200b\u4ebf\u200b\u53c2\u6570\u200b\u7684\u200b GPT2-S \u200b\u6765\u8bf4\u200b\uff0c\u200b\u5b83\u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5927\u7ea6\u200b\u9700\u8981\u200b\u5360\u7528\u200b 0.928 GB \u200b\u5185\u5b58\u200b\u3002NVME \u200b\u5378\u8f7d\u200b\u8282\u7701\u200b\u4e86\u200b\u5927\u7ea6\u200b 998 MB \u200b\u5185\u5b58\u200b\uff0c\u200b\u7b26\u5408\u200b\u6211\u4eec\u200b\u7684\u200b\u9884\u671f\u200b\u3002</p> <p>\u200b\u7136\u540e\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u7528\u200b Gemini \u200b\u6765\u200b\u8bad\u7ec3\u200b GPT \u200b\u6a21\u578b\u200b\u3002\u200b\u653e\u7f6e\u200b\u7b56\u7565\u200b\u5e94\u8be5\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>\"auto\"</code>\u3001 <code>\"cpu\"</code> \u200b\u6216\u200b <code>\"const\"</code>\u3002</p> <pre><code>def train_gemini_cpu(nvme_offload_fraction: float = 0.0):\n    colossalai.launch_from_torch({})\n    config = GPT2Config()\n    with ColoInitContext(device=torch.cuda.current_device()):\n        model = GPT2LMHeadModel(config)\n    criterion = GPTLMLoss()\n    optimizer = HybridAdam(model.parameters(), nvme_offload_fraction=nvme_offload_fraction)\n    print(f'Model numel: {get_model_numel(model) / 1024**3:.3f} B')\n\n    plugin = GeminiPlugin(\n                strict_ddp_mode=True,\n                device=torch.cuda.current_device(),\n                placement_policy='cpu',\n                pin_memory=True,\n                hidden_dim=config.n_embd,\n                initial_scale=2**5\n                )\n    booster = Booster(plugin)\n    model, optimizer, criterion, _* = booster.boost(model, optimizer, criterion)\n\n    start = time.time()\n    for step in range(3):\n        data = get_data(4, 128, config.vocab_size)\n        outputs = model(**data)\n        loss = criterion(outputs.logits, data['input_ids'])\n        booster.backward(loss, optimizer)\n        optimizer.step()\n        optimizer.zero_grad()\n        print(f'[{step}] loss: {loss.item():.3f}')\n    print(f'Time: {time.time() - start:.3f} s')\n    print(f'Mem usage: {get_mem_usage() / 1024**2:.3f} MB')\n</code></pre> <p>\u200b\u4e0d\u200b\u4f7f\u7528\u200b NVME \u200b\u5378\u8f7d\u200b\uff1a</p> <pre><code>train_gemini_cpu(0.0)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u5f97\u5230\u200b\uff1a</p> <pre><code>Model numel: 0.116 B\nsearching chunk configuration is completed in 0.27 s.\nused number: 118.68 MB, wasted number: 0.75 MB\ntotal wasted percentage is 0.63%\n[0] loss: 10.953\n[1] loss: 10.938\n[2] loss: 10.969\nTime: 2.997 s\nMem usage: 5592.227 MB\n</code></pre> <p>\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b\uff08\u200b\u5168\u91cf\u200b\uff09 NVME \u200b\u5378\u8f7d\u200b\uff1a</p> <pre><code>train_gemini_cpu(1.0)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u5f97\u5230\u200b\uff1a</p> <pre><code>Model numel: 0.116 B\nsearching chunk configuration is completed in 0.27 s.\nused number: 118.68 MB, wasted number: 0.75 MB\ntotal wasted percentage is 0.63%\n[0] loss: 10.953\n[1] loss: 10.938\n[2] loss: 10.969\nTime: 3.691 s\nMem usage: 5298.344 MB\n</code></pre> <p>NVME \u200b\u5378\u8f7d\u200b\u8282\u7701\u200b\u4e86\u200b\u5927\u7ea6\u200b 294 MB \u200b\u5185\u5b58\u200b\u3002\u200b\u6ce8\u610f\u200b\u4f7f\u7528\u200b Gemini \u200b\u7684\u200b <code>pin_memory</code> \u200b\u529f\u80fd\u200b\u53ef\u4ee5\u200b\u52a0\u901f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4f46\u662f\u200b\u4f1a\u200b\u589e\u52a0\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u3002\u200b\u6240\u4ee5\u200b\u8fd9\u4e2a\u200b\u7ed3\u679c\u200b\u4e5f\u200b\u662f\u200b\u7b26\u5408\u200b\u6211\u4eec\u200b\u9884\u671f\u200b\u7684\u200b\u3002\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u5173\u95ed\u200b <code>pin_memory</code>\uff0c\u200b\u6211\u4eec\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u89c2\u5bdf\u200b\u5230\u200b\u5927\u7ea6\u200b 900 MB \u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u4e0b\u964d\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/nvme_offload/#api","title":"API \u200b\u53c2\u8003","text":"<p>{{ autodoc:colossalai.nn.optimizer.HybridAdam }}</p> <p>{{ autodoc:colossalai.nn.optimizer.CPUAdam }}</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/","title":"\u6d41\u6c34\u200b\u5e76\u884c","text":"<p>\u200b\u4f5c\u8005\u200b: Guangyang Lu, Hongxin Liu, Yongbin Li, Mingyan Jiang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - \u200b\u5e76\u884c\u200b\u6280\u672f\u200b - Booster API - Shardformer - Booster \u200b\u63d2\u4ef6\u200b</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - \u200b\u4f7f\u7528\u200bpipeline\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u5fae\u8c03\u200bBert</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training - Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM - GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#_2","title":"\u5feb\u901f\u200b\u9884\u89c8","text":"<p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u5c06\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u3002\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b, \u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b NVIDIA \u200b\u63a8\u51fa\u200b\u7684\u200b 1F1B \u200b\u6d41\u6c34\u7ebf\u200b\u3002\u200b\u7531\u4e8e\u200b\u5728\u200b\u672c\u4f8b\u200b\u4e2d\u200b, \u200b\u4f7f\u7528\u200b ViT \u200b\u548c\u200b ImageNet \u200b\u592a\u8fc7\u200b\u5e9e\u5927\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b Bert \u200b\u548c\u200b Glue\u200b\u6570\u636e\u200b\u96c6\u200b \u200b\u4e3a\u4f8b\u200b.</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#_3","title":"\u76ee\u5f55","text":"<p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b:</p> <ol> <li>\u200b\u4ecb\u7ecd\u200b 1F1B \u200b\u6d41\u6c34\u7ebf\u200b\uff1b</li> <li>\u200b\u4f7f\u7528\u200b\u975e\u200b\u4ea4\u9519\u200b\u548c\u200b\u4ea4\u9519\u200b schedule\uff1b</li> <li>\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5fae\u8c03\u200b Bert</li> </ol>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#1f1b","title":"\u8ba4\u8bc6\u200b 1F1B \u200b\u6d41\u6c34\u7ebf","text":"<p>\u200b\u9996\u5148\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5411\u200b\u60a8\u200b\u4ecb\u7ecd\u200b GPipe\uff0c\u200b\u4ee5\u4fbf\u200b\u60a8\u200b\u66f4\u597d\u200b\u5730\u200b\u4e86\u89e3\u200b\u3002</p> \u200b\u56fe\u200b1: GPipe\uff0c\u200b\u6765\u81ea\u200b\u8bba\u6587\u200b Megatron-LM \u3002 <p>\u200b\u6b63\u5982\u200b\u4f60\u200b\u6240\u200b\u770b\u5230\u200b\u7684\u200b\uff0c\u200b\u5bf9\u4e8e\u200b GPipe\uff0c\u200b\u53ea\u6709\u200b\u5f53\u200b\u4e00\u4e2a\u200b\u6279\u6b21\u200b\u4e2d\u200b\u6240\u6709\u200b microbatches \u200b\u7684\u200b\u524d\u200b\u5411\u200b\u8ba1\u7b97\u200b\u5b8c\u6210\u200b\u540e\u200b\uff0c\u200b\u624d\u200b\u4f1a\u200b\u6267\u884c\u200b\u540e\u200b\u5411\u200b\u8ba1\u7b97\u200b\u3002</p> <p>\u200b\u4e00\u822c\u6765\u8bf4\u200b\uff0c1F1B\uff08\u200b\u4e00\u4e2a\u200b\u524d\u5411\u200b\u901a\u9053\u200b\u548c\u200b\u4e00\u4e2a\u200b\u540e\u200b\u5411\u200b\u901a\u9053\u200b\uff09\u200b\u6bd4\u200b GPipe \uff08\u200b\u5728\u200b\u5185\u5b58\u200b\u6216\u200b\u5185\u5b58\u200b\u548c\u200b\u65f6\u95f4\u200b\u65b9\u9762\u200b\uff09\u200b\u66f4\u200b\u6709\u6548\u7387\u200b\u30021F1B \u200b\u6d41\u6c34\u7ebf\u200b\u6709\u200b\u4e24\u4e2a\u200b schedule \uff0c\u200b\u975e\u200b\u4ea4\u9519\u200b\u5f0f\u200b\u548c\u200b\u4ea4\u9519\u200b\u5f0f\u200b\uff0c\u200b\u56fe\u793a\u200b\u5982\u4e0b\u200b\u3002</p> Figure2: \u200b\u56fe\u7247\u200b\u6765\u81ea\u200b\u8bba\u6587\u200b Megatron-LM \u3002\u200b\u4e0a\u9762\u200b\u7684\u200b\u90e8\u5206\u200b\u663e\u793a\u200b\u4e86\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u975e\u200b\u4ea4\u9519\u200b schedule\uff0c\u200b\u5e95\u90e8\u200b\u663e\u793a\u200b\u7684\u200b\u662f\u200b\u4ea4\u9519\u200b\u7684\u200b schedule\u3002"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#schedule","title":"\u975e\u200b\u4ea4\u9519\u200b Schedule","text":"<p>\u200b\u975e\u200b\u4ea4\u9519\u200b\u5f0f\u200b schedule \u200b\u53ef\u200b\u5206\u4e3a\u200b\u4e09\u4e2a\u200b\u9636\u6bb5\u200b\u3002\u200b\u7b2c\u4e00\u9636\u6bb5\u200b\u662f\u200b\u70ed\u8eab\u200b\u9636\u6bb5\u200b\uff0c\u200b\u5904\u7406\u5668\u200b\u8fdb\u884c\u200b\u4e0d\u540c\u200b\u6570\u91cf\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u8ba1\u7b97\u200b\u3002\u200b\u5728\u200b\u63a5\u4e0b\u6765\u200b\u7684\u200b\u9636\u6bb5\u200b\uff0c\u200b\u5904\u7406\u5668\u200b\u8fdb\u884c\u200b\u4e00\u6b21\u200b\u524d\u5411\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u7136\u540e\u200b\u662f\u200b\u4e00\u6b21\u200b\u540e\u200b\u5411\u200b\u8ba1\u7b97\u200b\u3002\u200b\u5904\u7406\u5668\u200b\u5c06\u200b\u5728\u200b\u6700\u540e\u200b\u4e00\u4e2a\u200b\u9636\u6bb5\u200b\u5b8c\u6210\u200b\u540e\u200b\u5411\u200b\u8ba1\u7b97\u200b\u3002</p> <p>\u200b\u8fd9\u79cd\u200b\u6a21\u5f0f\u200b\u6bd4\u200b GPipe \u200b\u66f4\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5b83\u200b\u9700\u8981\u200b\u548c\u200b GPipe \u200b\u4e00\u6837\u200b\u7684\u200b\u65f6\u95f4\u200b\u6765\u200b\u5b8c\u6210\u200b\u4e00\u8f6e\u200b\u8ba1\u7b97\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#schedule_1","title":"\u4ea4\u9519\u200b Schedule","text":"<p>\u200b\u8fd9\u4e2a\u200b schedule \u200b\u8981\u6c42\u200bmicrobatches\u200b\u7684\u200b\u6570\u91cf\u200b\u662f\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\u7684\u200b\u6574\u6570\u500d\u200b\u3002</p> <p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b schedule \u200b\u4e2d\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u53ef\u4ee5\u200b\u5bf9\u200b\u591a\u4e2a\u200b\u5c42\u200b\u7684\u200b\u5b50\u96c6\u200b\uff08\u200b\u79f0\u4e3a\u200b\u6a21\u578b\u200b\u5757\u200b\uff09\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4e00\u4e2a\u200b\u8fde\u7eed\u200b\u5c42\u200b\u7684\u200b\u96c6\u5408\u200b\u3002\u200b\u5177\u4f53\u200b\u6765\u770b\u200b\uff0c\u200b\u4e4b\u524d\u200b\u8bbe\u5907\u200b1\u200b\u62e5\u6709\u200b\u5c42\u200b1-4\uff0c\u200b\u8bbe\u5907\u200b2\u200b\u62e5\u6709\u200b\u5c42\u200b5-8\uff0c\u200b\u4ee5\u6b64\u7c7b\u63a8\u200b\uff1b\u200b\u4f46\u200b\u73b0\u5728\u200b\u8bbe\u5907\u200b1\u200b\u6709\u5c42\u200b1,2,9,10\uff0c\u200b\u8bbe\u5907\u200b2\u200b\u6709\u5c42\u200b3,4,11,12\uff0c\u200b\u4ee5\u6b64\u7c7b\u63a8\u200b\u3002 \u200b\u5728\u200b\u8be5\u200b\u6a21\u5f0f\u200b\u4e0b\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u4e0a\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u90fd\u200b\u88ab\u200b\u5206\u914d\u200b\u5230\u200b\u591a\u4e2a\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\u7684\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u8f83\u200b\u5c11\u200b\u3002</p> <p>\u200b\u8fd9\u79cd\u200b\u6a21\u5f0f\u200b\u65e2\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\u53c8\u200b\u8282\u7701\u65f6\u95f4\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#colossal-ai","title":"Colossal-AI\u200b\u4e2d\u200b\u7684\u200b\u5b9e\u73b0","text":"<p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4f9d\u8d56\u4e8e\u200b <code>scheduler</code> \u200b\u548c\u200b <code>Shardformer</code>\u3002\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u975e\u200b\u4ea4\u9519\u200b\u7684\u200b\uff08<code>OneForwardOneBackwardSchedule</code>\uff09\u200b\u548c\u200b\u4ea4\u9519\u200b\u7684\u200b\uff08<code>InterleavedSchedule</code>\uff09\u200b\u4e24\u79cd\u200b\u8c03\u5ea6\u200b\u65b9\u5f0f\u200b\u3002\u200b\u800c\u200b Shardformer \u200b\u5b9e\u73b0\u200b\u4e86\u200b\u5bf9\u6a21\u578b\u200b\u7684\u200b\u5c42\u200b\u5206\u5272\u200b\uff0c\u200b\u5e76\u200b\u66ff\u6362\u200b\u4e86\u200b\u6a21\u578b\u200b\u7684\u200b <code>forward</code> \u200b\u51fd\u6570\u200b\uff0c\u200b\u4f7f\u200b\u5176\u200b\u4e0e\u200b\u8c03\u5ea6\u200b\u5668\u200b\u517c\u5bb9\u200b\u3002</p> <p>\u200b\u5728\u200b Colossal-AI \u200b\u4e2d\u200b\uff0c<code>HybridParallelPlugin</code> \u200b\u5c01\u88c5\u200b\u4e86\u200b\u6d41\u6c34\u7ebf\u200b\u6267\u884c\u200b\u7b56\u7565\u200b\u3002\u200b\u5b83\u200b\u7ba1\u7406\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u901a\u4fe1\u200b\u7ec4\u548c\u200b\u4e00\u4e2a\u200b <code>scheduler</code>\u3002\u200b\u5f53\u200b\u4f7f\u7528\u200b\u6b64\u200b\u63d2\u4ef6\u200b\u589e\u5f3a\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u6a21\u578b\u200b\u7684\u200b\u5c42\u200b\u5c06\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b <code>shardformer.optimize</code> \u200b\u51fd\u6570\u200b\u8fdb\u884c\u200b\u5206\u5272\u200b\uff0c\u200b\u7136\u540e\u200b\u8c03\u7528\u200b <code>execute_pipeline</code> \u200b\u4f7f\u7528\u200b <code>scheduler</code> \u200b\u6765\u200b\u5206\u522b\u200b\u6267\u884c\u200b\u6a21\u578b\u200b\u7684\u200b\u5404\u4e2a\u200b\u90e8\u5206\u200b\u3002 <code>HybridParallelPlugin</code>\u200b\u6682\u65f6\u200b\u53ea\u200b\u652f\u6301\u200b<code>OneForwardOneBackwardSchedule</code>, <code>InterleavedSchedule</code>\u200b\u5c06\u4f1a\u200b\u5728\u200b\u4e0d\u4e45\u200b\u540e\u200b\u652f\u6301\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b <code>HybridParallelPlugin</code> \u200b\u7684\u200b\u53c2\u6570\u200b\u6765\u81ea\u200b\u5b9a\u4e49\u200b\u60a8\u200b\u7684\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u4f7f\u7528\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b<code>HybridParallelPlugin</code>\u200b\u7684\u200b\u4f7f\u7528\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/pipeline_parallel/#bert","title":"\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5fae\u8c03\u200b Bert\u200b\u6a21\u578b","text":"<p>\u200b\u9996\u5148\u200b\u6211\u4eec\u200b\u5b9a\u4e49\u200b\u597d\u200b\u9700\u8981\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\uff0c\u200b\u5305\u62ec\u200b<code>model</code>, <code>dataloader</code>, <code>optimizer</code>, <code>lr_scheduler</code>, <code>criterion</code> \u200b\u7b49\u200b: <pre><code>import argparse\nfrom typing import Callable, List, Union\n\nimport torch\nimport torch.nn as nn\nfrom data import GLUEDataBuilder\nfrom torch.optim import Adam, Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler as LRScheduler\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import (\n    AlbertForSequenceClassification,\n    AutoConfig,\n    BertForSequenceClassification,\n    get_linear_schedule_with_warmup,\n)\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import HybridParallelPlugin\nfrom colossalai.cluster import DistCoordinator\nfrom colossalai.nn.optimizer import HybridAdam\n\n# Define some config\nNUM_EPOCHS = 3\nBATCH_SIZE = 32\nLEARNING_RATE = 2.4e-5\nWEIGHT_DECAY = 0.01\nWARMUP_FRACTION = 0.1\n\ncoordinator = DistCoordinator()\n\ndef move_to_cuda(batch):\n    return {k: v.cuda() for k, v in batch.items()}\n\n# Define 'criterion' function with two inputs, which will be passed to 'execute_pipeline'.\ndef _criterion(outputs, inputs):\n    return outputs.loss\n\n# Define optimizer\nlr = LEARNING_RATE\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": WEIGHT_DECAY,\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\n\noptimizer = HybridAdam(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n\n\n# Define lr_scheduler\ntotal_steps = len(train_dataloader) * NUM_EPOCHS\nnum_warmup_steps = int(WARMUP_FRACTION * total_steps)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=total_steps,\n)\n\n\n# Define Bert model\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=cfg).cuda()\n\n# Define a dataloader\ndata_builder = GLUEDataBuilder(model_name,\n                                plugin,\n                                args.task,\n                                train_batch_size=BATCH_SIZE,\n                                eval_batch_size=BATCH_SIZE)\ntrain_dataloader = data_builder.train_dataloader()\n</code></pre></p> <p>\u200b\u4f7f\u7528\u200b<code>HybridParallelPlugin</code>\u200b\u521d\u59cb\u5316\u200b\u4e00\u4e2a\u200bbooster. <pre><code>plugin = HybridParallelPlugin(tp_size=1,\n                                pp_size=2,\n                                num_microbatches=None,\n                                microbatch_size=1,\n                                enable_all_optimization=True,\n                                zero_stage=1,\n                                precision='fp16',\n                                initial_scale=1)\nbooster = Booster(plugin=plugin)\n</code></pre></p> <p>\u200b\u4f7f\u7528\u200b<code>booster</code>\u200b\u5c06\u200b\u4f18\u5316\u200b\u7279\u6027\u200b\u6ce8\u5165\u200b\u5230\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u4e2d\u200b\u3002 <pre><code>model, optimizer, _criterion, _, lr_scheduler = booster.boost(model,\n                                                                optimizer,\n                                                                criterion=_criterion,\n                                                                lr_scheduler=lr_scheduler)\n</code></pre></p> <p>\u200b\u6700\u540e\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b <pre><code># Define a train function\ndef train_epoch(epoch: int, model: nn.Module, optimizer: Optimizer, _criterion: Callable, lr_scheduler: LRScheduler,\n                train_dataloader: DataLoader, booster: Booster, coordinator: DistCoordinator):\n\n    is_pp_last_stage = booster.plugin.stage_manager.is_last_stage()\n    total_step = len(train_dataloader)\n\n    model.train()\n    optimizer.zero_grad()\n    # convert train_dataloader to a iterator\n    train_dataloader_iter = iter(train_dataloader)\n    with tqdm(range(total_step),\n              desc=f'Epoch [{epoch + 1}/{NUM_EPOCHS}]',\n              disable=not (is_pp_last_stage)) as pbar:\n        # Forward pass\n        for _ in pbar:\n            outputs = booster.execute_pipeline(train_dataloader_iter,\n                                                model,\n                                                _criterion,\n                                                optimizer,\n                                                return_loss=True,\n                                                return_outputs=True)\n            # Backward and optimize\n            if is_pp_last_stage:\n                loss = outputs['loss']\n                pbar.set_postfix({'loss': loss.item()})\n\n            optimizer.step()\n            optimizer.zero_grad()\n            lr_scheduler.step()\n\n# Train model\nfor epoch in range(NUM_EPOCHS):\n    train_epoch(epoch, model, optimizer, _criterion, lr_scheduler, train_dataloader, booster, coordinator)\n</code></pre></p> <p>\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b <code>2</code> \u200b\u4e2a\u200b\u6d41\u6c34\u200b\u6bb5\u200b\uff0c\u200b\u5e76\u4e14\u200b batch \u200b\u5c06\u200b\u88ab\u200b\u5207\u200b\u5206\u4e3a\u200b <code>1</code> \u200b\u4e2a\u200b micro batches\u3002\uff08\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u90fd\u200b\u53ef\u200b\u6839\u636e\u200b\u5b9e\u9645\u200b\u60c5\u51b5\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u5408\u9002\u200b\u7684\u200b\u503c\u200b\uff09</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/","title":"Shardformer","text":"<p>Author: Baizhou Zhang, Bin Jia</p> <p>\u200b\u9884\u5907\u200b\u77e5\u8bc6\u200b - \u200b\u5e76\u884c\u200b\u6280\u672f\u200b - Booster API - Booster \u200b\u63d2\u4ef6\u200b</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - \u200b\u4f7f\u7528\u200bShardformer\u200b\u8fdb\u884c\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b - \u200b\u901a\u8fc7\u200bHybridParallelPlugin\u200b\u4f7f\u7528\u200bShardformer</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM - GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism - FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning - Sequence Parallelism: Long Sequence Training from System Perspective - Reducing Activation Recomputation in Large Transformer Models</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u5728\u200b\u8bad\u7ec3\u200bLLaMa-2 70B\u200b\u6216\u200bOPT 175B\u200b\u7b49\u200b\u5927\u578b\u200bTransformer\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u6ee1\u8db3\u200bGPU\u200b\u5185\u5b58\u200b\u7684\u200b\u9650\u5236\u200b\uff0c\u200b\u5c06\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u5212\u5206\u200b\u4e3a\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u5206\u7247\u200b\u7684\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u65b9\u6cd5\u200b\uff08\u200b\u5305\u62ec\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\uff09\u200b\u662f\u200b\u5fc5\u4e0d\u53ef\u5c11\u200b\u7684\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u4e0d\u200b\u719f\u6089\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u7684\u200b\u7528\u6237\u200b\u6765\u8bf4\u200b\uff0c\u200b\u624b\u52a8\u200b\u526a\u5207\u200b\u6a21\u578b\u200b\u5e76\u200b\u91cd\u5199\u200b\u5176\u524d\u200b\u5411\u200b/\u200b\u53cd\u5411\u200b\u903b\u8f91\u200b\u53ef\u80fd\u200b\u5f88\u200b\u56f0\u96be\u200b\u3002\u200b\u4e0e\u6b64\u540c\u65f6\u200b\uff0cHuggingface transformers\u200b\u5f00\u6e90\u200b\u5e93\u200b\u6b63\u5728\u200b\u9010\u6e10\u200b\u6210\u4e3a\u200b\u7528\u6237\u200b\u6a21\u578b\u200b\u6765\u6e90\u200b\u7684\u200b\u9996\u9009\u200b\uff0c\u200b\u5927\u90e8\u5206\u200b\u4e3b\u6d41\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u90fd\u200b\u5df2\u200b\u5728\u200bHuggingface transformers\u200b\u6a21\u578b\u5e93\u200b\u4e2d\u200b\u5f00\u6e90\u200b\u3002</p> <p>\u200b\u51fa\u4e8e\u200b\u8fd9\u79cd\u200b\u52a8\u673a\u200b\uff0cColossalAI\u200b\u56e2\u961f\u200b\u5f00\u53d1\u200b\u4e86\u200bShardformer\uff0c\u200b\u8be5\u200b\u529f\u80fd\u200b\u53ef\u4ee5\u200b\u81ea\u52a8\u200b\u4e3a\u200bHuggingFace\u200b\u4e2d\u200b\u4e3b\u6d41\u200b\u7684\u200bTransformer\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u5c01\u88c5\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4ee5\u53ca\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7b56\u7565\u200b\u3002\u200b\u5982\u6b64\u4e00\u6765\u200b\uff0c\u200b\u5bf9\u7cfb\u7edf\u200b\u4e86\u89e3\u200b\u4e0d\u591a\u200b\u7684\u200b\u7528\u6237\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u5728\u200btransformers\u200b\u6a21\u578b\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u53ea\u200b\u9700\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\uff0c\u200b\u7528\u6237\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6a21\u578b\u200b\u8f6c\u53d8\u200b\u4e3a\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u72b6\u6001\u200b\u3002\u200b\u6b64\u5916\u200b\uff0cShardformer\u200b\u4e5f\u200b\u5305\u62ec\u200b\u4e86\u200b\u591a\u79cd\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5728\u200b\u524d\u200b\u5411\u200b/\u200b\u540e\u200b\u5411\u200b\u7684\u200b\u4f20\u9012\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u5b9e\u73b0\u200b\u52a0\u901f\u200b\u548c\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#_2","title":"\u652f\u6301\u200b\u4fe1\u606f","text":"<p>\u200b\u6a21\u578b\u200b/\u200b\u529f\u80fd\u200b \u200b\u517c\u5bb9\u6027\u200b\u77e9\u9635\u200b\uff1a</p> Model/Feature TensorParallel PipelineParallel LazyInitialization xFormers FlashAttention 2 JIT FusedOperators FusedLayerNorm SequenceParallel SequenceOverlap Llama V1/V2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c OPT \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c BLOOM \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f ChatGLM 2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f BERT \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f GPT 2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f T5 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c ViT \u2714\ufe0f \u2714\ufe0f \u274c \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c Whisper \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u2714\ufe0f \u274c \u274c SAM \u2714\ufe0f \u274c \u274c \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c Blip2 \u2714\ufe0f \u274c \u274c \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u274c \u274c <p>\u200b\u6211\u4eec\u200b\u8ba1\u5212\u200b\u5728\u200b\u4e0d\u4e45\u200b\u540e\u200b\u4e3a\u200bShardformer\u200b\u652f\u6301\u200b\u7684\u200b\u6a21\u578b\u200b: - RoBERTa - ALBERT - ERNIE - GPT Neo - GPT-J - BEiT - SwinTransformer V1/V2 - qwen</p> <p>\u200b\u968f\u7740\u200b\u672a\u6765\u200b\u66f4\u200b\u591a\u200b\u6a21\u578b\u200b\u548c\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u7684\u200b\u51fa\u73b0\u200b\uff0c\u200b\u6211\u4eec\u200b\u652f\u6301\u200b\u7684\u200b\u6a21\u578b\u200b/\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u5c06\u4f1a\u200b\u53d8\u5f97\u200b\u8d8a\u6765\u8d8a\u200b\u591a\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u5bf9\u200b\u6211\u4eec\u200b\u5e94\u8be5\u200b\u652f\u6301\u200b\u7684\u200b\u6a21\u578b\u200b/\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\u6709\u200b\u4efb\u4f55\u200b\u5efa\u8bae\u200b\uff0c\u200b\u6b22\u8fce\u200b\u5728\u200b\u9879\u76ee\u200b\u7684\u200bIssues\u200b\u677f\u5757\u200b\u53c2\u4e0e\u200b\u8ba8\u8bba\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#_3","title":"\u7528\u6cd5","text":""},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#shardformer_1","title":"Shardformer\u200b\u7684\u200b\u53c2\u6570\u200b\u914d\u7f6e","text":"<p>Shardformer\u200b\u7684\u200b\u914d\u7f6e\u200b\u7531\u7c7b\u200b<code>ShardConfig</code>\u200b\u7684\u200b\u53c2\u6570\u200b\u63a7\u5236\u200b\uff1a</p> <p>{{ autodoc:colossalai.shardformer.ShardConfig }}</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u542f\u7528\u200b Apex Fused Layernorm\uff0c\u200b\u8bf7\u200b\u5b89\u88c5\u200b <code>apex</code>\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u542f\u7528\u200b flash attention\uff0c\u200b\u8bf7\u200b\u5b89\u88c5\u200b <code>flash_attn</code>\u3002\u200b\u6b64\u5916\u200b\uff0cxFormers \u200b\u7684\u200b <code>cutlass_op</code> \u200b\u53ef\u4ee5\u200b\u4f5c\u4e3a\u200bFlash Attention\u200b\u7684\u200b\u8865\u5145\u200b\u4f18\u5316\u200b\u65b9\u5f0f\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#shardformer_2","title":"\u542f\u52a8\u200bShardformer","text":""},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#1-boostershardformer","title":"1. \u200b\u901a\u8fc7\u200bBooster\u200b\u542f\u52a8\u200bShardformer (\u200b\u63a8\u8350\u200b)","text":"<p>\u200b\u901a\u8fc7\u200b\u7528\u200b<code>HybridParallelPlugin</code>\u200b\u521d\u59cb\u5316\u200b\u7684\u200b<code>Booster</code>\u200b\u6765\u200b\u542f\u52a8\u200b<code>Shardformer</code>\u200b\u662f\u200b\u6700\u200b\u63a8\u8350\u200b\u7684\u200b\u7528\u6cd5\u200b\u3002\u200b\u5176\u200b\u4e3b\u8981\u200b\u539f\u56e0\u200b\u662f\u200b\u5982\u679c\u200b\u4e0d\u200b\u8c03\u7528\u200b<code>Booster</code>\u200b\u7684\u200b<code>execute_pipeline</code>\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u5c31\u200b\u65e0\u6cd5\u200b\u6b63\u5e38\u200b\u5de5\u4f5c\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c<code>HybridParallelPlugin</code>\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5c06\u200b<code>Shardformer</code>\u200b\u7684\u200b\u529f\u80fd\u200b\u4e0e\u200b\u5176\u4ed6\u200b\u529f\u80fd\u200b\uff08\u200b\u4f8b\u5982\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u6216\u200bZero\uff09\u200b\u76f8\u7ed3\u5408\u200b\u7684\u200b\u80fd\u529b\u200b\u3002</p> <p>\u200b\u8fd9\u91cc\u200b\u662f\u200b\u4e00\u4e2a\u200b\u901a\u8fc7\u200b<code>HybridParallelPlugin</code>\u200b\u542f\u52a8\u200b<code>Shardformer</code>\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002 \u200b\u79fb\u52a8\u200b\u5230\u200b\u793a\u4f8b\u200b\u7684\u200b\u6839\u76ee\u5f55\u200b\u4e0b\u200b\uff0c\u200b\u6267\u884c\u547d\u4ee4\u200b\uff1a <pre><code>torchrun --standalone --nproc_per_node 4  finetune.py --target_f1 0.86 --plugin \"hybrid_parallel\" --model_type \"bert\"\n</code></pre> \u200b\u4f60\u200b\u4fbf\u200b\u53ef\u4ee5\u200b\u5fae\u8c03\u200b\u4e00\u4e2a\u200b\u88ab\u200b<code>Shardformer</code>\u200b\u5c01\u88c5\u200b\u8fc7\u200b\u7684\u200bBert\u200b\u6a21\u578b\u200b\uff0c\u200b\u800c\u200b\u5c01\u88c5\u200b\u7684\u200b\u64cd\u4f5c\u200b\u662f\u200b\u7531\u200b<code>HybridParallelPlugin</code>\u200b\u5b8c\u6210\u200b\u7684\u200b\u3002</p> <p>\u200b\u63a5\u4e0b\u6765\u200b\u4e00\u8d77\u200b\u6df1\u5165\u200b\u6316\u6398\u200b\u4e00\u4e0b\u200b<code>finetune.py</code>\u200b\u91cc\u200b\u7684\u200b\u4ee3\u7801\u200b\uff1a</p> <p>\u200b\u5728\u200b<code>main</code>\u200b\u51fd\u6570\u200b\u4e2d\u200b\uff0c\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7684\u200b\u63d2\u4ef6\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u7684\u200b\u4ee3\u7801\u200b\u521b\u5efa\u200b <pre><code>...\nelif args.plugin == \"hybrid_parallel\":\n    # modify the param accordingly for finetuning test cases\n    plugin = HybridParallelPlugin(\n        tp_size=1,\n        pp_size=2,\n        num_microbatches=None,\n        microbatch_size=1,\n        enable_all_optimization=True,\n        zero_stage=1,\n        precision=\"fp16\",\n        initial_scale=1,\n    )\n</code></pre> \u200b\u5728\u200b\u8fd9\u91cc\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b\u4e0d\u540c\u200b\u7684\u200b<code>tp_size</code>, <code>pp_size</code> \u200b\u6216\u200b <code>zero_stage</code>\u200b\u6765\u200b\u6539\u53d8\u200b\u63d2\u4ef6\u200b\u7684\u200b\u914d\u7f6e\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u63d2\u4ef6\u200b\u914d\u7f6e\u200b\u7684\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u5728\u200bBooster \u200b\u63d2\u4ef6\u200b\u6587\u6863\u200b\u4e2d\u200b\u88ab\u200b\u627e\u5230\u200b\u3002</p> <p>\u200b\u5f53\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u4e0d\u200b\u88ab\u200b\u542f\u7528\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6d41\u7a0b\u200b\u548c\u200b\u5176\u4ed6\u200b\u7684\u200b\u63d2\u4ef6\u200b\u662f\u200b\u4e00\u6837\u200b\u7684\u200b \uff08\u200b\u5148\u200b\u7528\u200bBooster\u200b\u5c01\u88c5\u200b\u6a21\u578b\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u518d\u7528\u200b\u6b63\u5e38\u200b\u7684\u200b\u65b9\u5f0f\u200b\u505a\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b\uff09\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5f53\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u88ab\u200b\u542f\u7528\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u6709\u200b\u51e0\u5904\u200b\u4e0d\u540c\u4e8e\u200b\u5bfb\u5e38\u200b\u60c5\u51b5\u200b\u7684\u200b\u7528\u6cd5\u200b\uff1a</p> <ol> <li> <p>\u200b\u5728\u200b\u8fdb\u884c\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u4e4b\u524d\u200b\uff0ccriterion\u200b\u51fd\u6570\u200b\uff08loss\u200b\u51fd\u6570\u200b\uff09\u200b\u9700\u8981\u200b\u88ab\u200b\u5904\u7406\u200b\u4ee5\u200b\u6ee1\u8db3\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7684\u200b\u4f20\u53c2\u200b\u8981\u6c42\u200b:     <pre><code>def _criterion(outputs, inputs):\n    outputs = output_transform_fn(outputs)\n    loss = criterion(outputs)\n    return loss\n</code></pre></p> </li> <li> <p>\u200b\u5728\u200b <code>train_epoch</code> \u200b\u51fd\u6570\u200b\u4e2d\u200b, dataloader \u200b\u5728\u200b\u8fdb\u884c\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u540e\u200b\u5411\u200b\u64cd\u4f5c\u200b\u4e4b\u524d\u200b\u9700\u8981\u200b\u88ab\u200b\u8f6c\u6362\u200b\u4e3a\u200b <code>Iterator</code> \u200b\u7c7b\u200b:     <pre><code>train_dataloader_iter = iter(train_dataloader)\n</code></pre></p> </li> <li> <p>\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b<code>Booster.execute_pipeline</code> \u200b\u65b9\u6cd5\u200b\u6765\u200b\u6267\u884c\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b:     <pre><code>outputs = booster.execute_pipeline(\n    train_dataloader_iter, model, _criterion, optimizer, return_loss=True, return_outputs=True\n)\n</code></pre>     \u200b\u8be5\u200b\u65b9\u6cd5\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u6267\u884c\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5728\u200b\u6267\u884c\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u540e\u200b\u4e0d\u200b\u9700\u8981\u200b\u518d\u200b\u8c03\u7528\u200b <code>loss.backward()</code>\u200b\u65b9\u6cd5\u200b\u3002     \u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b <code>Booster.execute_pipeline</code> \u200b\u7684\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b Booster API \u200b\u6587\u6863\u200b\u3002</p> </li> </ol>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#2-shardformer-apishardformer","title":"2. \u200b\u901a\u8fc7\u200bShardformer API\u200b\u542f\u52a8\u200bShardformer (\u200b\u4e0d\u200b\u63a8\u8350\u200b)","text":"<p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u624b\u52a8\u200b\u8c03\u7528\u200bShardformer API\u200b\u7684\u200b\u65b9\u5f0f\u200b\u542f\u52a8\u200bShardformer\u3002\u200b\u7136\u800c\u200b\u6211\u4eec\u200b\u5e76\u200b\u4e0d\u200b\u63a8\u8350\u200b\u8fd9\u79cd\u200b\u7528\u6cd5\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u5728\u200b\u6ca1\u6709\u200b<code>Booster</code>\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u65e0\u6cd5\u200b\u6b63\u5e38\u200b\u8fd0\u884c\u200b\u3002</p> <p>\u200b\u8fd9\u91cc\u200b \u200b\u662f\u200b\u4e00\u4e2a\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200bShardformer\u200b\u7684\u200bAPI\u200b\u542f\u52a8\u200b<code>Shardformer</code>\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002 \u200b\u5728\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b\u7684\u200b<code>train</code>\u200b\u51fd\u6570\u200b\u4e2d\u200b\uff0c\u200b\u6a21\u578b\u200b\u88ab\u200b\u4ee5\u4e0b\u200b\u7684\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u8fdb\u884c\u200b\u5c01\u88c5\u200b\uff1a <pre><code>...\nif dist.get_world_size() &gt; 1:\n    tp_group = dist.new_group(backend=\"nccl\")\n\n    # First create configuration for Shardformer\n    shard_config = ShardConfig(\n        tensor_parallel_process_group=tp_group,\n        enable_tensor_parallelism=True,\n        enable_all_optimization=True\n    )\n\n    # Then create ShardFormer object with created config\n    shard_former = ShardFormer(shard_config=shard_config)\n\n    # Finally shard the model using ShardFormer.optimize method\n    model, _ = shard_former.optimize(model)\n...\n</code></pre></p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#_4","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li> <p>\u200b\u5f53\u200b\u542f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u4e0d\u8981\u200b\u7528\u200b\u5e38\u89c4\u200b\u65b9\u5f0f\u200b\uff08<code>model(input)</code>\u3001<code>loss.backward()</code>\uff09\u200b\u8fdb\u884c\u200b\u524d\u5411\u200b/\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b\uff0c\u200b\u8fd9\u6837\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u672a\u77e5\u200b\u7684\u200b\u9519\u8bef\u200b\u3002\u200b\u8fd9\u79cd\u200b\u60c5\u5f62\u200b\u4e0b\u200b\u8bf7\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b<code>booster.execute_pipeline</code>\u200b\u65b9\u6cd5\u200b\u6765\u200b\u8fdb\u884c\u200b\u524d\u5411\u200b/\u200b\u540e\u200b\u5411\u200b\u4f20\u9012\u200b\u3002</p> </li> <li> <p>\u200b\u5f53\u200b\u4f7f\u7528\u200bShardformer\u200b\u5904\u7406\u200b<code>GPT2ForSequenceClassification</code>\u3001<code>ViTForImageClassification</code>\u200b\u7b49\u200b\u5206\u7c7b\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200blabels\u200b\u7684\u200b\u603b\u6570\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u5e76\u884c\u5ea6\u200b\u7684\u200b\u6574\u6570\u500d\u200b\uff0c\u200b\u5426\u5219\u200bShardformer\u200b\u65e0\u6cd5\u200b\u6b63\u786e\u200b\u5730\u200b\u5904\u7406\u200bclassifier\u200b\u5c42\u200b\u3002\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u4fee\u590d\u200b\u65b9\u6cd5\u200b\u5c31\u662f\u200b\u5728\u200btransformers\u200b\u7684\u200bconfig\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u865a\u62df\u200b\u7684\u200b\u6807\u7b7e\u200b\u3002\u200b\u8fd9\u4e00\u200bbug\u200b\u5c06\u200b\u5728\u200b Shardformer\u200b\u7684\u200b\u672a\u6765\u200b\u7248\u672c\u200b\u4e2d\u200b\u4fee\u590d\u200b\u3002</p> </li> <li> <p>\u200b\u8bad\u7ec3\u200bChatGLM-2 6B\u200b\u7684\u200b\u60c5\u51b5\u200b\u6709\u70b9\u200b\u7279\u6b8a\u200b\uff1a\u200b\u7531\u4e8e\u200bHuggingface Transformers \u200b\u76ee\u524d\u200b\u5c1a\u672a\u200b\u6b63\u5f0f\u200b\u652f\u6301\u200bChatGLM\u3002\u200b\u5728\u200b\u4f7f\u7528\u200bShardformer\u200b\u8bad\u7ec3\u200bChatGLM-2\u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u5bfc\u5165\u200bconfig/model\u200b\u7684\u200b\u7c7b\u200b\uff1a     <pre><code>from colossalai.shardformer.modeling.chatglm2_6b.configuration_chatglm import ChatGLMConfig\nfrom colossalai.shardformer.modeling.chatglm2_6b.modeling_chatglm import ChatGLMForConditionalGeneration, ChatGLMModel\n</code></pre>     \u200b\u5e76\u4e14\u200b\u4f7f\u7528\u200b\u8fd9\u4e9b\u200b\u5bfc\u5165\u200b\u7684\u200b\u7c7b\u200b\u521d\u59cb\u5316\u200b\u6a21\u578b\u200b\u3002</p> </li> </ol>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#shardformer_3","title":"Shardformer\u200b\u7684\u200b\u5de5\u4f5c\u200b\u539f\u7406","text":""},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#_5","title":"\u8bbe\u8ba1\u200b\u601d\u60f3","text":"<p>\u200b\u901a\u5e38\u200b\u6765\u8bf4\u200b\uff0cShardformer\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u56db\u79cd\u200b\u201c\u200b\u66ff\u6362\u200b\u201d\u200b\u8fdb\u884c\u200b\u5de5\u4f5c\u200b\uff1a</p> <ol> <li> <p>\u200b\u7528\u200b\u6211\u4eec\u200b\u8bbe\u8ba1\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u6a21\u5757\u200b\u66ff\u6362\u200b\u539f\u59cb\u200b\u7684\u200bPyTorch\u200b\u6a21\u5757\u200b\uff08\u200b\u4f8b\u5982\u200b<code>nn.Linear</code>\u3001<code>nn.Embedding</code>\uff09\u3002 \u200b\u5206\u5e03\u5f0f\u200b\u6a21\u5757\u200b\u4fdd\u6301\u200b\u4e0e\u200b\u539f\u59cb\u200b\u6a21\u5757\u200b\u76f8\u540c\u200b\u7684\u200b\u5c5e\u6027\u200b\uff0c\u200b\u4f46\u200b\u5206\u5e03\u5f0f\u200b\u6a21\u5757\u200b\u4f1a\u7528\u200b\u65b0\u200b\u7684\u200b\u53c2\u6570\u200b\u66ff\u6362\u200b\u539f\u59cb\u200b\u6a21\u5757\u200b\u7684\u200b\u53c2\u6570\u200b\u3002\u200b\u65b0\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u5c06\u200b\u53d6\u4ee3\u200b\u539f\u6765\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\uff0c\u200b\u7528\u4e8e\u200b\u6267\u884c\u200b\u5206\u5e03\u5f0f\u8ba1\u7b97\u200b\uff0c\u200b\u4f8b\u5982\u200b\u5728\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4e0b\u200b\u6267\u884c\u200b\u7ebf\u6027\u200b\u5c42\u200b\u7684\u200bsplit/gather\u200b\u64cd\u4f5c\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u5206\u5e03\u5f0f\u200b\u6a21\u5757\u200b\u90fd\u200b\u5e94\u5f53\u200b\u5b9e\u73b0\u200b\u5176\u200b<code>from_native_module</code>\u200b\u9759\u6001\u65b9\u6cd5\u200b\uff0c\u200b\u4ee5\u200b\u5c06\u200bPyTorch\u200b\u6a21\u5757\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5176\u200b\u76f8\u5e94\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u6a21\u5757\u200b\u3002</p> </li> <li> <p>\u200b\u5c06\u200b\u539f\u59cb\u200bHuggingface Transformers\u200b\u4e2d\u95f4\u5c42\u200b\u7684\u200b\u5c5e\u6027\u200b\u4e3a\u200b\u9002\u7528\u200b\u4e8e\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5c5e\u6027\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5f53\u200b\u4f7f\u7528\u200b\u5e76\u884c\u5ea6\u200b\u4e3a\u200b2\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200bLlaMa-2\u200b\u65f6\u200b,<code>LlamaDecoderLayer</code>   \u200b\u7684\u200b\u5c5e\u6027\u200b<code>num_heads</code>\uff08\u200b\u6bcf\u200b\u4e00\u5c42\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u7684\u200b\u6570\u91cf\u200b\uff09\u200b\u5e94\u200b\u66ff\u6362\u200b\u4e3a\u200b<code>model.config.num_attention_heads // 2</code>\u3002</p> </li> <li> <p>\u200b\u5c06\u200b\u539f\u6765\u200bHuggingface transformers\u200b\u5e93\u200b\u5b9e\u73b0\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u66ff\u6362\u200b\u4e3a\u200b\u6211\u4eec\u200b\u5b9a\u5236\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u3002\u200b\u524d\u5411\u200b\u51fd\u6570\u200b\u7684\u200b\u66ff\u6362\u200b\u5bf9\u4e8e\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u6027\u200b\u81f3\u5173\u91cd\u8981\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u9700\u8981\u200b\u7279\u6b8a\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u53bb\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\u4e4b\u95f4\u200b\u4f20\u9012\u200b\u4e2d\u95f4\u200b\u7684\u200b\u9690\u85cf\u200b\u72b6\u6001\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6211\u4eec\u200b\u5b9a\u5236\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u5c06\u200b\u4f8b\u5982\u200b<code>flash attention</code>\u200b\u6216\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u7684\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\u6ce8\u5165\u200b\u5230\u200b\u524d\u200b\u5411\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u3002</p> </li> <li> <p>\u200b\u5c06\u200b\u5b8c\u6574\u200b\u7684\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u66ff\u6362\u200b\u4e3a\u200b\u53ea\u200b\u7531\u200b\u5f53\u524d\u200b\u8bbe\u5907\u200b\u63a7\u5236\u200b\u7684\u200b\u90e8\u5206\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3002\u200b\u901a\u8fc7\u200b\u6267\u884c\u200b<code>ModelSharder.shard</code>\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5f53\u524d\u200b\u8bbe\u5907\u200b\u4ec5\u4f1a\u200b\u4fdd\u7559\u200b\u5b83\u200b\u5e94\u8be5\u200b\u5904\u7406\u200b\u7684\u200b\u90a3\u200b\u90e8\u5206\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u3002\u200b\u5177\u4f53\u6765\u8bf4\u200b\uff0c\u200b\u8fd9\u90e8\u5206\u200b\u53c2\u6570\u200b\u53ef\u4ee5\u200b\u662f\u200b\u4f7f\u7528\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u65f6\u200b\u5206\u914d\u200b\u5230\u200b\u5f53\u524d\u200b\u673a\u5668\u200b\u7684\u200b\u53c2\u6570\u200b\u5206\u7247\u200b\uff0c\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u65f6\u200b\u5f53\u524d\u200b\u6d41\u6c34\u7ebf\u200b\u9636\u6bb5\u200b\u7684\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\uff0c\u200b\u6216\u8005\u200b\u517c\u800c\u6709\u4e4b\u200b\u3002\u200b\u9664\u6b64\u4e4b\u5916\u200b\u7684\u200b\u6240\u6709\u200b\u5176\u4ed6\u200b\u53c2\u6570\u200b\u90fd\u200b\u88ab\u200b\u91ca\u653e\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\u7684\u200b\u7a7a\u95f4\u200b\u3002 \u200b\u5982\u6b64\u4e00\u6765\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u53ea\u4f1a\u200b\u8ba1\u7b97\u200b\u4fdd\u7559\u200b\u7684\u200b\u90e8\u5206\u200b\u53c2\u6570\u200b\u5bf9\u5e94\u200b\u7684\u200b\u72b6\u6001\u200b\uff0c\u200b\u4ece\u800c\u200b\u8fdb\u4e00\u6b65\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\u7684\u200b\u4f7f\u7528\u200b\u3002</p> </li> </ol> <p>\u200b\u6240\u6709\u200b\u8fd9\u4e9b\u200b\u66ff\u6362\u200b\u90fd\u200b\u662f\u200b\u901a\u8fc7\u200b\u624b\u52a8\u200b\u7f16\u5199\u200b\u7684\u200b\u7b56\u7565\u200b\u548c\u200b\u524d\u200b\u5411\u200b\u51fd\u6570\u200b\u6765\u200b\u5b9e\u73b0\u200b\u7684\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u66f4\u200b\u6df1\u5165\u200b\u5730\u200b\u7814\u7a76\u200bShardformer\u200b\u7684\u200b\u8bbe\u8ba1\u65b9\u6848\u200b\uff0c\u200b\u6216\u8005\u200b\u5b9a\u5236\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200bShardformer\u200b\u7b56\u7565\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200bShardformer \u200b\u5f00\u53d1\u8005\u200b\u6587\u6863\u200b\u548c\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u8bbe\u8ba1\u65b9\u6848\u200b\u4ee5\u200b\u83b7\u5f97\u200b\u66f4\u200b\u591a\u200b\u7ec6\u8282\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/shardformer/#sequence-parallelism","title":"\u5e8f\u5217\u200b\u5e76\u884c\u200b Sequence Parallelism","text":"<p>\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u662f\u200b<code>Shardformer</code>\u200b\u652f\u6301\u200b\u7684\u200b\u4e00\u79cd\u200b\u7279\u6b8a\u200b\u7684\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\u3002\u200b\u5728\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\uff0c\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u4e0e\u200b\u6b64\u5904\u200b\u7a0d\u200b\u6709\u200b\u4e0d\u540c\u200b\uff0c\u200b\u540e\u8005\u200b\u4fa7\u91cd\u4e8e\u200bring attention\u3002\u200b\u5728\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\uff0c\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u4ec5\u200b\u4e0e\u200b1D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\uff0c\u200b\u4ee5\u200b\u8fdb\u4e00\u6b65\u200b\u51cf\u5c11\u200b\u8ba1\u7b97\u200b\u4e2d\u200bactivation\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u3002</p> <ol> <li> <p>\u200b\u5728\u200b\u666e\u901a\u200b\u7684\u200b1D\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u4e2d\u200b\uff0c\u200b\u6709\u200b\u4e24\u4e2a\u200b\u901a\u4fe1\u200b\u64cd\u4f5c\u200b\\(g\\)\u200b\u548c\u200b\\(\\vec{g}\\)\uff0c\\(g\\)\u200b\u5728\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4e00\u6b21\u200b\u5168\u5c40\u200b\u5f52\u7ea6\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u6765\u81ea\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b\u7684\u200b\u68af\u5ea6\u200b\uff0c\u200b\u800c\u200b\\(\\vec{g}\\)\u200b\u5728\u200b\u6b63\u5411\u200b\u4f20\u64ad\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4e00\u6b21\u200bAll-Reduce\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u6765\u81ea\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b\u7684\u200b\u8f93\u51fa\u200b\u3002</p> </li> <li> <p>\u200b\u5f53\u200b\u4f7f\u7528\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\\(\\vec{g}\\)\u200b\u9700\u8981\u200b\u5728\u200b\u6b63\u5411\u200b\u4f20\u64ad\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8fdb\u884c\u200bAll-Gather\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u5e8f\u5217\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u7684\u200b\u8f93\u5165\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8fdb\u884c\u200bReduce-Scatter\u200b\u4ee5\u200b\u5206\u5272\u200b\u68af\u5ea6\u200b\u3002\\(\\vec{g}\\)\u200b\u9700\u8981\u200b\u8fdb\u884c\u200bReduce-Scatter\u200b\u4ee5\u200b\u5c06\u200b\u5e8f\u5217\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u7684\u200b\u884c\u200b\u7ebf\u6027\u200b\u5c42\u200b\u8f93\u51fa\u200b\u5206\u5272\u200b\u5230\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5e76\u200b\u8fdb\u884c\u200bAll-Gather\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u5b8c\u6574\u200b\u7684\u200b\u68af\u5ea6\u200b\u3002</p> </li> <li> <p>\u200b\u4f7f\u7528\u200bNCCL\u200b\u7684\u200bAll-reduce\u200b\u5b9e\u73b0\u200b\u91c7\u7528\u200b\u4e86\u200b<code>Ring All-Reduce</code>\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u7531\u200b\u4e00\u6b21\u200bReduce-Scatter\u200b\u548c\u200b\u4e00\u6b21\u200bAll-Gather\u200b\u7ec4\u6210\u200b\uff0c\u200b\u4e24\u8005\u200b\u7684\u200b\u5f00\u9500\u200b\u76f8\u7b49\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u4e0e\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u548c\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5b83\u200b\u5e76\u200b\u4e0d\u4f1a\u200b\u5f15\u5165\u200b\u989d\u5916\u200b\u7684\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\u3002</p> </li> <li> <p>\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u4e00\u70b9\u200b\u662f\u200b\uff0c\u200b\u5728\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b <code>Column Linear</code> \u200b\u5c42\u4e2d\u200b\u8fdb\u884c\u200b\u5e8f\u5217\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u68af\u5ea6\u200b\u7684\u200b\u53cd\u5411\u200b\u8ba1\u7b97\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u9700\u8981\u200b\u83b7\u53d6\u200b\u5b8c\u6574\u200b\u7684\u200b\u8f93\u5165\u200b\u3002\u200b\u5728\u200b\u524d\u200b\u5411\u200b\u4f20\u64ad\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4ec5\u200b\u4fdd\u7559\u200b\u6cbf\u200b\u5e8f\u5217\u200b\u7ef4\u5ea6\u200b\u5206\u5272\u200b\u7684\u200b\u8f93\u5165\u200b\u90e8\u5206\u200b\uff0c\u200b\u5f20\u91cf\u200b\u7684\u200b\u5f62\u72b6\u200b\u4f8b\u5982\u200b\\((batch, sequence\\_len/k, hidden\\_states)\\)\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u989d\u5916\u200b\u7684\u200b\u5168\u5c40\u200b\u6536\u96c6\u200b\u64cd\u4f5c\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u5b8c\u6574\u200b\u7684\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u5728\u200b\u5b9e\u73b0\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u4e0e\u200b\u5168\u5c40\u200b\u6536\u96c6\u200b\u901a\u4fe1\u200b\u64cd\u4f5c\u200b\u91cd\u53e0\u200b\uff0c\u200b\u8fd9\u200b\u4e0d\u4f1a\u200b\u5f15\u5165\u200b\u989d\u5916\u200b\u7684\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\uff08\u200b\u5bf9\u5e94\u200b<code>Shardformer</code>\u200b\u4e2d\u200b\u7684\u200b<code>enable_sequence_overlap</code>\u200b\u53c2\u6570\u200b\uff09\u3002</p> </li> </ol>"},{"location":"4-%E7%89%B9%E7%82%B9/zero_with_chunk/","title":"\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b (ZeRO)","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu, Jiarui Fang, Zijian Ye</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b:</p> <ul> <li>booster\u200b\u4f7f\u7528\u200b</li> </ul> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b</p> <ul> <li>Train GPT with Colossal-AI</li> </ul> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b</p> <ul> <li>ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</li> <li>ZeRO-Offload: Democratizing Billion-Scale Model Training</li> <li>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</li> <li>DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters</li> <li>PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management</li> </ul>"},{"location":"4-%E7%89%B9%E7%82%B9/zero_with_chunk/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b (ZeRO) \u200b\u901a\u8fc7\u200b\u5bf9\u200b\u4e09\u4e2a\u200b\u6a21\u578b\u200b\u72b6\u6001\u200b\uff08\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3001\u200b\u68af\u5ea6\u200b\u548c\u200b\u53c2\u6570\u200b\uff09\u200b\u8fdb\u884c\u200b\u5212\u5206\u200b\u800c\u200b\u4e0d\u662f\u200b\u590d\u5236\u200b\u4ed6\u4eec\u200b\uff0c\u200b\u6d88\u9664\u200b\u4e86\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8fdb\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u5185\u5b58\u200b\u5197\u4f59\u200b\u3002\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u4e0e\u200b\u4f20\u7edf\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5185\u5b58\u200b\u6548\u7387\u200b\u5f97\u5230\u200b\u4e86\u200b\u6781\u5927\u200b\u7684\u200b\u63d0\u9ad8\u200b\uff0c\u200b\u800c\u200b\u8ba1\u7b97\u200b\u7c92\u5ea6\u200b\u548c\u200b\u901a\u4fe1\u200b\u6548\u7387\u200b\u5f97\u5230\u200b\u4e86\u200b\u4fdd\u7559\u200b\u3002</p> <ol> <li> <p>\u200b\u5206\u7247\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b: \u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b (\u200b\u5982\u200b Adam optimizer, 32\u200b\u4f4d\u200b\u7684\u200b\u6743\u91cd\u200b, \u200b\u4ee5\u53ca\u200b\u4e00\u200b\u4e8c\u9636\u200b\u52a8\u91cf\u200b\u4f30\u8ba1\u200b) \u200b\u88ab\u200b\u5212\u5206\u200b\u5230\u200b\u5404\u4e2a\u200b\u8fdb\u7a0b\u200b\u4e2d\u200b, \u200b\u56e0\u6b64\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u53ea\u200b\u66f4\u65b0\u200b\u5176\u200b\u5206\u533a\u200b\u3002</p> </li> <li> <p>\u200b\u5206\u7247\u200b\u68af\u5ea6\u200b: \u200b\u5728\u200b\u68af\u5ea6\u200b\u5728\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8fdb\u7a0b\u200b\u7ec4\u5185\u200b\u8fdb\u884c\u200b reduction \u200b\u540e\u200b, \u200b\u68af\u5ea6\u200b\u5f20\u91cf\u200b\u4e5f\u200b\u88ab\u200b\u5212\u5206\u200b\uff0c\u200b\u8fd9\u6837\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u53ea\u200b\u5b58\u50a8\u200b\u4e0e\u5176\u200b\u5212\u5206\u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5bf9\u5e94\u200b\u7684\u200b\u68af\u5ea6\u200b\u3002 \u200b\u6ce8\u610f\u200b, Colossal-AI \u200b\u5c06\u200b\u68af\u5ea6\u200b\u8f6c\u6362\u200b\u4e3a\u200b FP32 \u200b\u683c\u5f0f\u200b\u4ee5\u200b\u53c2\u4e0e\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b\u3002</p> </li> <li> <p>\u200b\u5206\u7247\u200b\u53c2\u6570\u200b: 16\u200b\u4f4d\u200b\u7684\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u88ab\u200b\u5212\u5206\u200b\u5230\u200b\u4e00\u4e2a\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7ec4\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u4e2d\u200b\u3002</p> </li> <li> <p>Gemini: \u200b\u5bf9\u4e8e\u200b\u53c2\u6570\u200b\u3001\u200b\u68af\u5ea6\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u7684\u200b\u52a8\u6001\u200b\u5f02\u6784\u200b\u5185\u5b58\u7a7a\u95f4\u200b\u7ba1\u7406\u5668\u200b\u3002</p> </li> </ol> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u6211\u4eec\u200b\u8fd8\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f7f\u7528\u200b\u96f6\u200b\u5197\u4f59\u200b\u4f18\u5316\u200b\u5668\u200b (ZeRO)\u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b\u5207\u5206\u200b\u53c2\u6570\u200b\u7684\u200b\u65b9\u5f0f\u200b\u5bf9\u6a21\u578b\u200b\u8fdb\u884c\u200b\u5206\u5e03\u5f0f\u200b\u5b58\u50a8\u200b\uff0c\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u7684\u200b\u4f18\u70b9\u200b\u662f\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u5185\u5b58\u200b\u8d1f\u8f7d\u200b\u662f\u200b\u5b8c\u5168\u200b\u5747\u8861\u200b\u7684\u200b\u3002\u200b\u4f46\u662f\u200b\u8fd9\u79cd\u200b\u65b9\u5f0f\u200b\u6709\u200b\u5f88\u591a\u200b\u7f3a\u70b9\u200b\u3002\u200b\u9996\u5148\u200b\uff0c\u200b\u901a\u4fe1\u200b\u65f6\u200b\u9700\u8981\u200b\u7533\u8bf7\u200b\u4e00\u5757\u200b\u4e34\u65f6\u200b\u5185\u5b58\u200b\u7528\u6765\u200b\u901a\u4fe1\u200b\uff0c\u200b\u901a\u4fe1\u200b\u5b8c\u6bd5\u200b\u91ca\u653e\u200b\uff0c\u200b\u8fd9\u56de\u200b\u5bfc\u81f4\u200b\u5b58\u5728\u200b\u5185\u5b58\u200b\u788e\u7247\u200b\u5316\u200b\u7684\u200b\u95ee\u9898\u200b\u3002\u200b\u5176\u6b21\u200b\uff0c\u200b\u4ee5\u200bTensor\u200b\u4e3a\u200b\u7c92\u5ea6\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\uff0c\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u7f51\u7edc\u5e26\u5bbd\u200b\u65e0\u6cd5\u200b\u5145\u5206\u5229\u7528\u200b\u3002\u200b\u901a\u5e38\u200b\u6765\u8bf4\u200b\u4f20\u8f93\u200b\u7684\u200b\u6d88\u606f\u200b\u957f\u5ea6\u200b\u8d8a\u957f\u200b\u5e26\u5bbd\u200b\u5229\u7528\u7387\u200b\u8d8a\u9ad8\u200b\u3002</p> <p>\u200b\u5229\u7528\u200bColossalAI v0.1.8\u200b\u5f15\u5165\u200b\u4e86\u200bChunk\u200b\u673a\u5236\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u63d0\u5347\u200bZeRO\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u8fd0\u7b97\u200b\u987a\u5e8f\u200b\u4e0a\u200b\u8fde\u7eed\u200b\u7684\u200b\u4e00\u7ec4\u200b\u53c2\u6570\u200b\u5b58\u5165\u200b\u4e00\u4e2a\u200bChunk\u200b\u4e2d\u200b\uff08Chunk\u200b\u5373\u200b\u4e00\u6bb5\u200b\u8fde\u7eed\u200b\u7684\u200b\u5185\u5b58\u7a7a\u95f4\u200b\uff09\uff0c\u200b\u6bcf\u4e2a\u200bChunk\u200b\u7684\u200b\u5927\u5c0f\u200b\u76f8\u540c\u200b\u3002Chunk\u200b\u65b9\u5f0f\u200b\u7ec4\u7ec7\u200b\u5185\u5b58\u200b\u53ef\u4ee5\u200b\u4fdd\u8bc1\u200bPCI-e\u200b\u548c\u200bGPU-GPU\u200b\u4e4b\u95f4\u200b\u7f51\u7edc\u5e26\u5bbd\u200b\u7684\u200b\u9ad8\u6548\u200b\u5229\u7528\u200b\uff0c\u200b\u51cf\u5c0f\u200b\u4e86\u200b\u901a\u4fe1\u200b\u6b21\u6570\u200b\uff0c\u200b\u540c\u65f6\u200b\u907f\u514d\u200b\u6f5c\u5728\u200b\u7684\u200b\u5185\u5b58\u200b\u788e\u7247\u200b\u3002</p> <p>\u200b\u5728\u200bv0.1.8\u200b\u4e4b\u524d\u200b\uff0cZeRO\u200b\u5728\u200b\u8fdb\u884c\u200b\u53c2\u6570\u200b\u805a\u5408\u200b\u65f6\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\u8f83\u200b\u9ad8\u200b\uff0c\u200b\u5982\u679c\u200b\u4e00\u4e2a\u200b\u53c2\u6570\u200b\u5728\u200b\u8fde\u7eed\u200b\u7684\u200b\u51e0\u6b21\u200b\u8ba1\u7b97\u200b\u4e2d\u200b\u88ab\u200b\u4f7f\u7528\u200b\u591a\u6b21\u200b\uff0c\u200b\u5373\u4f1a\u200b\u53d1\u751f\u200b\u591a\u6b21\u200b\u901a\u4fe1\u200b\uff0c\u200b\u6548\u7387\u200b\u8f83\u200b\u4f4e\u200b\u3002\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u5728\u200b\u4f7f\u7528\u200bCheckpoint\u200b\u65f6\u200b\u975e\u5e38\u200b\u5e38\u89c1\u200b\uff0c\u200b\u53c2\u6570\u200b\u5728\u200b\u8ba1\u7b97\u200bbackward\u200b\u65f6\u4f1a\u200b\u91cd\u200b\u8ba1\u7b97\u200b\u4e00\u904d\u200bforward\u3002\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cZeRO\u200b\u7684\u200b\u6548\u7387\u200b\u4fbf\u200b\u4e0d\u200b\u9ad8\u200b\u3002</p> <p>\u200b\u4ee5\u200bGPT\u200b\u4e3a\u4f8b\u200b\uff0c\u200b\u5176\u200bCheckpoint\u200b\u4f1a\u200b\u5e94\u7528\u200b\u5728\u200b\u6bcf\u200b\u4e00\u4e2a\u200bGPT Block\u200b\u4e0a\u200b\uff0c\u200b\u6bcf\u200b\u4e00\u4e2a\u200bGPT Block\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200bSelf-Attention\u200b\u5c42\u200b\u548c\u200bMLP\u200b\u5c42\u200b\u3002\u200b\u5728\u200b\u8ba1\u7b97\u200bBackward\u200b\u65f6\u200b\uff0c\u200b\u4f1a\u200b\u4f9d\u6b21\u200b\u8ba1\u7b97\u200bSelf-Attention\u200b\u5c42\u200b\u3001MLP\u200b\u5c42\u200b\u7684\u200bforward\uff0c\u200b\u7136\u540e\u200b\u4f9d\u6b21\u200b\u8ba1\u7b97\u200bMLP\u200b\u5c42\u200b\u3001Self-Attention\u200b\u5c42\u200b\u7684\u200bbackward\u3002\u200b\u5982\u200b\u4f7f\u7528\u200bChunk\u200b\u673a\u5236\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200bSelf-Attention\u200b\u5c42\u200b\u548c\u200bMLP\u200b\u5c42\u200b\u653e\u5728\u200b\u540c\u4e00\u4e2a\u200bChunk\u200b\u4e2d\u200b\uff0c\u200b\u5728\u200b\u6bcf\u4e2a\u200bGPT Block\u200b\u7684\u200bbackward\u200b\u7684\u200b\u4e2d\u200b\u4fbf\u200b\u65e0\u9700\u200b\u518d\u200b\u901a\u4fe1\u200b\u3002</p> <p>\u200b\u9664\u6b64\u4e4b\u5916\u200b\uff0c\u200b\u7531\u4e8e\u200b\u5c0f\u200bTensor\u200b\u7684\u200b\u901a\u4fe1\u200b\u3001\u200b\u5185\u5b58\u200b\u79fb\u52a8\u200b\u6ca1\u6cd5\u200b\u5b8c\u5168\u200b\u5229\u7528\u200bNVLINK\u3001PCIE\u200b\u5e26\u5bbd\u200b\uff0c\u200b\u800c\u4e14\u200b\u6bcf\u6b21\u200b\u901a\u4fe1\u200b\u3001\u200b\u5185\u5b58\u200b\u79fb\u52a8\u200b\u90fd\u200b\u6709\u200bkernel launch\u200b\u7684\u200b\u5f00\u9500\u200b\u3002\u200b\u4f7f\u7528\u200b\u4e86\u200bChunk\u200b\u4e4b\u540e\u200b\u53ef\u4ee5\u200b\u628a\u200b\u591a\u6b21\u200b\u5c0f\u200bTensor\u200b\u7684\u200b\u901a\u4fe1\u200b\u3001\u200b\u5185\u5b58\u200b\u79fb\u52a8\u200b\u53d8\u4e3a\u200b\u4e00\u6b21\u200b\u5927\u200bTensor\u200b\u7684\u200b\u901a\u4fe1\u200b\u3001\u200b\u5185\u5b58\u200b\u79fb\u52a8\u200b\uff0c\u200b\u65e2\u200b\u63d0\u9ad8\u200b\u4e86\u200b\u5e26\u5bbd\u200b\u5229\u7528\u200b\uff0c\u200b\u4e5f\u200b\u51cf\u5c0f\u200b\u4e86\u200bkernel launch\u200b\u7684\u200b\u5f00\u9500\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u8f7b\u91cf\u7ea7\u200b\u7684\u200bChunk\u200b\u641c\u7d22\u200b\u673a\u5236\u200b\uff0c\u200b\u5e2e\u52a9\u200b\u7528\u6237\u200b\u81ea\u52a8\u200b\u627e\u5230\u200b\u5185\u5b58\u200b\u788e\u7247\u200b\u6700\u5c0f\u200b\u7684\u200bChunk\u200b\u5c3a\u5bf8\u200b\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/zero_with_chunk/#_2","title":"\u4f7f\u7528","text":""},{"location":"4-%E7%89%B9%E7%82%B9/zero_with_chunk/#geminiddp","title":"GeminiDDP","text":"<p>\u200b\u6211\u4eec\u200b\u5c06\u200b\u8fd0\u7528\u200b<code>GeminiDDP</code>\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6765\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200bChunk\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u7684\u200bZeRO\u3002\u200b\u8fd9\u662f\u200b\u6211\u4eec\u200b\u65b0\u200b\u5305\u88c5\u200b\u7684\u200btorch.Module \uff0c\u200b\u5b83\u200b\u4f7f\u7528\u200b ZeRO-DP \u200b\u548c\u200b Gemini\uff0c\u200b\u5176\u4e2d\u200bZeRO \u200b\u7528\u4e8e\u200b\u5e76\u884c\u200b\uff0cGemini \u200b\u7528\u4e8e\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u3002</p> <p>Gemini\u200b\u652f\u6301\u200b\u60f0\u6027\u200b\u521d\u59cb\u5316\u200b, \u200b\u5b83\u200b\u53ef\u4ee5\u200b\u8282\u7701\u200b\u591a\u5361\u200b\u521d\u59cb\u5316\u200b\u5927\u200b\u6a21\u578b\u200b\u65f6\u200b\u7684\u200b\u663e\u5b58\u200b\u4f7f\u7528\u200b.</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u6709\u200b <code>N</code> billion \u200b\u4e2a\u200b\u53c2\u6570\u200b\uff0c\u200b\u4f60\u200b\u7684\u200b GPU \u200b\u5185\u5b58\u200b\u4e3a\u200b <code>M</code> GB, \u200b\u5f53\u200b <code>4N &gt;= M</code> \u200b\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b LazyInitContext\u3002\u200b\u5426\u5219\u200b\uff0cLazyInitContext \u200b\u662f\u200b\u53ef\u9009\u200b\u7684\u200b\u3002</p> <pre><code>with LazyInitContext(default_device=torch.device('cuda')):\n  model = gpt2_medium(checkpoint=True)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b <code>Booster</code> API\uff0c\u200b\u5b83\u200b\u7528\u6237\u200b\u53cb\u597d\u200b\u3002\u200b\u6211\u4eec\u200b\u63a8\u8350\u200b\u4f60\u200b\u4f7f\u7528\u200b <code>Booster</code> API\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4ecd\u7136\u200b\u60f3\u200b\u4f7f\u7528\u200b\u5e95\u5c42\u200b API\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7ee7\u7eed\u200b\u9605\u8bfb\u200b\u672c\u200b\u8282\u200b\u5176\u4ed6\u200b\u5185\u5bb9\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b <code>GeminiDDP</code> \u200b\u5305\u88c5\u200b\u6a21\u578b\u200b\u3002</p> <pre><code>model = GeminiDDP(model, hidden_dim=hidden_dim, min_chunk_size_m=min_chunk_size_m)\n</code></pre> <p><code>hidden dim</code>\u200b\u662f\u200bDNN\u200b\u7684\u200b\u9690\u85cf\u200b\u7ef4\u5ea6\u200b\u3002\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\u6765\u200b\u52a0\u5feb\u200b\u641c\u7d22\u200b\u901f\u5ea6\u200b\u3002\u200b\u5982\u679c\u200b\u7528\u6237\u200b\u5728\u200b\u8bad\u7ec3\u200b\u524d\u200b\u4e0d\u200b\u77e5\u9053\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u3002 \u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b\u9ed8\u8ba4\u503c\u200b 1024\u3002<code>min_chunk_size_m</code>\u200b\u662f\u200b\u4ee5\u200b\u5146\u200b\uff082^20\uff09\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u7684\u200b\u6700\u5c0f\u200b\u5757\u200b\u5927\u5c0f\u200b\u3002\u200b\u5982\u679c\u200b\u53c2\u6570\u200b\u7684\u200b\u603b\u200b\u5927\u5c0f\u200b\u4ecd\u7136\u200b\u5c0f\u4e8e\u200b\u6700\u5c0f\u200b\u5757\u200b\u5927\u5c0f\u200b\uff0c\u200b\u5219\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\u5c06\u200b\u88ab\u200b\u538b\u7f29\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u5c0f\u200b\u5757\u200b\u3002</p> <p>\u200b\u521d\u59cb\u5316\u200b\u4f18\u5316\u200b\u5668\u200b\u3002</p> <pre><code>optimizer = GeminiAdamOptimizer(model, lr=1e-3, initial_scale=2**5)\n</code></pre> <p>\u200b\u8bad\u7ec3\u200b <pre><code>optimizer.zero_grad()\noutputs = model(input_ids, attn_mask)\nloss = criterion(outputs, input_ids)\noptimizer.backward(loss)\noptimizer.step()\n</code></pre></p> <p>\u26a0\ufe0f \u200b\u6ce8\u610f\u200b\uff1a\u200b\u8bf7\u200b\u4e0d\u8981\u200b\u4f7f\u7528\u200b<code>loss.backward()</code>\uff0c\u200b\u89c4\u8303\u200b\u5199\u6cd5\u200b\u662f\u200b<code>optimizer.backward(loss)</code>\u3002</p>"},{"location":"4-%E7%89%B9%E7%82%B9/zero_with_chunk/#gpt","title":"\u8bad\u7ec3\u200bGPT","text":"<p>\u200b\u5728\u200b\u6b64\u200b\u4f8b\u7a0b\u200b\u4e2d\u200b, \u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b <code>Hugging Face Transformers</code>\uff0c\u200b\u5e76\u200b\u4ee5\u200b <code>GPT2 Medium</code> \u200b\u4e3a\u4f8b\u200b\u3002\u200b\u4f60\u200b\u5fc5\u987b\u200b\u5728\u200b\u5141\u8bb8\u200b\u8be5\u200b\u4f8b\u7a0b\u200b\u524d\u200b\u5b89\u88c5\u200b <code>transformers</code>\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u7b80\u5355\u200b\u8d77\u200b\u89c1\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u91cc\u200b\u53ea\u200b\u4f7f\u7528\u200b\u968f\u673a\u200b\u751f\u6210\u200b\u7684\u200b\u6570\u636e\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\u6211\u4eec\u200b\u53ea\u200b\u9700\u8981\u200b\u5f15\u5165\u200b<code>Huggingface transformers</code> \u200b\u7684\u200b <code>GPT2LMHeadModel</code>\u200b\u6765\u200b\u5b9a\u4e49\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e0d\u200b\u9700\u8981\u200b\u7528\u6237\u200b\u8fdb\u884c\u200b\u6a21\u578b\u200b\u7684\u200b\u5b9a\u4e49\u200b\u4e0e\u200b\u4fee\u6539\u200b\uff0c\u200b\u65b9\u4fbf\u200b\u7528\u6237\u200b\u4f7f\u7528\u200b\u3002</p> <p>\u200b\u5b9a\u4e49\u200bGPT\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>class GPTLMModel(nn.Module):\n\n    def __init__(self,\n                 hidden_size=768,\n                 num_layers=12,\n                 num_attention_heads=12,\n                 max_seq_len=1024,\n                 vocab_size=50257,\n                 checkpoint=False):\n        super().__init__()\n        self.checkpoint = checkpoint\n        self.model = GPT2LMHeadModel(\n            GPT2Config(n_embd=hidden_size,\n                       n_layer=num_layers,\n                       n_head=num_attention_heads,\n                       n_positions=max_seq_len,\n                       n_ctx=max_seq_len,\n                       vocab_size=vocab_size))\n        if checkpoint:\n            self.model.gradient_checkpointing_enable()\n\n    def forward(self, input_ids, attention_mask):\n        return self.model(input_ids=input_ids, attention_mask=attention_mask, use_cache=not self.checkpoint)[0]\n\ndef gpt2_medium(checkpoint=False):\n    return GPTLMModel(hidden_size=1024, num_layers=24, num_attention_heads=16, checkpoint=checkpoint)\n</code></pre> <p>\u200b\u5b9a\u4e49\u200b\u635f\u5931\u200b\u51fd\u6570\u200b:</p> <pre><code>class GPTLMLoss(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, logits, labels):\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        return self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n</code></pre> <p>\u200b\u5199\u200b\u4e00\u4e2a\u200b\u83b7\u5f97\u200b\u968f\u673a\u200b\u8f93\u5165\u200b\u7684\u200b\u51fd\u6570\u200b:</p> <pre><code>def get_data(batch_size, seq_len, vocab_size):\n    input_ids = torch.randint(0, vocab_size, (batch_size, seq_len), device=torch.cuda.current_device())\n    attention_mask = torch.ones_like(input_ids)\n    return input_ids, attention_mask\n</code></pre> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u4f7f\u7528\u200bbooster\u200b\u6ce8\u5165\u200b Gemini + ZeRO DDP \u200b\u7279\u6027\u200b, \u200b\u5e76\u200b\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u3002\u200b\u7531\u4e8e\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\u5bf9\u200bGPT\u200b\u8fdb\u884c\u200b\u9884\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ea\u200b\u4f7f\u7528\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff1a</p> <pre><code>from colossalai.nn.optimizer import HybridAdam\n\nfrom colossalai.booster import Booster\nfrom colossalai.lazy import LazyInitContext\nfrom colossalai.booster.plugin import GeminiPlugin\n\ndef main():\n    args = parse_args()\n    BATCH_SIZE = 8\n    SEQ_LEN = 1024\n    VOCAB_SIZE = 50257\n    NUM_STEPS = 10\n    colossalai.launch_from_torch(config={})\n\n    # build criterion\n    criterion = GPTLMLoss()\n    optimizer = HybridAdam(model.parameters(), lr=0.001)\n\n    torch.manual_seed(123)\n    # build GPT model\n    with ColoInitContext(default_device=torch.device('cuda')):\n      model = gpt2_medium(checkpoint=True)\n\n\n    # Gemini + ZeRO DP\n    plugin = GeminiPlugin(max_norm=1.0, initial_scale=2**5)\n    booster = Booster(plugin=plugin)\n    model, optimizer, criterion, _, _ = booster.boost(model, optimizer, criterion)\n\n    torch.cuda.synchronize()\n    model.train()\n    for n in range(NUM_STEPS):\n        # we just use randomly generated data here\n        input_ids, attn_mask = get_data(BATCH_SIZE, SEQ_LEN, VOCAB_SIZE)\n        optimizer.zero_grad()\n        outputs = model(input_ids, attn_mask)\n        loss = criterion(outputs, input_ids)\n        booster.backward(loss, optimizer)\n        optimizer.step()\n\n    torch.cuda.synchronize()\n</code></pre> <p>\u26a0\ufe0f \u200b\u6ce8\u610f\u200b\uff1a\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200bGemini\u200b\u6a21\u5757\u200b\u7684\u8bdd\u200b\uff0c\u200b\u8bf7\u200b\u4e0d\u8981\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u4e4b\u524d\u200b\u63d0\u5230\u200b\u8fc7\u200b\u7684\u200b\u68af\u5ea6\u200b\u7d2f\u52a0\u200b\u3002 \u200b\u5b8c\u6574\u200b\u7684\u200b\u4f8b\u5b50\u200b\u4ee3\u7801\u200b\u53ef\u4ee5\u200b\u5728\u200b Train GPT with Colossal-AI. \u200b\u83b7\u5f97\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/","title":"\u5c06\u200b MoE \u200b\u6574\u5408\u200b\u8fdb\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b","text":"<p>\u200b\u4f5c\u8005\u200b: Haichen Huang, Yongbin Li</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - ColossalAI-Examples WideNet</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity - Go Wider Instead of Deeper</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/#introduction","title":"Introduction","text":"<p>\u200b\u81ea\u4ece\u200b<code>Switch Transformer</code>\u200b\u51fa\u73b0\u200b\u4ee5\u6765\u200b\uff0c\u200b\u4eba\u5de5\u667a\u80fd\u200b\u793e\u533a\u200b\u53d1\u73b0\u200b\u4e13\u5bb6\u200b\u6df7\u5408\u200b (MoE) \u200b\u662f\u200b\u4e00\u79cd\u200b\u6269\u5927\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u5bb9\u91cf\u200b\u7684\u200b\u6709\u7528\u200b\u6280\u672f\u200b\u3002 Colossal-AI \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e13\u4e3a\u200bMoE\u200b\u6a21\u578b\u200b\u8bbe\u8ba1\u200b\u7684\u200b\u5e76\u884c\u6027\u200b\u7684\u200b\u65e9\u671f\u200b\u8bbf\u95ee\u200b\u7248\u672c\u200b\u3002Colossal-AI\u200b\u4e2d\u200bMoE\u200b\u6700\u200b\u7a81\u51fa\u200b\u7684\u200b\u4f18\u52bf\u200b\u5c31\u662f\u200b\u65b9\u4fbf\u200b\u3002\u200b\u6211\u4eec\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u5e2e\u52a9\u200b\u6211\u4eec\u200b\u7684\u200b\u7528\u6237\u200b\u8f7b\u677e\u200b\u5730\u200b\u5c06\u200bMoE\u200b\u4e0e\u200b\u6a21\u578b\u200b\u5e76\u884c\u6027\u200b\u548c\u200b\u6570\u636e\u200b\u5e76\u884c\u6027\u200b\u7ed3\u5408\u200b\u8d77\u6765\u200b\u3002 \u200b\u4f46\u662f\u200b\uff0c\u200b\u5f53\u524d\u200b\u7684\u200b\u5b9e\u65bd\u200b\u73b0\u5728\u200b\u6709\u200b\u4e24\u4e2a\u200b\u4e3b\u8981\u200b\u7f3a\u70b9\u200b\u3002\u200b\u7b2c\u4e00\u4e2a\u200b\u7f3a\u70b9\u200b\u662f\u200b\u5b83\u200b\u5728\u200b\u5927\u6279\u91cf\u200b\u548c\u200b\u957f\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u6548\u7387\u200b\u4f4e\u4e0b\u200b\u3002\u200b\u7b2c\u4e8c\u4e2a\u200b\u7f3a\u70b9\u200b\u662f\u200b\u4e0e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u6027\u200b\u4e0d\u200b\u517c\u5bb9\u200b\u3002\u200b\u6211\u4eec\u200b\u6b63\u5728\u200b\u81f4\u529b\u4e8e\u200b\u7cfb\u7edf\u4f18\u5316\u200b\uff0c\u200b\u4ee5\u200b\u514b\u670d\u200b\u8bad\u7ec3\u200b\u6548\u7387\u200b\u95ee\u9898\u200b\u3002\u200b\u4e0e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200b\u517c\u5bb9\u6027\u95ee\u9898\u200b\u9700\u8981\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u9002\u5e94\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u672a\u6765\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u3002 \u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u5177\u6709\u200b\u6a21\u578b\u200b\u5e76\u884c\u6027\u200b\u548c\u200b\u6570\u636e\u200b\u5e76\u884c\u6027\u200b\u7684\u200b MoE\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/#_1","title":"\u76ee\u5f55","text":"<p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b\uff1a 1. \u200b\u642d\u5efa\u200bMoE\u200b\u8fd0\u884c\u200b\u73af\u5883\u200b 2. \u200b\u521b\u5efa\u200bMoE\u200b\u5c42\u200b 3. \u200b\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b</p> <p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u793a\u4f8b\u200b\uff0c \u200b\u8be6\u7ec6\u200b\u4ecb\u7ecd\u200b\u8bf7\u200b\u53c2\u8003\u200b ColossalAI-Examples. \u200b\u8be5\u200b\u793a\u4f8b\u200b\u4f7f\u7528\u200b WideNet \u200b\u4f5c\u4e3a\u200b\u57fa\u4e8e\u200b MoE \u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u793a\u4f8b\u200b.</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/#moe_1","title":"\u642d\u5efa\u200bMoE\u200b\u8fd0\u884c\u200b\u73af\u5883","text":"<p>\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u9879\u76ee\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\uff0c\u200b\u521b\u5efa\u200b<code>config.py</code>\u200b\u6587\u4ef6\u200b\u3002\u200b\u5728\u200b\u8be5\u200b\u6587\u4ef6\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6307\u5b9a\u200b\u5e0c\u671b\u200b\u7528\u4e8e\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u4e00\u4e9b\u200b\u529f\u80fd\u200b\u3002\u200b\u4e3a\u4e86\u200b\u542f\u7528\u200b MoE\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5728\u200b<code>config.py</code>\u200b\u4e2d\u200b\u5b9a\u4e49\u200b<code>parallel</code>\u200b\u5b57\u200b\u6bb5\u200b\uff0c\u200b\u5e76\u200b\u6307\u5b9a\u200b<code>moe</code>\u200b\u7684\u200b\u503c\u200b\u3002<code>moe</code>\u200b\u8868\u793a\u200b\u4e00\u7ec4\u200bmoe\u200b\u5e76\u884c\u200b\u5316\u200b\u8bad\u7ec3\u7ec4\u200b\u7684\u200b\u5e76\u884c\u200b\u5927\u5c0f\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c<code>moe</code>\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b4\uff0c\u200b\u5219\u200b4\u200b\u4e2a\u200b\u8fdb\u7a0b\u200b\u5c06\u200b\u5206\u914d\u200b\u7ed9\u200b4\u200b\u4e2a\u200b\u8fde\u7eed\u200b\u7684\u200bGPU\uff0c\u200b\u8fd9\u200b4\u200b\u4e2a\u200b\u8fdb\u7a0b\u200b\u7ec4\u6210\u200b\u4e00\u4e2a\u200bmoe\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u7ec4\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u53ea\u4f1a\u200b\u5f97\u5230\u200b\u4e00\u90e8\u5206\u200b\u4e13\u5bb6\u200b\u3002\u200b\u589e\u52a0\u200bmo e\u200b\u5e76\u884c\u200b\u7684\u200b\u5927\u5c0f\u200b\u5c06\u200b\u964d\u4f4e\u200b\u901a\u4fe1\u200b\u6210\u672c\u200b\uff0c\u200b\u4f46\u4f1a\u200b\u589e\u52a0\u200b\u6bcf\u4e2a\u200bGPU\u200b\u7684\u200b\u8ba1\u7b97\u6210\u672c\u200b\u548c\u200b\u5185\u5b58\u200b\u4e2d\u200bactivation\u200b\u7684\u200b\u5b58\u50a8\u200b\u6210\u672c\u200b\u3002\u200b\u603b\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7684\u200b\u5927\u5c0f\u200b\u662f\u200b\u81ea\u52a8\u68c0\u6d4b\u200b\u7684\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u8bbe\u7f6e\u200b\u4e3a\u200bGPU\u200b\u7684\u200b\u6570\u91cf\u200b\u3002</p> <pre><code>MOE_MODEL_PARALLEL_SIZE = ...\nparallel = dict(\n    moe=dict(size=MOE_MODEL_PARALLEL_SIZE)\n)\n</code></pre> <p>\u200b\u5982\u679c\u200b<code>MOE_MODEL_PARALLEL_SIZE = E</code>\uff0c\u200b\u5373\u200b\u8bbe\u7f6e\u200b\u4e13\u5bb6\u200b\u7684\u200b\u603b\u6570\u200b\u4e3a\u200b<code>E</code>\uff08<code>E</code>\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u5e38\u6570\u200b\uff09\u3002\u200b\u5728\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u4e2d\u200b\uff0ctransformer\u200b\u7f16\u7801\u5668\u200b\u4e2d\u524d\u200b\u5411\u200b\u90e8\u5206\u200b\u7684\u200b\u5904\u7406\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> MoE Transformer, image source: GShard <p>\u200b\u6240\u6709\u200b\u4e13\u5bb6\u200b\u90fd\u200b\u5206\u914d\u200b\u7ed9\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u7ec4\u4e2d\u200b\u7684\u200bGPU\uff0c\u200b\u6bcf\u200b\u4e00\u4e2a\u200bGPU\u200b\u53ea\u200b\u62e5\u6709\u200b\u4e00\u90e8\u5206\u200b\u4e13\u5bb6\u200b\uff0c\u200b\u539f\u59cb\u6570\u636e\u200b\u5e76\u884c\u200b\u7ec4\u5728\u200b\u53cd\u5411\u200b\u4f20\u9012\u200b\u7684\u200b\u68af\u5ea6\u200b\u5904\u7406\u200b\u671f\u95f4\u200b\u4e0d\u518d\u200b\u9002\u7528\u200b\u4e8e\u200b\u4e13\u5bb6\u200b\u53c2\u6570\u200b\u3002\u200b\u6240\u4ee5\u200b\u6211\u4eec\u200b\u521b\u5efa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u5e76\u884c\u200b\u7ec4\u200b\uff0c\u200b\u53eb\u505a\u200bmoe\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7ec4\u200b\u3002\u200b\u5f53\u200b\u914d\u7f6e\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>WORLD_SIZE=4</code>\uff0c<code>MOE_MODEL_PARALLEL_SIZE=2</code>\u200b\u65f6\u200b\uff0c\u200b\u4e24\u4e2a\u200b\u5e76\u884c\u200b\u7ec4\u200b\u7684\u200b\u533a\u522b\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> MoE\u200b\u5e76\u884c\u5904\u7406\u200b <p>\u200b\u81f3\u4e8e\u200b\u68af\u5ea6\u200b\u5904\u7406\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b<code>MoeGradientHandler</code>\u200b\u6765\u200ball-reduce\u200b\u6a21\u578b\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b<code>colossalai.initialize</code>\u200b\u51fd\u6570\u200b\u521b\u5efa\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5f15\u64ce\u200b\uff0cMoE\u200b\u68af\u5ea6\u200b\u5904\u7406\u7a0b\u5e8f\u200b\u5c06\u200b\u81ea\u52a8\u200b\u6dfb\u52a0\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u5f15\u64ce\u200b\u4e2d\u200b\u3002\u200b\u5426\u5219\u200b\uff0c\u200b\u4f60\u200b\u5e94\u8be5\u200b\u81ea\u5df1\u200b\u5904\u7406\u200b\u68af\u5ea6\u200b\u3002MoE\u200b\u8fd0\u884c\u200b\u73af\u5883\u200b\u7684\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\u90fd\u200b\u4fdd\u5b58\u200b\u5728\u200b<code>colossalai.global_variables.moe_env</code>\u200b\u4e2d\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8bbf\u95ee\u200b\u60a8\u200b\u7684\u200b\u914d\u7f6e\u200b\u53c2\u6570\u200b\u6765\u200b\u68c0\u67e5\u200b\u60a8\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u662f\u5426\u200b\u6b63\u786e\u200b\u3002</p> <pre><code>from colossalai.global_variables import moe_env\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/#moe_2","title":"\u521b\u5efa\u200bMoE\u200b\u5c42","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u200b<code>colossalai.nn.moe</code>\u200b\u521b\u5efa\u200bMoE\u200b\u5c42\u200b\u3002\u200b\u4f46\u200b\u5728\u6b64\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u4e3a\u200b\u6240\u6709\u200b\u8fdb\u7a0b\u200b\u8bbe\u7f6e\u200b\u968f\u673a\u200b\u79cd\u5b50\u200b\u3002</p> <pre><code>from colossalai.context.random import moe_set_seed\nfrom model_zoo.moe.models import Widenet\n\nmoe_set_seed(42)\nmodel = Widenet(num_experts=4, capacity_factor=1.2)\n</code></pre> <p><code>moe_set_seed</code> \u200b\u4f1a\u4e3a\u200b\u4e00\u4e2a\u200bmoe\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u7ec4\u4e2d\u200b\u7684\u200b\u4e0d\u540c\u200b\u8fdb\u7a0b\u200b\u8bbe\u7f6e\u200b\u4e0d\u540c\u200b\u7684\u200b\u79cd\u5b50\u200b\uff08\u200b\u8fd9\u200b\u6709\u52a9\u4e8e\u200b\u5728\u200b\u4e13\u5bb6\u200b\u4e2d\u200b\u521d\u59cb\u5316\u200b\u53c2\u6570\u200b\uff09\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u4e13\u5bb6\u200b\u5b9e\u4f8b\u200b\u548c\u200b\u4e00\u4e2a\u200b\u8def\u7531\u5668\u200b\u5b9e\u4f8b\u200b\uff0c\u200b\u793a\u4f8b\u200b\u5982\u4e0b\u200b\u3002</p> <pre><code>from colossalai.nn.layer.moe import Experts, MoeLayer, Top2Router, NormalNoiseGenerator\n\n\nnoisy_func = NormalNoiseGenerator(num_experts)\nshared_router = Top2Router(capacity_factor,\n                           noisy_func=noisy_func)\nshared_experts = Experts(expert=VanillaFFN,\n                         num_experts=num_experts,\n                         **moe_mlp_args(\n                             d_model=d_model,\n                             d_ff=d_ff,\n                             drop_rate=drop_rate\n                         ))\nffn=MoeLayer(dim_model=d_model, num_experts=num_experts,\n             router=shared_router, experts=shared_experts)\n</code></pre> <p>\u200b\u5728\u200bExperts\u200b\u7684\u200b\u521d\u59cb\u5316\u200b\u4e2d\u200b\uff0c\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u8ba1\u7b97\u200b\u6bcf\u4e2a\u200bGPU\u200b\u7684\u200b\u672c\u5730\u200bexpert\u200b\u6570\u91cf\u200b\uff0c\u200b\u60a8\u200b\u53ea\u200b\u9700\u200b\u6307\u5b9a\u200b\u6bcf\u4e2a\u200b\u4e13\u5bb6\u200b\u7684\u200b\u7c7b\u578b\u200b\u53ca\u5176\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u4f7f\u7528\u200b\u7684\u200b\u53c2\u6570\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b<code>Top1Router</code>\u200b\u548c\u200b<code>Top2Router</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b<code>colossalai.nn.layer.moe</code> \u200b\u627e\u5230\u200b\u5b83\u4eec\u200b\u3002\u200b\u5728\u200b\u521b\u5efa\u200bexperts\u200b\u548c\u200brouter\u200b\u7684\u200b\u5b9e\u4f8b\u200b\u65f6\u200b\uff0c<code>Moelayer</code>\u200b\u53ea\u200b\u521d\u59cb\u5316\u200b\u4e86\u200b<code>gate</code>\u200b\u6a21\u5757\u200b\uff0c\u200b\u7c7b\u578b\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b\u6211\u4eec\u200b\u7684\u200bAPI\u200b\u6587\u6863\u200b\u548c\u200b\u4ee3\u7801\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/integrate_mixture_of_experts_into_your_model/#_2","title":"\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u6a21\u578b","text":"<p>\u200b\u4f7f\u7528\u200bcolossalai\u200b\u4e2d\u200b\u7684\u200b<code>colossalai.initialize</code>\u200b\u51fd\u6570\u200b\u4e3a\u200b\u5f15\u64ce\u200b\u6dfb\u52a0\u200b\u68af\u5ea6\u200b\u5904\u7406\u7a0b\u5e8f\u200b\u4ee5\u200b\u5904\u7406\u200b MoE\u200b\u6a21\u578b\u200b\u7684\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u3002\u200b\u5728\u200b <code>colossalai.initialize</code> \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b<code>MoeGradientHandler</code>\u200b\u5bf9\u8c61\u200b\u6765\u200b\u5904\u7406\u200b\u68af\u5ea6\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200bcolossal\u200b\u76ee\u5f55\u200b\u4e2d\u200b\u627e\u5230\u200b\u6709\u5173\u200b<code>MoeGradientHandler</code>\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u3002\u200b\u4e3a\u4e86\u200b\u6dfb\u52a0\u200bMoE\u200b\u7684\u200b\u76f8\u5173\u200b\u635f\u5931\u200b\u5904\u7406\u200b\uff0c\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u5e94\u200b\u4f7f\u7528\u200b<code>Moeloss</code>\u200b\u5c01\u88c5\u200b\uff0c\u200b\u793a\u4f8b\u200b\u5982\u4e0b\u200b\u3002 <pre><code>criterion = MoeLoss(\n    aux_weight=0.01,\n    loss_fn=nn.CrossEntropyLoss,\n    label_smoothing=0.1\n)\n</code></pre> \u200b\u6700\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ea\u200b\u9700\u200b\u4f7f\u7528\u200b <code>colossalai</code> \u200b\u4e2d\u200b\u7684\u200b<code>trainer</code>\u200b\u6216\u200b<code>engine</code>\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u5373\u53ef\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/","title":"\u8ba4\u8bc6\u200bGemini\uff1aColossalAI\u200b\u7684\u200b\u5f02\u6784\u200b\u5185\u5b58\u7a7a\u95f4\u200b\u7ba1\u7406\u5668","text":"<p>\u200b\u4f5c\u8005\u200b: Jiarui Fang</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u5728\u200bGPU\u200b\u6570\u91cf\u200b\u4e0d\u8db3\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60f3\u8981\u200b\u589e\u52a0\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\uff0c\u200b\u5f02\u6784\u200b\u8bad\u7ec3\u200b\u662f\u200b\u6700\u200b\u6709\u6548\u200b\u7684\u200b\u624b\u6bb5\u200b\u3002\u200b\u5b83\u200b\u901a\u8fc7\u200b\u5728\u200b CPU \u200b\u548c\u200b GPU \u200b\u4e2d\u200b\u5bb9\u7eb3\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\uff0c\u200b\u5e76\u200b\u4ec5\u200b\u5728\u200b\u5fc5\u8981\u200b\u65f6\u200b\u5c06\u200b\u6570\u636e\u200b\u79fb\u52a8\u200b\u5230\u200b\u5f53\u524d\u200b\u8bbe\u5907\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u540c\u65f6\u200b\u5229\u7528\u200b GPU \u200b\u5185\u5b58\u200b\u3001CPU \u200b\u5185\u5b58\u200b\uff08\u200b\u7531\u200b CPU DRAM \u200b\u6216\u200b NVMe SSD\u200b\u5185\u5b58\u200b\u7ec4\u6210\u200b\uff09\u200b\u6765\u200b\u7a81\u7834\u200b\u5355\u200bGPU\u200b\u5185\u5b58\u200b\u5899\u200b\u7684\u200b\u9650\u5236\u200b\u3002\u200b\u5e76\u884c\u200b\uff0c\u200b\u5728\u200b\u5927\u89c4\u6a21\u200b\u8bad\u7ec3\u200b\u4e0b\u200b\uff0c\u200b\u5176\u4ed6\u200b\u65b9\u6848\u200b\u5982\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u3001\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\u3001\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5f02\u6784\u200b\u8bad\u7ec3\u200b\u57fa\u7840\u200b\u4e0a\u200b\u8fdb\u4e00\u6b65\u200b\u6269\u5c55\u200bGPU\u200b\u89c4\u6a21\u200b\u3002\u200b\u8fd9\u200b\u7bc7\u6587\u7ae0\u200b\u63cf\u8ff0\u200bColossalAI\u200b\u7684\u200b\u5f02\u6784\u200b\u5185\u5b58\u7a7a\u95f4\u200b\u7ba1\u7406\u200b\u6a21\u5757\u200bGemini\u200b\u7684\u200b\u8bbe\u8ba1\u200b\u7ec6\u8282\u200b\uff0c\u200b\u5b83\u200b\u7684\u200b\u601d\u60f3\u200b\u6765\u6e90\u4e8e\u200bPatrickStar\uff0cColossalAI\u200b\u6839\u636e\u200b\u81ea\u8eab\u200b\u60c5\u51b5\u200b\u8fdb\u884c\u200b\u4e86\u200b\u91cd\u65b0\u200b\u5b9e\u73b0\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#_2","title":"\u7528\u6cd5","text":"<p>\u200b\u76ee\u524d\u200bGemini\u200b\u652f\u6301\u200b\u548c\u200bZeRO\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b\u517c\u5bb9\u200b\uff0c\u200b\u5b83\u200b\u7684\u200b\u4f7f\u7528\u200b\u65b9\u6cd5\u200b\u5f88\u200b\u7b80\u5355\u200b\uff1a\u200b\u4f7f\u7528\u200bbooster\u200b\u5c06\u200b<code>GeminiPlugin</code>\u200b\u4e2d\u200b\u7684\u200b\u7279\u6027\u200b\u6ce8\u5165\u200b\u5230\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u4e2d\u200b\u3002\u200b\u66f4\u200b\u591a\u200b<code>booster</code>\u200b\u4ecb\u7ecd\u200b\u8bf7\u200b\u53c2\u8003\u200bbooster\u200b\u4f7f\u7528\u200b\u3002</p> <pre><code>from torchvision.models import resnet18\nfrom colossalai.booster import Booster\nfrom colossalai.zero import ColoInitContext\nfrom colossalai.booster.plugin import GeminiPlugin\nplugin = GeminiPlugin(placement_policy='cuda', strict_ddp_mode=True, max_norm=1.0, initial_scale=2**5)\nbooster = Booster(plugin=plugin)\nctx = ColoInitContext()\nwith ctx:\n    model = resnet18()\noptimizer = HybridAdam(model.parameters(), lr=1e-3)\ncriterion = lambda x: x.mean()\nmodel, optimizer, criterion, _, _ = booster.boost(model, optimizer, criterion)\n)\n</code></pre> <p>\u200b\u6ce8\u610f\u200b\uff0cGemini\u200b\u548c\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\uff0c\u200b\u5982\u200bTensor Parallelism\uff0cData Parallelism\uff0cPipeline Parallelism\uff0cZeRO\u200b\u662f\u200b\u89e3\u200b\u8026\u5408\u200b\u7684\u200b\u3002\u200b\u5bf9\u200bTP\uff0cPP\u200b\u7684\u200b\u652f\u6301\u200b\u8fd8\u200b\u5728\u200b\u5f00\u53d1\u200b\u4e2d\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#_3","title":"\u672f\u8bed","text":"<p>\u200b\u7b97\u5b50\u200b(OPerator)\uff1a\u200b\u4e00\u4e2a\u200b\u795e\u7ecf\u200b\u7f51\u7edc\u5c42\u200b\u7684\u200b\u8ba1\u7b97\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u6bd4\u5982\u200bLinear\uff0cLayerNorm\u200b\u7b49\u200b\u3002\u200b\u7b97\u5b50\u200b\u53ef\u4ee5\u200b\u662f\u200b\u6b63\u5411\u200b\u4f20\u64ad\u200b\u7684\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u662f\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u7684\u200b\u8ba1\u7b97\u200b\u3002</p> <p>\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u5728\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\u5fc5\u987b\u200b\u7ba1\u7406\u200b\u7684\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u3002</p> <p>\u200b\u6a21\u578b\u200b\u6570\u636e\u200b(model data): \u200b\u7531\u200b\u53c2\u6570\u200b\u3001\u200b\u68af\u5ea6\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u7ec4\u6210\u200b\uff0c\u200b\u5176\u200b\u89c4\u6a21\u200b\u4e0e\u200b\u6a21\u578b\u200b\u7ed3\u6784\u200b\u5b9a\u4e49\u200b\u76f8\u5173\u200b</p> <p>\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b(non-model data): \u200b\u4e3b\u8981\u200b\u7531\u200b\u7b97\u5b50\u200b\u751f\u6210\u200b\u7684\u200b\u4e2d\u95f4\u200b\u5f20\u91cf\u200b\u548c\u200b\u7b97\u5b50\u200b\u7684\u200b\u4e34\u65f6\u200b\u53d8\u91cf\u200b\u7ec4\u6210\u200b\u3002\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u6839\u636e\u200b\u8bad\u7ec3\u4efb\u52a1\u200b\u7684\u200b\u914d\u7f6e\u200b\u52a8\u6001\u53d8\u5316\u200b\uff0c\u200b\u4f8b\u5982\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u3002\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u548c\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u76f8\u4e92\u7ade\u4e89\u200b GPU \u200b\u5185\u5b58\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#_4","title":"\u8bbe\u8ba1","text":"<p>\u200b\u76ee\u524d\u200b\u7684\u200b\u4e00\u4e9b\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff0cDeepSpeed\u200b\u91c7\u7528\u200b\u7684\u200bZero-offload\u200b\u5728\u200bCPU\u200b\u548c\u200bGPU\u200b\u5185\u5b58\u200b\u4e4b\u95f4\u200b\u9759\u6001\u200b\u5212\u5206\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5b83\u4eec\u200b\u7684\u200b\u5185\u5b58\u200b\u5e03\u5c40\u200b\u5bf9\u4e8e\u200b\u4e0d\u540c\u200b\u7684\u200b\u8bad\u7ec3\u200b\u914d\u7f6e\u200b\u662f\u200b\u6052\u5b9a\u200b\u7684\u200b\u3002\u200b\u5982\u4e0b\u200b\u56fe\u200b\u5de6\u8fb9\u200b\u6240\u793a\u200b\uff0c\u200b\u5f53\u200b GPU \u200b\u5185\u5b58\u200b\u4e0d\u8db3\u4ee5\u200b\u6ee1\u8db3\u200b\u5176\u200b\u76f8\u5e94\u200b\u7684\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u8981\u6c42\u200b\u65f6\u200b\uff0c\u200b\u5373\u4f7f\u200b\u5f53\u65f6\u200bCPU\u200b\u4e0a\u200b\u4ecd\u200b\u6709\u200b\u53ef\u7528\u5185\u5b58\u200b\uff0c\u200b\u7cfb\u7edf\u200b\u4e5f\u200b\u4f1a\u200b\u5d29\u6e83\u200b\u3002\u200b\u800c\u200bColossalAI\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5c06\u200b\u4e00\u90e8\u5206\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u6362\u51fa\u200b\u5230\u200bCPU\u200b\u4e0a\u6765\u200b\u5b8c\u6210\u200b\u8bad\u7ec3\u200b\u3002</p> \u200b\u6bd4\u8f83\u200bZero-Offload\u200b\u548c\u200bGemini\u200b\u7684\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u65b9\u6848\u200b <p>ColossalAI\u200b\u8bbe\u8ba1\u200b\u4e86\u200bGemini\uff0c\u200b\u5c31\u200b\u50cf\u200b\u53cc\u5b50\u661f\u200b\u4e00\u6837\u200b\uff0c\u200b\u5b83\u200b\u7ba1\u7406\u200bCPU\u200b\u548c\u200bGPU\u200b\u4e8c\u8005\u200b\u5185\u5b58\u7a7a\u95f4\u200b\u3002\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u5f20\u91cf\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u52a8\u6001\u200b\u5206\u5e03\u200b\u5728\u200bCPU-GPU\u200b\u7684\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u5185\u200b\uff0c\u200b\u4ece\u800c\u200b\u8ba9\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u7a81\u7834\u200bGPU\u200b\u7684\u200b\u5185\u5b58\u200b\u5899\u200b\u3002\u200b\u5185\u5b58\u200b\u7ba1\u7406\u5668\u200b\u7531\u200b\u4e24\u200b\u90e8\u5206\u200b\u7ec4\u6210\u200b\uff0c\u200b\u5206\u522b\u200b\u662f\u200bMemStatsCollector(MSC)\u200b\u548c\u200bStatefulTensorMgr(STM)\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5229\u7528\u200b\u4e86\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u7f51\u7edc\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u7684\u200b\u8fed\u4ee3\u200b\u7279\u6027\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u8fed\u4ee3\u200b\u5206\u4e3a\u200bwarmup\u200b\u548c\u200bnon-warmup\u200b\u4e24\u4e2a\u200b\u9636\u6bb5\u200b\uff0c\u200b\u5f00\u59cb\u200b\u65f6\u200b\u7684\u200b\u4e00\u4e2a\u200b\u6216\u200b\u82e5\u5e72\u200b\u8fed\u4ee3\u200b\u6b65\u200b\u5c5e\u4e8e\u200b\u9884\u70ed\u200b\u9636\u6bb5\u200b\uff0c\u200b\u5176\u4f59\u200b\u7684\u200b\u8fed\u4ee3\u200b\u6b65\u200b\u5c5e\u4e8e\u200b\u6b63\u5f0f\u200b\u9636\u6bb5\u200b\u3002\u200b\u5728\u200bwarmup\u200b\u9636\u6bb5\u200b\u6211\u4eec\u200b\u4e3a\u200bMSC\u200b\u6536\u96c6\u200b\u4fe1\u606f\u200b\uff0c\u200b\u800c\u200b\u5728\u200bnon-warmup\u200b\u9636\u6bb5\u200bSTM\u200b\u5165\u53bb\u200bMSC\u200b\u6536\u96c6\u200b\u7684\u200b\u4fe1\u606f\u200b\u6765\u200b\u79fb\u52a8\u200btensor\uff0c\u200b\u4ee5\u200b\u8fbe\u5230\u200b\u6700\u5c0f\u5316\u200bCPU-GPU\u200b\u6570\u636e\u200b\u79fb\u52a8\u200bvolume\u200b\u7684\u200b\u76ee\u7684\u200b\u3002</p> Gemini\u200b\u5728\u200b\u4e0d\u540c\u200b\u8bad\u7ec3\u200b\u9636\u6bb5\u200b\u7684\u200b\u8fd0\u884c\u200b\u6d41\u7a0b"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#statefultensormgr","title":"StatefulTensorMgr","text":"<p>STM\u200b\u7ba1\u7406\u200b\u6240\u6709\u200bmodel data tensor\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002\u200b\u5728\u200b\u6a21\u578b\u200b\u7684\u200b\u6784\u9020\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0cColossalAI\u200b\u628a\u200b\u6240\u6709\u200bmodel data\u200b\u5f20\u91cf\u200b\u6ce8\u518c\u200b\u7ed9\u200bSTM\u3002\u200b\u5185\u5b58\u200b\u7ba1\u7406\u5668\u200b\u7ed9\u200b\u6bcf\u4e2a\u200b\u5f20\u91cf\u200b\u6807\u8bb0\u200b\u4e00\u4e2a\u200b\u72b6\u6001\u200b\u4fe1\u606f\u200b\u3002\u200b\u72b6\u6001\u200b\u96c6\u5408\u200b\u5305\u62ec\u200bHOLD\uff0cCOMPUTE\uff0cFREE\u200b\u4e09\u79cd\u200b\u72b6\u6001\u200b\u3002STM\u200b\u7684\u200b\u529f\u80fd\u200b\u5982\u4e0b\u200b\uff1a</p> <p>\u200b\u67e5\u8be2\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\uff1a\u200b\u901a\u8fc7\u200b\u904d\u5386\u200b\u6240\u6709\u200btensor\u200b\u7684\u200b\u5728\u200b\u5f02\u6784\u200b\u7a7a\u95f4\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u83b7\u53d6\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u5bf9\u200bCPU\u200b\u548c\u200bGPU\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u3002</p> <p>\u200b\u8f6c\u6362\u200b\u5f20\u91cf\u200b\u72b6\u6001\u200b\uff1a\u200b\u5b83\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u5f20\u91cf\u200b\u53c2\u4e0e\u200b\u7b97\u5b50\u200b\u8ba1\u7b97\u200b\u4e4b\u524d\u200b\uff0c\u200b\u5c06\u200b\u5f20\u91cf\u200b\u6807\u8bb0\u200b\u4e3a\u200bCOMPUTE\u200b\u72b6\u6001\u200b\uff0c\u200b\u5728\u200b\u8ba1\u7b97\u200b\u4e4b\u540e\u200b\u6807\u8bb0\u200b\u4e3a\u200bHOLD\u200b\u72b6\u6001\u200b\u3002\u200b\u5982\u679c\u200b\u5f20\u91cf\u200b\u4e0d\u518d\u200b\u4f7f\u7528\u200b\u5219\u200b\u6807\u8bb0\u200b\u7684\u200bFREE\u200b\u72b6\u6001\u200b\u3002</p> <p>\u200b\u8c03\u6574\u200b\u5f20\u91cf\u200b\u4f4d\u7f6e\u200b\uff1a\u200b\u5f20\u91cf\u200b\u7ba1\u7406\u5668\u200b\u4fdd\u8bc1\u200bCOMPUTE\u200b\u72b6\u6001\u200b\u7684\u200b\u5f20\u91cf\u200b\u88ab\u200b\u653e\u7f6e\u200b\u5728\u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5982\u679c\u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u7684\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u4e0d\u8db3\u200b\uff0c\u200b\u5219\u200b\u9700\u8981\u200b\u79fb\u52a8\u200b\u51fa\u200b\u4e00\u4e9b\u200bHOLD\u200b\u72b6\u6001\u200b\u7684\u200b\u5f20\u91cf\u200b\u5230\u200b\u5176\u4ed6\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u5b58\u50a8\u200b\u3002Tensor eviction strategy\u200b\u9700\u8981\u200bMSC\u200b\u7684\u200b\u4fe1\u606f\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u540e\u9762\u200b\u4ecb\u7ecd\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#memstatscollector","title":"MemStatsCollector","text":"<p>\u200b\u5728\u200b\u9884\u70ed\u200b\u9636\u6bb5\u200b\uff0c\u200b\u5185\u5b58\u200b\u4fe1\u606f\u200b\u7edf\u8ba1\u200b\u5668\u200b\u76d1\u6d4b\u200bCPU\u200b\u548c\u200bGPU\u200b\u4e2d\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u548c\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\uff0c\u200b\u4f9b\u200b\u6b63\u5f0f\u200b\u8bad\u7ec3\u200b\u9636\u6bb5\u200b\u53c2\u8003\u200b\u3002\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b\u67e5\u8be2\u200bSTM\u200b\u53ef\u4ee5\u200b\u83b7\u5f97\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u5728\u200b\u67d0\u4e2a\u200b\u65f6\u523b\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u3002\u200b\u4f46\u662f\u200b\u975e\u200b\u6a21\u578b\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u5374\u200b\u96be\u4ee5\u200b\u83b7\u53d6\u200b\u3002\u200b\u56e0\u4e3a\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u7684\u200b\u751f\u5b58\u200b\u5468\u671f\u200b\u5e76\u200b\u4e0d\u200b\u5f52\u200b\u7528\u6237\u200b\u7ba1\u7406\u200b\uff0c\u200b\u73b0\u6709\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u6ca1\u6709\u200b\u66b4\u9732\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u7684\u200b\u8ffd\u8e2a\u200b\u63a5\u53e3\u200b\u7ed9\u200b\u7528\u6237\u200b\u3002MSC\u200b\u901a\u8fc7\u200b\u91c7\u6837\u200b\u65b9\u5f0f\u200b\u5728\u200b\u9884\u70ed\u200b\u9636\u6bb5\u200b\u83b7\u5f97\u200b\u975e\u200b\u6a21\u578b\u200b\u5bf9\u200bCPU\u200b\u548c\u200bGPU\u200b\u5185\u5b58\u200b\u7684\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\u3002\u200b\u5177\u4f53\u65b9\u6cd5\u200b\u5982\u4e0b\u200b\uff1a</p> <p>\u200b\u6211\u4eec\u200b\u5728\u200b\u7b97\u5b50\u200b\u7684\u200b\u5f00\u59cb\u200b\u548c\u200b\u7ed3\u675f\u200b\u8ba1\u7b97\u200b\u65f6\u200b\uff0c\u200b\u89e6\u53d1\u200b\u5185\u5b58\u200b\u91c7\u6837\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u6211\u4eec\u200b\u79f0\u200b\u8fd9\u4e2a\u200b\u65f6\u95f4\u200b\u70b9\u4e3a\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\uff08sampling moment)\uff0c\u200b\u4e24\u4e2a\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\u4e4b\u95f4\u200b\u7684\u200b\u65f6\u95f4\u200b\u6211\u4eec\u200b\u79f0\u4e3a\u200bperiod\u3002\u200b\u8ba1\u7b97\u200b\u8fc7\u7a0b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u9ed1\u76d2\u200b\uff0c\u200b\u7531\u4e8e\u200b\u53ef\u80fd\u200b\u5206\u914d\u200b\u4e34\u65f6\u200bbuffer\uff0c\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\u5f88\u200b\u590d\u6742\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8f83\u200b\u51c6\u786e\u200b\u7684\u200b\u83b7\u53d6\u200bperiod\u200b\u7684\u200b\u7cfb\u7edf\u200b\u6700\u5927\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u3002\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u7684\u200b\u4f7f\u7528\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4e24\u4e2a\u200b\u7edf\u8ba1\u200b\u65f6\u523b\u200b\u4e4b\u95f4\u200b\u7cfb\u7edf\u200b\u6700\u5927\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b-\u200b\u6a21\u578b\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u83b7\u5f97\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5982\u4f55\u200b\u8bbe\u8ba1\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\u5462\u200b\u3002\u200b\u6211\u4eec\u200b\u9009\u62e9\u200bpreOp\u200b\u7684\u200bmodel data layout adjust\u200b\u4e4b\u524d\u200b\u3002\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002\u200b\u6211\u4eec\u200b\u91c7\u6837\u200b\u83b7\u5f97\u200b\u4e0a\u200b\u4e00\u4e2a\u200bperiod\u200b\u7684\u200bsystem memory used\uff0c\u200b\u548c\u200b\u4e0b\u200b\u4e00\u4e2a\u200bperiod\u200b\u7684\u200bmodel data memory used\u3002\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u4f1a\u200b\u7ed9\u200bMSC\u200b\u7684\u200b\u5de5\u4f5c\u200b\u9020\u6210\u200b\u969c\u788d\u200b\u3002\u200b\u5982\u56fe\u6240\u793a\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5bf9\u4e8e\u200bZeRO\u200b\u6216\u8005\u200bTensor Parallel\uff0c\u200b\u7531\u4e8e\u200bOp\u200b\u8ba1\u7b97\u200b\u524d\u200b\u9700\u8981\u200bgather\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\uff0c\u200b\u4f1a\u200b\u5e26\u6765\u200b\u989d\u5916\u200b\u7684\u200b\u5185\u5b58\u200b\u9700\u6c42\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u6211\u4eec\u200b\u8981\u6c42\u200b\u5728\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u53d8\u5316\u200b\u524d\u200b\u8fdb\u884c\u200b\u91c7\u6837\u7cfb\u7edf\u200b\u5185\u5b58\u200b\uff0c\u200b\u8fd9\u6837\u200b\u5728\u200b\u4e00\u4e2a\u200bperiod\u200b\u5185\u200b\uff0cMSC\u200b\u4f1a\u200b\u628a\u200bpreOp\u200b\u7684\u200b\u6a21\u578b\u200b\u53d8\u5316\u200b\u5185\u5b58\u200b\u6355\u6349\u200b\u3002\u200b\u6bd4\u5982\u200b\u5728\u200bperiod 2-3\u200b\u5185\u200b\uff0c\u200b\u6211\u4eec\u200b\u8003\u8651\u200b\u7684\u200btensor gather\u200b\u548c\u200bshard\u200b\u5e26\u6765\u200b\u7684\u200b\u5185\u5b58\u200b\u53d8\u5316\u200b\u3002 \u200b\u5c3d\u7ba1\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\u653e\u5728\u200b\u5176\u4ed6\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u6bd4\u5982\u200b\u6392\u9664\u200bgather buffer\u200b\u7684\u200b\u53d8\u52a8\u200b\u65b0\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4f46\u662f\u200b\u4f1a\u200b\u7ed9\u200b\u9020\u6210\u200b\u9ebb\u70e6\u200b\u3002\u200b\u4e0d\u540c\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200bOp\u200b\u7684\u200b\u5b9e\u73b0\u200b\u6709\u200b\u5dee\u5f02\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5bf9\u4e8e\u200bLinear Op\uff0cTensor Parallel\u200b\u4e2d\u200bgather buffer\u200b\u7684\u200b\u5206\u914d\u200b\u5728\u200bOp\u200b\u4e2d\u200b\u3002\u200b\u800c\u200b\u5bf9\u4e8e\u200bZeRO\uff0cgather buffer\u200b\u7684\u200b\u5206\u914d\u200b\u662f\u200b\u5728\u200bPreOp\u200b\u4e2d\u200b\u3002\u200b\u5c06\u200b\u653e\u5728\u200bPreOp\u200b\u5f00\u59cb\u200b\u65f6\u200b\u91c7\u6837\u200b\u6709\u5229\u4e8e\u200b\u5c06\u200b\u4e24\u79cd\u200b\u60c5\u51b5\u200b\u7edf\u4e00\u200b\u3002</p> <p>\u200b\u5c3d\u7ba1\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\u653e\u5728\u200b\u5176\u4ed6\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u6bd4\u5982\u200b\u6392\u9664\u200bgather buffer\u200b\u7684\u200b\u53d8\u52a8\u200b\u65b0\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4f46\u662f\u200b\u4f1a\u200b\u7ed9\u200b\u9020\u6210\u200b\u9ebb\u70e6\u200b\u3002\u200b\u4e0d\u540c\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200bOp\u200b\u7684\u200b\u5b9e\u73b0\u200b\u6709\u200b\u5dee\u5f02\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5bf9\u4e8e\u200bLinear Op\uff0cTensor Parallel\u200b\u4e2d\u200bgather buffer\u200b\u7684\u200b\u5206\u914d\u200b\u5728\u200bOp\u200b\u4e2d\u200b\u3002\u200b\u800c\u200b\u5bf9\u4e8e\u200bZeRO\uff0cgather buffer\u200b\u7684\u200b\u5206\u914d\u200b\u662f\u200b\u5728\u200bPreOp\u200b\u4e2d\u200b\u3002\u200b\u5c06\u200b\u653e\u5728\u200bPreOp\u200b\u5f00\u59cb\u200b\u65f6\u200b\u91c7\u6837\u200b\u6709\u5229\u4e8e\u200b\u5c06\u200b\u4e24\u79cd\u200b\u60c5\u51b5\u200b\u7edf\u4e00\u200b\u3002</p> Sampling based MemStatsCollector"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/meet_gemini/#tensor-eviction-strategy","title":"Tensor Eviction Strategy","text":"<p>MSC\u200b\u7684\u200b\u91cd\u8981\u804c\u8d23\u200b\u662f\u200b\u5728\u200b\u8c03\u6574\u200btensor layout\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5728\u200b\u4e0a\u200b\u56fe\u200bS2\u200b\u65f6\u523b\u200b\uff0c\u200b\u6211\u4eec\u200b\u51cf\u5c11\u200b\u8bbe\u5907\u200b\u4e0a\u200bmodel data\u200b\u6570\u636e\u200b\uff0cPeriod 2-3\u200b\u8ba1\u7b97\u200b\u7684\u200b\u5cf0\u503c\u200b\u5185\u5b58\u200b\u5f97\u5230\u200b\u6ee1\u8db3\u200b\u3002</p> <p>\u200b\u5728\u200bwarmup\u200b\u9636\u6bb5\u200b\uff0c\u200b\u7531\u4e8e\u200b\u8fd8\u200b\u6ca1\u200b\u6267\u884c\u200b\u5b8c\u6bd5\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b\u8fed\u4ee3\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200b\u5185\u5b58\u200b\u7684\u200b\u771f\u5b9e\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\u5c1a\u200b\u4e00\u65e0\u6240\u77e5\u200b\u3002\u200b\u6211\u4eec\u200b\u6b64\u65f6\u200b\u9650\u5236\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u4e0a\u9650\u200b\uff0c\u200b\u6bd4\u5982\u200b\u53ea\u200b\u4f7f\u7528\u200b30%\u200b\u7684\u200bGPU\u200b\u5185\u5b58\u200b\u3002\u200b\u8fd9\u6837\u200b\u4fdd\u8bc1\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u987a\u5229\u5b8c\u6210\u200b\u9884\u70ed\u200b\u72b6\u6001\u200b\u3002</p> <p>\u200b\u5728\u200bnon-warmup\u200b\u9636\u6bb5\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u5229\u7528\u200b\u9884\u70ed\u200b\u9636\u6bb5\u200b\u91c7\u96c6\u200b\u7684\u200b\u975e\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u5185\u5b58\u200b\u4fe1\u606f\u200b\uff0c\u200b\u9884\u7559\u200b\u51fa\u200b\u4e0b\u200b\u4e00\u4e2a\u200bPeriod\u200b\u5728\u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u9700\u8981\u200b\u7684\u200b\u5cf0\u503c\u200b\u5185\u5b58\u200b\uff0c\u200b\u8fd9\u200b\u9700\u8981\u200b\u6211\u4eec\u200b\u79fb\u52a8\u200b\u51fa\u200b\u4e00\u4e9b\u200b\u6a21\u578b\u200b\u5f20\u91cf\u200b\u3002 \u200b\u4e3a\u4e86\u200b\u907f\u514d\u200b\u9891\u7e41\u200b\u5728\u200bCPU-GPU\u200b\u6362\u5165\u200b\u6362\u200b\u51fa\u200b\u76f8\u540c\u200b\u7684\u200btensor\uff0c\u200b\u5f15\u8d77\u200b\u7c7b\u4f3c\u200bcache thrashing\u200b\u7684\u200b\u73b0\u8c61\u200b\u3002\u200b\u6211\u4eec\u200b\u5229\u7528\u200bDNN\u200b\u8bad\u7ec3\u200b\u8fed\u4ee3\u200b\u7279\u6027\u200b\uff0c\u200b\u8bbe\u8ba1\u200b\u4e86\u200bOPT cache\u200b\u6362\u200b\u51fa\u200b\u7b56\u7565\u200b\u3002\u200b\u5177\u4f53\u6765\u8bf4\u200b\uff0c\u200b\u5728\u200bwarmup\u200b\u9636\u6bb5\u200b\uff0c\u200b\u6211\u4eec\u200b\u8bb0\u5f55\u200b\u6bcf\u4e2a\u200btensor\u200b\u88ab\u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u9700\u8981\u200b\u7684\u200b\u91c7\u6837\u200b\u65f6\u523b\u200b\u3002\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u9a71\u9010\u200b\u4e00\u4e9b\u200bHOLD tensor\uff0c\u200b\u90a3\u4e48\u200b\u6211\u4eec\u200b\u9009\u62e9\u200b\u5728\u200b\u672c\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u6700\u665a\u200b\u88ab\u200b\u9700\u8981\u200b\u7684\u200btensor\u200b\u4f5c\u4e3a\u200b\u53d7\u5bb3\u8005\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/opt_service/","title":"Colossal-AI\u200b\u4f7f\u7528\u6307\u5357\u200b\uff1a5\u200b\u5206\u949f\u200b\u642d\u5efa\u200b\u5728\u7ebf\u200bOPT\u200b\u670d\u52a1","text":""},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/opt_service/#_1","title":"\u4ecb\u7ecd","text":"<p>\u200b\u672c\u200b\u6307\u5bfc\u200b\u624b\u518c\u200b\u5c06\u200b\u8bf4\u660e\u200b\u5982\u4f55\u200b\u5229\u7528\u200bColossal-AI\u200b\u642d\u5efa\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200bOPT\u200b\u670d\u52a1\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/opt_service/#colossal-ai","title":"Colossal-AI \u200b\u63a8\u7406\u200b\u6982\u8ff0","text":"<p>Colossal-AI \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u63a8\u7406\u200b\u5b50\u7cfb\u7edf\u200b Energon-AI\uff0c \u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u57fa\u4e8e\u200bColossal-AI\u200b\u7684\u200b\u670d\u52a1\u200b\u7cfb\u7edf\u200b\uff0c\u200b\u62e5\u6709\u200b\u4ee5\u4e0b\u200b\u7279\u6027\u200b\uff1a</p> <ul> <li>\u200b\u5927\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b\uff1a \u200b\u5728\u200bColossal-AI\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u7684\u200b\u5e2e\u52a9\u200b\u4e0b\u200b\uff0cColossal-AI\u200b\u7684\u200b\u63a8\u7406\u200b\u53ef\u200b\u5b9e\u73b0\u200b\u5927\u200b\u6a21\u578b\u200b\u7684\u200b\u9ad8\u6548\u200b\u5e76\u884c\u200b\u63a8\u7406\u200b\u3002</li> <li>\u200b\u9884\u200b\u6784\u5efa\u200b\u5927\u200b\u6a21\u578b\u200b\uff1a Colossal-AI\u200b\u63d0\u4f9b\u200b\u70ed\u95e8\u200b\u6a21\u578b\u200b\u7684\u200b\u9884\u200b\u6784\u5efa\u200b\u90e8\u7f72\u200b\uff0c\u200b\u4f8b\u5982\u200bOPT\u3002\u200b\u5176\u200b\u652f\u6301\u200b\u7528\u4e8e\u200b\u751f\u6210\u200b\u4efb\u52a1\u200b\u548c\u200b\u52a0\u8f7d\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u7f13\u5b58\u200b\u6280\u672f\u200b\u3002</li> <li>\u200b\u5f15\u64ce\u200b\u5c01\u88c5\u200b\uff1a Colossal-AI\u200b\u4e2d\u6709\u200b\u4e00\u4e2a\u200b\u62bd\u8c61\u200b\u5c42\u200b\u88ab\u79f0\u4f5c\u200b\u5f15\u64ce\u200b\u3002\u200b\u5176\u200b\u5c06\u200b\u5355\u200b\u5b9e\u4f8b\u200b\u591a\u200b\u8bbe\u5907\u200b(SIMD) \u200b\u6267\u884c\u200b\u4e0e\u200b\u8fdc\u7a0b\u200b\u8fc7\u7a0b\u200b\u8c03\u7528\u200b\u5c01\u88c5\u200b\u5728\u200b\u4e00\u8d77\u200b\u3002</li> <li>\u200b\u5728\u7ebf\u200b\u670d\u52a1\u200b\u7cfb\u7edf\u200b\uff1a \u200b\u57fa\u4e8e\u200bFastAPI\uff0c\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u5feb\u901f\u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u63a8\u7406\u200b\u7684\u200b\u7f51\u7edc\u670d\u52a1\u200b\u3002 \u200b\u5728\u7ebf\u200b\u670d\u52a1\u200b\u5bf9\u200b\u751f\u6210\u200b\u4efb\u52a1\u200b\u8fdb\u884c\u200b\u4e86\u200b\u7279\u6b8a\u200b\u4f18\u5316\u200b\u3002\u200b\u5b83\u200b\u91c7\u7528\u200bleft padding\u200b\u548c\u200bbucket batching\u200b\u4e24\u79cd\u200b\u6280\u672f\u200b\u6765\u200b\u63d0\u9ad8\u6548\u7387\u200b\u3002</li> </ul>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/opt_service/#_2","title":"\u57fa\u672c\u200b\u7528\u6cd5","text":"<ol> <li>\u200b\u4e0b\u8f7d\u200bOPT\u200b\u6a21\u578b\u200b</li> </ol> <p>\u200b\u60f3\u8981\u200b\u5feb\u901f\u200b\u53d1\u5e03\u200b\u5206\u5e03\u5f0f\u200b\u63a8\u7406\u200b\u670d\u52a1\u200b\uff0c\u200b\u60a8\u200b\u4ece\u200b\u6b64\u5904\u200b\u4e0b\u8f7d\u200bOPT-125M\u3002\u200b\u6709\u5173\u200b\u52a0\u8f7d\u200b\u5176\u4ed6\u200b\u4f53\u91cf\u200b\u6a21\u578b\u200b\u7684\u200b\u8be6\u7ec6\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u60a8\u200b\u53ef\u200b\u8bbf\u95ee\u200b\u6b64\u5904\u200b\u3002</p> <ol> <li>\u200b\u51c6\u5907\u200b\u63d0\u524d\u200b\u6784\u5efa\u200b\u7684\u200b\u670d\u52a1\u200b\u955c\u50cf\u200b</li> </ol> <p>\u200b\u4ece\u200bdockerhub\u200b\u62c9\u53d6\u200b\u4e00\u4e2a\u200b\u5df2\u7ecf\u200b\u5b89\u88c5\u200bColossal-AI\u200b\u63a8\u7406\u200b\u7684\u200bdocker\u200b\u955c\u50cf\u200b\u3002</p> <pre><code>docker pull hpcaitech/energon-ai:latest\n</code></pre> <ol> <li>\u200b\u53d1\u5e03\u200bHTTP\u200b\u670d\u52a1\u200b</li> </ol> <p>\u200b\u82e5\u60f3\u200b\u53d1\u5e03\u200b\u670d\u52a1\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u51c6\u5907\u200bpython\u200b\u811a\u672c\u200b\u6765\u200b\u63cf\u8ff0\u200b\u6a21\u578b\u200b\u7684\u200b\u7c7b\u578b\u200b\u548c\u200b\u76f8\u5173\u200b\u7684\u200b\u90e8\u7f72\u200b\uff0c\u200b\u4ee5\u53ca\u200bHTTP\u200b\u670d\u52a1\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u3002 \u200b\u6211\u4eec\u200b\u4e3a\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u793a\u4f8b\u200b\u3002 \u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u672c\u200b\u6307\u5bfc\u200b\u624b\u518c\u200b\u4e2d\u200b\u4f7f\u7528\u200bOPT \u200b\u793a\u4f8b\u200b\u3002 \u200b\u670d\u52a1\u200b\u7684\u200b\u5165\u53e3\u200b\u662f\u200b\u4e00\u4e2a\u200bbash\u200b\u811a\u672c\u200b server.sh\u3002 \u200b\u672c\u200b\u670d\u52a1\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u53c2\u8003\u200b opt_config.py\uff0c\u200b\u8be5\u200b\u6587\u4ef6\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u6a21\u578b\u200b\u7684\u200b\u7c7b\u578b\u200b\u3001 \u200b\u68c0\u67e5\u70b9\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b\u3001\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u548c\u200bhttp\u200b\u8bbe\u7f6e\u200b\u3002\u200b\u60a8\u200b\u80fd\u200b\u6309\u7167\u200b\u60a8\u200b\u7684\u200b\u9700\u6c42\u200b\u6765\u200b\u4fee\u6539\u200b\u8fd9\u4e9b\u200b\u8bbe\u7f6e\u200b\u3002 \u200b\u4f8b\u5982\u200b\uff0c\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u5927\u5c0f\u200b\u8bbe\u7f6e\u200b\u4e3a\u200bopt_125M\uff0c\u200b\u5c06\u200b\u6b63\u786e\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u8def\u5f84\u200b\u6309\u7167\u200b\u5982\u4e0b\u200b\u8bbe\u7f6e\u200b\uff1a</p> <pre><code>model_class = opt_125M\ncheckpoint = 'your_file_path'\n</code></pre> <p>\u200b\u5c06\u200b\u5f20\u91cf\u200b\u5e76\u884c\u5ea6\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u60a8\u200b\u7684\u200bgpu\u200b\u6570\u91cf\u200b\u3002</p> <pre><code>tp_init_size = #gpu\n</code></pre> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c31\u200b\u80fd\u200b\u5229\u7528\u200bdocker\u200b\u53d1\u5e03\u200b\u4e00\u4e2a\u200b\u670d\u52a1\u200b\u3002\u200b\u60a8\u200b\u80fd\u200b\u5728\u200b<code>/model_checkpoint</code> \u200b\u548c\u200b <code>/config</code>\u200b\u8def\u5f84\u200b\u4e0b\u200b\u627e\u5230\u200b\u68c0\u67e5\u70b9\u200b\u6587\u4ef6\u200b\u548c\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002</p> <pre><code>export CHECKPOINT_DIR=\"your_opt_checkpoint_path\"\n# the ${CONFIG_DIR} must contain a server.sh file as the entry of service\nexport CONFIG_DIR=\"config_file_path\"\n\ndocker run --gpus all  --rm -it -p 8020:8020 -v ${CHECKPOINT_DIR}:/model_checkpoint -v ${CONFIG_DIR}:/config --ipc=host energonai:latest\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u6d4f\u89c8\u5668\u200b\u4e2d\u200b\u6253\u5f00\u200b <code>https://[IP-ADDRESS]:8020/docs#</code> \u200b\u8fdb\u884c\u200b\u6d4b\u8bd5\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/opt_service/#_3","title":"\u9ad8\u7ea7\u200b\u7279\u6027\u200b\u7528\u6cd5","text":"<ol> <li>\u200b\u6279\u5904\u7406\u200b\u4f18\u5316\u200b</li> </ol> <p>\u200b\u82e5\u60f3\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u7684\u200b\u9ad8\u7ea7\u200b\u6279\u5904\u7406\u200b\u6280\u672f\u200b\u6765\u200b\u6279\u91cf\u200b\u6536\u96c6\u200b\u591a\u4e2a\u200b\u67e5\u8be2\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200bexecutor_max_batch_size\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u6700\u5927\u200b\u6279\u5904\u7406\u200b\u5927\u5c0f\u200b\u3002 \u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u53ea\u6709\u200b\u5177\u6709\u200b\u76f8\u540c\u200b top_k\u3001top_p \u200b\u548c\u200b\u6e29\u5ea6\u200b\u7684\u200b\u89e3\u7801\u200b\u4efb\u52a1\u200b\u624d\u80fd\u200b\u4e00\u8d77\u200b\u6279\u5904\u7406\u200b\u3002</p> <pre><code>executor_max_batch_size = 16\n</code></pre> <p>\u200b\u6240\u6709\u200b\u7684\u200b\u67e5\u8be2\u200b\u5c06\u200b\u8fdb\u5165\u200bFIFO\u200b\u961f\u5217\u200b\u3002\u200b\u89e3\u7801\u200b\u6b65\u6570\u200b\u5c0f\u4e8e\u200b\u6216\u200b\u7b49\u4e8e\u200b\u961f\u5217\u200b\u5934\u90e8\u200b\u89e3\u7801\u200b\u6b65\u6570\u200b\u7684\u200b\u6240\u6709\u200b\u8fde\u7eed\u200b\u67e5\u8be2\u200b\u53ef\u4ee5\u200b\u4e00\u8d77\u200b\u6279\u5904\u7406\u200b\u3002  \u200b\u5e94\u7528\u200b\u5de6\u200b\u586b\u5145\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u6b63\u786e\u6027\u200b\u3002 executor_max_batch_size \u200b\u4e0d\u200b\u5e94\u8be5\u200b\u8fc7\u5927\u200b\uff0c\u200b\u4ece\u800c\u200b\u786e\u4fdd\u200b\u6279\u5904\u7406\u200b\u4e0d\u4f1a\u200b\u589e\u52a0\u200b\u5ef6\u8fdf\u200b\u3002 \u200b\u4ee5\u200bopt-30b\u200b\u4e3a\u4f8b\u200b\uff0c <code>executor_max_batch_size=16</code> \u200b\u5408\u9002\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200bopt-175b\u200b\u800c\u8a00\u200b\uff0c <code>executor_max_batch_size=4</code> \u200b\u66f4\u200b\u5408\u9002\u200b\u3002</p> <ol> <li>\u200b\u7f13\u5b58\u200b\u4f18\u5316\u200b</li> </ol> <p>\u200b\u5bf9\u4e8e\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u670d\u52a1\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u60a8\u200b\u80fd\u200b\u5c06\u200b\u6700\u8fd1\u200b\u7684\u200b\u591a\u4e2a\u200b\u67e5\u8be2\u200b\u7ed3\u679c\u200b\u7f13\u5b58\u200b\u5728\u200b\u4e00\u8d77\u200b\u3002\u200b\u5728\u200bconfig.py\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b cache_size \u200b\u548c\u200b cache_list_size\u3002\u200b\u7f13\u5b58\u200b\u7684\u200b\u5927\u5c0f\u200b\u5e94\u4e3a\u200b\u7f13\u5b58\u200b\u7684\u200b\u67e5\u8be2\u200b\u6570\u76ee\u200b\u3002cache_list_size \u200b\u5e94\u4e3a\u200b\u6bcf\u6b21\u200b\u67e5\u8be2\u200b\u5b58\u50a8\u200b\u7684\u200b\u7ed3\u679c\u200b\u6570\u200b\u3002\u200b\u4e00\u4e2a\u200b\u968f\u673a\u200b\u7f13\u5b58\u200b\u7684\u200b\u7ed3\u679c\u200b\u5c06\u4f1a\u200b\u88ab\u200b\u8fd4\u56de\u200b\u3002\u200b\u5f53\u200b\u7f13\u5b58\u200b\u5df2\u6ee1\u200b\uff0cLRU\u200b\u7b56\u7565\u200b\u88ab\u200b\u7528\u4e8e\u200b\u6e05\u7406\u200b\u7f13\u5b58\u200b\u8fc7\u200b\u7684\u200b\u67e5\u8be2\u200b\u3002cache_size=0\u200b\u610f\u5473\u7740\u200b\u4e0d\u200b\u7f13\u5b58\u200b\u3002</p> <pre><code>cache_size = 50\ncache_list_size = 2\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/","title":"\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b GPT-2","text":"<p>\u200b\u4f5c\u8005\u200b: Hongxin Liu, Yongbin Li, Mingyan Jiang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - \u200b\u5e76\u884c\u200b\u63d2\u4ef6\u200b - booster API</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b - ColossalAI-Examples GPT2</p> <p>\u200b\u76f8\u5173\u200b\u8bba\u6587\u200b - Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training - Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u5728\u200b\u4e0a\u200b\u4e00\u7bc7\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u4ecb\u7ecd\u200b\u4e86\u200b\u5982\u4f55\u200b\u7528\u200b\u6d41\u6c34\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b ViT\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u5c06\u200b\u5b66\u4e60\u200b\u4e00\u4e2a\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u573a\u666f\u200b--\u200b\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b\u8bad\u7ec3\u200bGPT-2\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u7531\u4e8e\u200bGPT-2\u200b\u8fc7\u5927\u200b\uff0c\u200b\u5373\u4f7f\u200bCPU\u200b\u5185\u5b58\u200b\u4e5f\u200b\u65e0\u6cd5\u200b\u5bb9\u7eb3\u200b\u5b83\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u8be5\u200b\u6a21\u578b\u200b\u5fc5\u987b\u200b\u88ab\u200b\u5206\u5272\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#_2","title":"\u76ee\u5f55","text":"<p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ecb\u7ecd\u200b: 1. \u200b\u521d\u59cb\u5316\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u63d2\u4ef6\u200b 2. \u200b\u5b9a\u4e49\u200b GPT-2 \u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b 3. \u200b\u4f7f\u7528\u200b HybridParallelPlugin \u200b\u589e\u5f3a\u200bGPT-2\u200b\u6a21\u578b\u200b 4. \u200b\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b GPT-2</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#_3","title":"\u5bfc\u5165\u200b\u4f9d\u8d56\u200b\u5e93","text":"<pre><code>from typing import Callable, List, Union\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler as LRScheduler\nfrom tqdm import tqdm\nfrom transformers import AutoConfig, GPT2ForSequenceClassification, get_linear_schedule_with_warmup\nfrom transformers import AutoTokenizer\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import GeminiPlugin, HybridParallelPlugin, LowLevelZeroPlugin, TorchDDPPlugin\nfrom colossalai.cluster import DistCoordinator\nfrom colossalai.nn.optimizer import HybridAdam\nfrom colossalai.utils import get_current_device\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#plugin","title":"\u5b9a\u4e49\u200bplugin","text":"<p>\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b<code>HybridParallelPlugin</code>\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u6307\u5b9a\u200b\u6240\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\uff0c\u200b\u5728\u200b\u8be5\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u540c\u65f6\u200b\u4f7f\u7528\u200b\u4e86\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u548c\u200bzero1. <pre><code>plugin = HybridParallelPlugin(\n    tp_size=1,\n    pp_size=2,\n    num_microbatches=None,\n    microbatch_size=1,\n    enable_all_optimization=True,\n    zero_stage=1,\n    precision=\"fp16\",\n    initial_scale=1,\n)\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#_4","title":"\u521b\u5efa\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b.","text":"<pre><code># Launch ColossalAI\ncolossalai.launch_from_torch(config={}, seed=42)\ncoordinator = DistCoordinator()\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#gpt-2_1","title":"\u5b9a\u4e49\u200bGPT-2\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6","text":"<p>\u200b\u5728\u200b\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u6240\u200b\u4f7f\u7528\u200b\u7684\u200b\u7ec4\u4ef6\u200b\u3002 \u200b\u5b9a\u4e49\u200b\u8d85\u200b\u53c2\u6570\u200b\u3002 <pre><code>NUM_EPOCHS = 3\nBATCH_SIZE = 32\nLEARNING_RATE = 2.4e-5\nWEIGHT_DECAY = 0.01\nWARMUP_FRACTION = 0.1\n</code></pre> \u200b\u83b7\u53d6\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>plugin.prepare_dataloader</code>\u200b\u751f\u6210\u200bdataloader,\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u81ea\u5b9a\u4e49\u200b\u60a8\u200b\u7684\u200bdataloader\u3002 <pre><code>def tokenize_batch(batch, tokenizer: Optional[AutoTokenizer] = None, max_length: int = 2048):\n    texts = [sample[\"sentence1\"] + sample[\"sentence2\"] for sample in batch]\n    data = tokenizer(texts, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length)\n    data = {k: v.cuda() for k, v in data.items()}\n    data[\"labels\"] = data[\"input_ids\"].clone()\n    return data\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ndataset = datasets.load_dataset(\"glue\", \"mrpc\")\ntrain_dataloader = plugin.prepare_dataloader(\n    dataset[\"train\"],\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n    collate_fn=partial(tokenize_batch, tokenizer=tokenizer, max_length=512),\n)\n</code></pre> \u200b\u5b9a\u4e49\u200bGPT-2\u200b\u6a21\u578b\u200b\u3002 <pre><code>cfg = AutoConfig.from_pretrained(\"gpt2\", num_labels=2)\nmodel = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=cfg).cuda()\n</code></pre> \u200b\u51c6\u5907\u200b\u4f18\u5316\u200b\u5668\u200b <pre><code>lr = LEARNING_RATE * coordinator.world_size\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": WEIGHT_DECAY,\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\n\noptimizer = HybridAdam(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n</code></pre> \u200b\u51c6\u5907\u200b <code>lr_scheduler</code> \u200b\u548c\u200b <code>criterion</code>\uff0c\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u5f53\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u4f7f\u7528\u200b\u4e86\u200b\u7ba1\u9053\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u8fd8\u200b\u9700\u200b\u5b9a\u4e49\u200b<code>criterion</code>\u200b\u51fd\u6570\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u51fd\u6570\u200b\u5e94\u8be5\u200b\u4ee5\u200b\u6a21\u578b\u200b\u524d\u540e\u200b\u5411\u200b\u7684\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\u4f5c\u4e3a\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u8fd4\u56de\u200bloss\u3002 <pre><code># lr scheduler\ntotal_steps = len(train_dataloader) * NUM_EPOCHS\nnum_warmup_steps = int(WARMUP_FRACTION * total_steps)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=total_steps,\n)\n\ndef _criterion(outputs, inputs):\n    return outputs.loss\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#gpt-2_2","title":"\u589e\u5f3a\u200bGPT-2\u200b\u6a21\u578b","text":"<p>\u200b\u4f7f\u7528\u200b HybridParallelPlugin \u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b booster\uff08\u200b\u589e\u5f3a\u5668\u200b\uff09\u3002\u200b\u6839\u636e\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u63d2\u4ef6\u200b\u53c2\u6570\u200b\uff0cbooster\u200b\u4f1a\u200b\u5c06\u200b\u4e00\u79cd\u200b\u6216\u8005\u200b\u591a\u79cd\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u6ce8\u5165\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\u3002\u200b\u8be5\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u4e86\u200b\u7ba1\u9053\u200b\u5e76\u884c\u200b\uff0czero1\uff0c\u200b\u53ca\u534a\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u7b49\u200b\u4f18\u5316\u200b\u3002 <pre><code>booster = Booster(plugin=plugin)\n</code></pre> \u200b\u4f7f\u7528\u200b\u5b9a\u4e49\u200b\u7684\u200b booster \u200b\u6765\u200b\u589e\u5f3a\u200b\u8fd9\u4e9b\u200b\u7ec4\u4ef6\u200b\u3002 <pre><code>model, optimizer, _criterion, _, lr_scheduler = booster.boost(\n    model, optimizer, criterion=_criterion, lr_scheduler=lr_scheduler\n)\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_gpt_using_hybrid_parallelism/#gpt-2_3","title":"\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b GPT-2","text":"<p>\u200b\u5728\u200b\u524d\u9762\u200b\u7684\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u89e3\u91ca\u200b\u4e86\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b Booster \u200b\u548c\u200b HybridParallelPlugin \u200b\u5c06\u200b\u5404\u79cd\u200b\u5e76\u884c\u200b\u7279\u6027\u200b\u6ce8\u5165\u200b\u5230\u200b\u6a21\u578b\u200b\u53ca\u5176\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u4e2d\u200b\u3002\u200b\u73b0\u5728\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5f00\u59cb\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u3002 \u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b\u8bad\u7ec3\u200b\u51fd\u6570\u200b\u3002\u200b\u5f53\u200b\u4f7f\u7528\u200b\u4e86\u200b\u7ba1\u9053\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u9700\u8981\u200b\u8c03\u7528\u200b<code>booster.execute_pipeline</code>\u200b\u8fdb\u884c\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u7684\u200b\u9636\u6bb5\u200b\u8c03\u5ea6\u200b\u3002 <pre><code>def train_epoch(\n    epoch: int,\n    model: nn.Module,\n    optimizer: Optimizer,\n    _criterion: Callable,\n    lr_scheduler: LRScheduler,\n    train_dataloader: DataLoader,\n    booster: Booster,\n    coordinator: DistCoordinator,\n):\n    use_pipeline = isinstance(booster.plugin, HybridParallelPlugin) and booster.plugin.pp_size &gt; 1\n    is_pp_last_stage = use_pipeline and booster.plugin.stage_manager.is_last_stage()\n    print_flag = (not use_pipeline and coordinator.is_master()) or (use_pipeline and is_pp_last_stage)\n    total_step = len(train_dataloader)\n\n    model.train()\n    optimizer.zero_grad()\n    train_dataloader_iter = iter(train_dataloader)\n    with tqdm(\n        range(total_step),\n        desc=f\"Epoch [{epoch + 1}/{NUM_EPOCHS}]\",\n        disable=not print_flag,\n    ) as pbar:\n        # Forward pass\n        for _ in pbar:\n            if use_pipeline:\n                outputs = booster.execute_pipeline(\n                    train_dataloader_iter, model, _criterion, optimizer, return_loss=True, return_outputs=True\n                )\n                # Backward and optimize\n                if is_pp_last_stage:\n                    loss = outputs[\"loss\"]\n                    pbar.set_postfix({\"loss\": loss.item()})\n            else:\n                data = next(train_dataloader_iter)\n                data = move_to_cuda(data)\n                outputs = model(**data)\n                loss = _criterion(outputs, None)\n                # Backward\n                booster.backward(loss, optimizer)\n                pbar.set_postfix({\"loss\": loss.item()})\n\n            optimizer.step()\n            optimizer.zero_grad()\n            lr_scheduler.step()\n</code></pre> \u200b\u8bad\u7ec3\u200b GPT-2 \u200b\u6a21\u578b\u200b\u3002 <pre><code>for epoch in range(NUM_EPOCHS):\n    train_epoch(epoch, model, optimizer, _criterion, lr_scheduler, train_dataloader, booster, coordinator)\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/","title":"\u4f7f\u7528\u200b Colossal-AI \uff08\u200b\u4ece\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u5230\u200b\u5f02\u6784\u200b\u5e76\u884c\u200b\uff09\u200b\u52a0\u901f\u200b ViT \u200b\u8bad\u7ec3\u200b\u8be6\u89e3","text":"<p>\u200b\u4f5c\u8005\u200b\uff1aYuxuan Lou, Mingyan Jiang</p> <p>\u200b\u524d\u7f6e\u200b\u6559\u7a0b\u200b - \u200b\u5e76\u884c\u200b\u63d2\u4ef6\u200b - booster API</p> <p>\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b</p> <ul> <li>Colossal-AI Examples ViT on <code>beans</code></li> </ul> <p>\u200b\u76f8\u5173\u200b\u6587\u732e\u200b - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u5728\u200b\u8fd9\u4e2a\u200bViT\u200b\u6a21\u578b\u200b\u7684\u200b\u6837\u4f8b\u200b\u4e2d\u200b\uff0cColossal-AI \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e09\u79cd\u200b\u4e0d\u540c\u200b\u7684\u200b\u5e76\u884c\u200b\u6280\u672f\u200b\u6765\u200b\u52a0\u901f\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff0c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u548c\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u8fd9\u200b\u4e09\u79cd\u200b\u5e76\u884c\u200b\u6280\u672f\u200b\u5728\u200b <code>beans</code> \u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200b ViT\u3002\u200b\u4e3a\u4e86\u200b\u8fd0\u884c\u200b\u9879\u76ee\u200b\uff0c\u200b\u9700\u8981\u200b2-4\u200b\u4e2a\u200b GPU\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_2","title":"\u76ee\u5f55","text":"<ol> <li>Colossal-AI \u200b\u5b89\u88c5\u200b\u65b9\u6cd5\u200b</li> <li>\u200b\u5b9a\u4e49\u200bVIT\u200b\u6a21\u578b\u200b\u53ca\u200b\u76f8\u5173\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b</li> <li>\u200b\u4f7f\u7528\u200b\u4f7f\u7528\u200b HybridParallelPlugin \u200b\u589e\u5f3a\u200bVIT\u200b\u6a21\u578b\u200b</li> <li>\u200b\u4f7f\u7528\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u3001\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u53ca\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200bVIT\u200b\u6a21\u578b\u200b</li> </ol>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#colossal-ai","title":"Colossal-AI \u200b\u5b89\u88c5","text":"<p>\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b Python \u200b\u7684\u200b\u5b98\u65b9\u200b\u7d22\u5f15\u200b\u6765\u200b\u5b89\u88c5\u200b Colossal-AI \u200b\u8f6f\u4ef6\u5305\u200b\u3002 <pre><code>pip install colossalai\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_3","title":"\u5bfc\u5165\u200b\u4f9d\u8d56\u200b\u5e93","text":"<pre><code>from typing import Any, Callable, Iterator\n\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport transformers\nfrom data import BeansDataset, beans_collator\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler as LRScheduler\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import ViTConfig, ViTForImageClassification, ViTImageProcessor\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import GeminiPlugin, HybridParallelPlugin, LowLevelZeroPlugin, TorchDDPPlugin\nfrom colossalai.cluster import DistCoordinator\nfrom colossalai.logging import disable_existing_loggers, get_dist_logger\nfrom colossalai.nn.lr_scheduler import CosineAnnealingWarmupLR\nfrom colossalai.nn.optimizer import HybridAdam\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#vision-transformer","title":"\u5b9a\u4e49\u200b Vision Transformer \u200b\u6a21\u578b","text":"<p>\u200b\u5b9a\u4e49\u200b\u8d85\u200b\u53c2\u6570\u200b <pre><code>SEED = 42\nMODEL_PATH = \"google/vit-base-patch16-224\"\nLEARNING_RATE = 5e-5\nWEIGHT_DECAY = 0.0\nNUM_EPOCH = 3\nWARMUP_RATIO = 0.3\nTP_SIZE = 2\nPP_SIZE = 2\n</code></pre> \u200b\u9996\u5148\u200b\u6211\u4eec\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b <pre><code># Launch ColossalAI\ncolossalai.launch_from_torch(config={}, seed=SEED\u00e5)\ncoordinator = DistCoordinator()\nworld_size = coordinator.world_size\n</code></pre> \u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e4b\u524d\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u6b63\u5e38\u200b\u6d41\u7a0b\u200b\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u7684\u200b\u76f8\u5173\u200b\u7ec4\u200b\uff0c\u200b\u5982\u200b\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff0c\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u5668\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u7b49\u200b\u3002\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u5f53\u200b\u4f7f\u7528\u200b\u7ba1\u9053\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u8fd8\u200b\u9700\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200bcriterion\u200b\u51fd\u6570\u200b\uff0c\u200b\u8be5\u200b\u51fd\u6570\u200b\u7684\u200b\u8f93\u5165\u200b\u662f\u200b\u6a21\u578b\u200b\u524d\u200b\u5411\u200b\u7684\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\uff0c\u200b\u8fd4\u56de\u200b\u7684\u200b\u662f\u200bloss\u3002 \u200b\u83b7\u53d6\u6570\u636e\u200b\u96c6\u200b, <code>BeansDataset</code>\u200b\u5b9a\u4e49\u200b\u5728\u200bdata.py <pre><code>image_processor = ViTImageProcessor.from_pretrained(MODEL_PATH)\ntrain_dataset = BeansDataset(image_processor, TP_SIZE, split=\"train\")\neval_dataset = BeansDataset(image_processor, RP_SIZE, split=\"validation\")\nnum_labels = train_dataset.num_labels\n</code></pre> \u200b\u5b9a\u4e49\u200bVIT\u200b\u6a21\u578b\u200b\uff1a <pre><code>config = ViTConfig.from_pretrained(MODEL_PATH)\nconfig.num_labels = num_labels\nconfig.id2label = {str(i): c for i, c in enumerate(train_dataset.label_names)}\nconfig.label2id = {c: str(i) for i, c in enumerate(train_dataset.label_names)}\nmodel = ViTForImageClassification.from_pretrained(\n    MODEL_PATH, config=config, ignore_mismatched_sizes=True\n)\n</code></pre> \u200b\u5b9a\u4e49\u200boptimizer\uff1a <pre><code>optimizer = HybridAdam(model.parameters(), lr=(LEARNING_RATE * world_size), weight_decay=WEIGHT_DECAY)\n</code></pre> \u200b\u5b9a\u4e49\u200blr scheduler: <pre><code>total_steps = len(train_dataloader) * NUM_EPOCH\nnum_warmup_steps = int(WARMUP_RATIO * total_steps)\nlr_scheduler = CosineAnnealingWarmupLR(\n        optimizer=optimizer, total_steps=(len(train_dataloader) * NUM_EPOCH), warmup_steps=num_warmup_steps\n    )\n</code></pre> \u200b\u5b9a\u4e49\u200bcriterion\u200b\u51fd\u6570\u200b\uff1a <pre><code>def _criterion(outputs, inputs):\n    return outputs.loss\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#vit","title":"\u589e\u5f3a\u200bVIT\u200b\u6a21\u578b","text":"<p>\u200b\u6211\u4eec\u200b\u5f00\u59cb\u200b\u4f7f\u7528\u200bcolossalai\u200b\u7684\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u6765\u200b\u589e\u5f3a\u200b\u6a21\u578b\u200b\uff0c\u200b\u9996\u5148\u200b\u6211\u4eec\u200b\u5148\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b<code>HybridParallelPlugin</code>\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c<code>HybridParallelPlugin</code>\u200b\u5c01\u88c5\u200b\u4e86\u200bcolossalai\u200b\u7684\u200b\u591a\u79cd\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\uff0c\u200b\u4e4b\u540e\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>HybridParallelPlugin</code>\u200b\u5bf9\u8c61\u200b\u6765\u200b\u521d\u59cb\u5316\u200bbooster\u200b\u5e76\u200b\u8c03\u7528\u200b<code>booster.boost</code>\u200b\u6765\u200b\u589e\u5f3a\u200b\u6a21\u578b\u200b\u3002</p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_4","title":"\u534a\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3","text":"<p>\u200b\u5728\u200b<code>HybridParallelPlugin</code>\u200b\u63d2\u4ef6\u200b\u4e2d\u200b\uff0c\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b<code>precision</code>\u200b\u786e\u5b9a\u200b\u8bad\u7ec3\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u53ef\u200b\u652f\u6301\u200b'fp16','bf16','fp32'\u200b\u4e09\u79cd\u200b\u7c7b\u578b\u200b\u3002'fp16','bf16'\u200b\u4e3a\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u7c7b\u578b\u200b\uff0c\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u5728\u200b<code>HybridParallelPlugin</code>\u200b\u4e2d\u6709\u200b\u4e24\u79cd\u200b\u5e94\u7528\u200b\u573a\u666f\u200b\uff0c\u200b\u4e00\u662f\u200b\u4f7f\u7528\u200bzero\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u65f6\u200b\uff0c\u200b\u9700\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u534a\u200b\u7cbe\u5ea6\u200b\uff1b\u200b\u4e8c\u662f\u200b\u6307\u5b9a\u200b\u4f7f\u7528\u200bamp\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200bamp\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u65f6\u200b\uff0c\u200b\u53ef\u200b\u8bbe\u7f6e\u200b\u76f8\u5173\u200b\u53c2\u6570\u200b\u3002 <code>initial_scale</code>\uff08\u200b\u6d6e\u70b9\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1aAMP\u200b\u7684\u200b\u521d\u59cb\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b216\u3002 <code>min_scale</code>\uff08\u200b\u6d6e\u70b9\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1aAMP\u200b\u7684\u200b\u6700\u5c0f\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b1\u3002 <code>growth_factor</code>\uff08\u200b\u6d6e\u70b9\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bAMP\u200b\u65f6\u200b\uff0c\u200b\u7528\u4e8e\u200b\u589e\u52a0\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u7684\u200b\u4e58\u6cd5\u200b\u56e0\u5b50\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b2\u3002 <code>backoff_factor</code>\uff08\u200b\u6d6e\u70b9\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bAMP\u200b\u65f6\u200b\uff0c\u200b\u7528\u4e8e\u200b\u51cf\u5c11\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u7684\u200b\u4e58\u6cd5\u200b\u56e0\u5b50\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b0.5\u3002 <code>growth_interval</code>\uff08\u200b\u6574\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bAMP\u200b\u65f6\u200b\uff0c\u200b\u5f53\u200b\u6ca1\u6709\u200b\u6ea2\u51fa\u200b\u65f6\u200b\u589e\u52a0\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u7684\u200b\u6b65\u6570\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b1000\u3002 <code>hysteresis</code>\uff08\u200b\u6574\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bAMP\u200b\u65f6\u200b\uff0c\u200b\u51cf\u5c11\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u4e4b\u524d\u200b\u7684\u200b\u6ea2\u51fa\u200b\u6b21\u6570\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b2\u3002 <code>max_scale</code>\uff08\u200b\u6d6e\u70b9\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1aAMP\u200b\u7684\u200b\u6700\u5927\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u3002\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b232\u3002</p> <p>\u200b\u4f7f\u7528\u200bAMP\u200b\u7684\u200bplugin\u200b\u793a\u4f8b\u200b\uff1a <pre><code>plugin = HybridParallelPlugin(\n            precision=\"fp16\",\n            initial_scale=1,\n        )\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_5","title":"\u5f20\u91cf\u200b\u5e76\u884c","text":"<p><code>HybridParallelPlugin</code>\u200b\u662f\u200b\u901a\u8fc7\u200bshardformer\u200b\u5b9e\u73b0\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u5728\u200b\u8be5\u200b\u63d2\u4ef6\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u200b\u8bbe\u7f6e\u200b<code>tp_size</code>\u200b\u786e\u5b9a\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7ec4\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u6b64\u5916\u200b\uff0c\u200b\u8fd8\u6709\u200b\u591a\u4e2a\u200b\u53c2\u6570\u200b\u53ef\u200b\u8bbe\u7f6e\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u65f6\u200b\u7684\u200b\u4f18\u5316\u200b\u7279\u6027\u200b\uff1a</p> <p><code>enable_all_optimization</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u542f\u7528\u200bShardformer\u200b\u652f\u6301\u200b\u7684\u200b\u6240\u6709\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u76ee\u524d\u200b\u6240\u6709\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\u5305\u62ec\u200b\u878d\u5408\u200b\u5f52\u4e00\u5316\u200b\u3001flash attention\u200b\u548c\u200bJIT\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>enable_fused_normalization</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u5728\u200bShardformer\u200b\u4e2d\u200b\u542f\u7528\u200b\u878d\u5408\u200b\u5f52\u4e00\u5316\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>enable_flash_attention</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u5728\u200bShardformer\u200b\u4e2d\u200b\u542f\u7528\u200bflash attention\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>enable_jit_fused</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u5728\u200bShardformer\u200b\u4e2d\u200b\u542f\u7528\u200bJIT\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>enable_sequence_parallelism</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u5728\u200bShardformer\u200b\u4e2d\u200b\u542f\u7528\u200b\u5e8f\u5217\u200b\u5e76\u884c\u6027\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>enable_sequence_overlap</code>\uff08\u200b\u5e03\u5c14\u200b\u7c7b\u578b\u200b\uff09\uff1a\u200b\u662f\u5426\u200b\u5728\u200bShardformer\u200b\u4e2d\u200b\u542f\u7528\u200b\u5e8f\u5217\u200b\u91cd\u53e0\u200b\u6027\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002</p> <p>\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u7684\u200bplugin\u200b\u793a\u4f8b\u200b <pre><code>plugin = HybridParallelPlugin(\n            tp_size=4,\n            enable_all_optimization=True\n        )\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_6","title":"\u6d41\u6c34\u7ebf\u200b\u5e76\u884c","text":"<p><code>HybridParallelPlugin</code>\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b<code>pp_size</code>\u200b\u786e\u5b9a\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7ec4\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c<code>num_microbatches</code>\u200b\u8bbe\u7f6e\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u65f6\u200b\u5c06\u200b\u6574\u4e2a\u200bbatch\u200b\u5212\u5206\u200b\u4e3a\u200b\u5c0f\u200bbatch\u200b\u7684\u200b\u6570\u91cf\u200b\uff0c<code>microbatch_size</code>\u200b\u53ef\u200b\u8bbe\u7f6e\u200b\u5c0f\u200bbatch\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u63d2\u4ef6\u200b\u4f1a\u200b\u4f18\u5148\u200b\u4f7f\u7528\u200b<code>num_microbatches</code>\u200b\u6765\u200b\u786e\u5b9a\u200bmicro batch\u200b\u7684\u200b\u914d\u7f6e\u200b\u3002 \u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u7684\u200bplugin\u200b\u793a\u4f8b\u200b <pre><code>plugin = HybridParallelPlugin(\n            pp_size=4,\n            num_microbatches=None,\n            microbatch_size=1\n        )\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_7","title":"\u6570\u636e\u200b\u5e76\u884c","text":"<p><code>HybridParallelPlugin</code>\u200b\u63d2\u4ef6\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u5305\u62ec\u200bzero-dp\u200b\u7cfb\u5217\u200b\u53ca\u200btorch DDP\u3002\u200b\u5f53\u200b<code>zero_stage</code>\u200b\u4e3a\u200b0(\u200b\u9ed8\u8ba4\u503c\u200b)\u200b\u65f6\u200b\u8868\u793a\u200b\u4f7f\u7528\u200btorch DDP\uff0c\u200b\u6ce8\u610f\u200btorch DDP\u200b\u4e0e\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u6709\u200b\u51b2\u7a81\u200b\uff0c\u200b\u4e0d\u80fd\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002<code>zero_stage</code>\u200b\u4e3a\u200b1\u200b\u65f6\u200b\u8868\u793a\u200b\u4f7f\u7528\u200bzero1\u200b\u7b56\u7565\u200b\u3002<code>zero_stage</code>\u200b\u4e3a\u200b2\u200b\u4f7f\u7528\u200bzero2,zero2\u200b\u7b56\u7565\u200b\u4e5f\u200b\u65e0\u6cd5\u200b\u4e0e\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002\u200b\u5982\u679c\u200b\u60f3\u200b\u4f7f\u7528\u200bzero3\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b<code>GeminiPlugin</code>\u3002\u200b\u4f7f\u7528\u200bzero\u200b\u7cfb\u5217\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff0c\u200b\u8bf7\u200b\u8bbe\u7f6e\u200b\u8bad\u7ec3\u200b\u7cbe\u5ea6\u200b\u4e3a\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u3002\u200b\u5f53\u200b\u672a\u6307\u5b9a\u200b\u4f7f\u7528\u200bzero\u200b\u53ca\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\uff0c\u200b\u4e14\u200bworld_size//(tp_size*pp_size)\u200b\u5927\u4e8e\u200b1\u200b\u65f6\u200b\uff0c<code>HybridParallelPlugin</code>\u200b\u4f1a\u4e3a\u200b\u60a8\u200b\u6253\u5f00\u200btorch DDP\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002 torch DDP\u200b\u76f8\u5173\u200b\u53c2\u6570\u8bbe\u7f6e\u200b\uff1a <code>broadcast_buffers</code>\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\uff0c\u200b\u5728\u200b\u8bad\u7ec3\u200b\u5f00\u59cb\u200b\u65f6\u200b\u662f\u5426\u200b\u5e7f\u64ad\u200b\u7f13\u51b2\u533a\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bTrue\u3002 <code>ddp_bucket_cap_mb</code>\uff08\u200b\u6574\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\u7684\u200b\u6876\u200b\u5927\u5c0f\u200b\uff08\u200b\u4ee5\u200bMB\u200b\u4e3a\u200b\u5355\u4f4d\u200b\uff09\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b25\u3002 <code>find_unused_parameters</code>\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\u662f\u5426\u200b\u67e5\u627e\u200b\u672a\u200b\u4f7f\u7528\u200b\u7684\u200b\u53c2\u6570\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>check_reduction\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\u662f\u5426\u200b\u68c0\u67e5\u200b\u51cf\u5c11\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002</code>gradient_as_bucket_view<code>\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\u662f\u5426\u200b\u5c06\u200b\u68af\u5ea6\u200b\u4f5c\u4e3a\u200b\u6876\u200b\u89c6\u56fe\u200b\u4f7f\u7528\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002</code>static_graph`\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bDDP\u200b\u65f6\u200b\u662f\u5426\u200b\u4f7f\u7528\u200b\u9759\u6001\u200b\u56fe\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002</p> <p>Torch DDP\u200b\u7684\u200bplugin\u200b\u793a\u4f8b\u200b <pre><code>plugin = HybridParallelPlugin(\n            tp_size=2,\n            pp_size=1,\n            zero_stage=0,\n            precision=\"fp16\",\n            initial_scale=1,\n        )\n</code></pre> \u200b\u82e5\u200b\u5e76\u884c\u200b\u8fdb\u7a0b\u200b\u4e3a\u200b4\uff0c\u200b\u5219\u200btorch DDP\u200b\u7684\u200b\u5e76\u884c\u200b\u7ec4\u200b\u5927\u5c0f\u200b\u4e3a\u200b2. zero\u200b\u76f8\u5173\u200b\u53c2\u6570\u8bbe\u7f6e\u200b\uff1a <code>zero_bucket_size_in_m</code>\uff08\u200b\u6574\u6570\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bZeRO\u200b\u65f6\u200b\uff0c\u200b\u4ee5\u200b\u767e\u4e07\u200b\u5143\u7d20\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u7684\u200b\u68af\u5ea6\u200b\u51cf\u5c0f\u200b\u6876\u200b\u5927\u5c0f\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b12\u3002 <code>cpu_offload</code>\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bZeRO\u200b\u65f6\u200b\u662f\u5426\u200b\u6253\u5f00\u200b<code>cpu_offload</code>\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bFalse\u3002 <code>communication_dtype</code>\uff08torch\u200b\u6570\u636e\u7c7b\u578b\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bZeRO\u200b\u65f6\u200b\u7684\u200b\u901a\u4fe1\u200b\u6570\u636e\u7c7b\u578b\u200b\u3002\u200b\u5982\u679c\u200b\u672a\u6307\u5b9a\u200b\uff0c\u200b\u5219\u200b\u5c06\u200b\u4f7f\u7528\u200b\u53c2\u6570\u200b\u7684\u200b\u6570\u636e\u7c7b\u578b\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bNone\u3002 <code>overlap_communication</code>\uff08\u200b\u5e03\u5c14\u503c\u200b\uff0c\u200b\u53ef\u9009\u9879\u200b\uff09\uff1a\u200b\u5728\u200b\u4f7f\u7528\u200bZeRO\u200b\u65f6\u200b\u662f\u5426\u200b\u91cd\u53e0\u200b\u901a\u4fe1\u200b\u548c\u200b\u8ba1\u7b97\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u4e3a\u200bTrue\u3002</p> <p>zero1\u200b\u7684\u200bplugin\u200b\u793a\u4f8b\u200b</p> <pre><code>plugin = HybridParallelPlugin(\n            tp_size=1,\n            pp_size=1,\n            zero_stage=1,\n            cpu_offload=True,\n            precision=\"fp16\",\n            initial_scale=1,\n        )\n</code></pre>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#_8","title":"\u6df7\u5408\u200b\u5e76\u884c","text":"<p>\u200b\u53ef\u200b\u53c2\u8003\u200b\u4e0a\u8ff0\u200b\u7684\u200b\u7b56\u7565\u200b\u81ea\u5b9a\u4e49\u200b\u5408\u9002\u200b\u7684\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002\u200b\u5b9a\u4e49\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7684\u200b\u63d2\u4ef6\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u8be5\u200b\u63d2\u4ef6\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200bbooster\uff1a</p> <p><pre><code>plugin = HybridParallelPlugin(\n            tp_size=TP_SIZE,\n            pp_size=PP_SIZE,\n            num_microbatches=None,\n            microbatch_size=1,\n            enable_all_optimization=True,\n            precision=\"fp16\",\n            initial_scale=1,\n        )\nbooster = Booster(plugin=plugin)\n</code></pre> \u200b\u63a5\u7740\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>booster.boost</code>\u200b\u6765\u200b\u5c06\u200bplugin\u200b\u6240\u200b\u5c01\u88c5\u200b\u7684\u200b\u7279\u6027\u200b\u6ce8\u5165\u200b\u5230\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u4e2d\u200b\u3002 <pre><code>model, optimizer, _criterion, train_dataloader, lr_scheduler = booster.boost(\n        model=model, optimizer=optimizer, criterion=criterion, dataloader=train_dataloader, lr_scheduler=lr_scheduler\n    )\n</code></pre></p>"},{"location":"5-%E9%AB%98%E7%BA%A7%E6%95%99%E7%A8%8B/train_vit_with_hybrid_parallelism/#vit_1","title":"\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u8bad\u7ec3\u200b ViT","text":"<p>\u200b\u6700\u540e\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u6765\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e86\u200b\u3002\u200b\u6211\u4eec\u200b\u5148\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b\u8bad\u7ec3\u200b\u51fd\u6570\u200b\uff0c\u200b\u63cf\u8ff0\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u5982\u679c\u200b\u4f7f\u7528\u200b\u4e86\u200b\u7ba1\u9053\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\uff0c\u200b\u9700\u8981\u200b\u8c03\u7528\u200b<code>booster.execute_pipeline</code>\u200b\u6765\u200b\u6267\u884c\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5b83\u4f1a\u200b\u8c03\u7528\u200b<code>scheduler</code>\u200b\u7ba1\u7406\u200b\u6a21\u578b\u200b\u7684\u200b\u524d\u540e\u200b\u5411\u200b\u64cd\u4f5c\u200b\u3002 <pre><code>def run_forward_backward(\n    model: nn.Module,\n    optimizer: Optimizer,\n    criterion: Callable[[Any, Any], torch.Tensor],\n    data_iter: Iterator,\n    booster: Booster,\n):\n    if optimizer is not None:\n        optimizer.zero_grad()\n    if isinstance(booster.plugin, HybridParallelPlugin) and booster.plugin.pp_size &gt; 1:\n        # run pipeline forward backward when enabling pp in hybrid parallel plugin\n        output_dict = booster.execute_pipeline(\n            data_iter, model, criterion, optimizer, return_loss=True, return_outputs=True\n        )\n        loss, outputs = output_dict[\"loss\"], output_dict[\"outputs\"]\n    else:\n        batch = next(data_iter)\n        batch = move_to_cuda(batch, torch.cuda.current_device())\n        outputs = model(**batch)\n        loss = criterion(outputs, None)\n        if optimizer is not None:\n            booster.backward(loss, optimizer)\n\ndef train_epoch(\n    epoch: int,\n    model: nn.Module,\n    optimizer: Optimizer,\n    criterion: Callable[[Any, Any], torch.Tensor],\n    lr_scheduler: LRScheduler,\n    dataloader: DataLoader,\n    booster: Booster,\n    coordinator: DistCoordinator,\n):\n    torch.cuda.synchronize()\n\n    num_steps = len(dataloader)\n    data_iter = iter(dataloader)\n    enable_pbar = coordinator.is_master()\n    if isinstance(booster.plugin, HybridParallelPlugin) and booster.plugin.pp_size &gt; 1:\n        # when using pp, only the last stage of master pipeline (dp_rank and tp_rank are both zero) shows pbar\n        tp_rank = dist.get_rank(booster.plugin.tp_group)\n        dp_rank = dist.get_rank(booster.plugin.dp_group)\n        enable_pbar = tp_rank == 0 and dp_rank == 0 and booster.plugin.stage_manager.is_last_stage()\n    model.train()\n\n    with tqdm(range(num_steps), desc=f\"Epoch [{epoch + 1}]\", disable=not enable_pbar) as pbar:\n        for _ in pbar:\n            loss, _ = run_forward_backward(model, optimizer, criterion, data_iter, booster)\n            optimizer.step()\n            lr_scheduler.step()\n\n            # Print batch loss\n            if enable_pbar:\n                pbar.set_postfix({\"loss\": loss.item()})\n</code></pre> \u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b <pre><code>for epoch in range(NUM_EPOCH):\n    train_epoch(epoch, model, optimizer, criterion, lr_scheduler, train_dataloader, booster, coordinator)\n</code></pre></p>"},{"location":"Colossal-Auto/feature/layout_converting_management/","title":"Layout converting management","text":"<p>\u200b\u5f53\u200b\u4e00\u4e2a\u200b\u5f20\u91cf\u200b\u5728\u200b\u4e0a\u4e0b\u6e38\u200b\u7b97\u5b50\u200b\u4e2d\u200b\u88ab\u200b\u8981\u6c42\u200b\u7684\u200bsharding spec\u200b\u4e0d\u200b\u540c\u65f6\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u5206\u5e03\u200b\u8f6c\u6362\u200b\u5904\u7406\u200b\uff08Layout Conversion\uff09\u3002\u200b\u76ee\u524d\u200b\u4e3b\u6d41\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6709\u200b\u4e24\u79cd\u200b\uff0c\u200b\u6253\u8868\u200b\u8f6c\u6362\u200b\u548c\u200b\u9010\u200b\u7ef4\u5ea6\u200b\u8f6c\u6362\u200b\u3002\u200b\u6253\u8868\u200b\u8f6c\u6362\u200b\u5c31\u662f\u200b\u5c06\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u60c5\u51b5\u200b\u679a\u4e3e\u200b\u51fa\u6765\u200b\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u9047\u5230\u200b\u9700\u8981\u200b\u8f6c\u6362\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u53bb\u200b\u8868\u683c\u200b\u4e2d\u200b\u627e\u5230\u200b\u5bf9\u5e94\u200b\u7684\u200b\u8f6c\u6362\u200b\u65b9\u6848\u200b\u3002 \u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u51fa\u200b\u4e00\u4e2a\u200b\u65b0\u5947\u200b\u7684\u200b\u60f3\u6cd5\u200b\uff0c\u200b\u4f7f\u7528\u200b\u542f\u53d1\u5f0f\u200b\u7684\u200b\u641c\u7d22\u200b\uff0c\u200b\u6765\u200b\u89e3\u51b3\u200bsharding spec\u200b\u7684\u200b\u8f6c\u6362\u200b\u95ee\u9898\u200b\u3002 \u200b\u7136\u800c\u200b\u5b83\u200b\u6709\u200b\u4e00\u4e2a\u200b\u5f88\u5927\u200b\u95ee\u9898\u200b\uff0c\u200b\u5c31\u662f\u200b\u968f\u7740\u200b\u8bbe\u5907\u200b\u5757\u200b\uff08Device Mesh\uff09\u200b\u7684\u200b\u7ef4\u5ea6\u200b\u589e\u52a0\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u7684\u200b\u89c4\u6a21\u200b\u6781\u5177\u200b\u81a8\u80c0\u200b\uff0c\u200b\u4ee5\u81f3\u4e8e\u200b\u65e0\u6cd5\u200b\u901a\u8fc7\u200b\u8fd9\u79cd\u200b\u679a\u4e3e\u200b\u6253\u8868\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6765\u200b\u89e3\u51b3\u200b\u3002\u200b\u9010\u200b\u7ef4\u5ea6\u200b\u8f6c\u6362\u200b\u662f\u200b\u5bf9\u4e8e\u200b\u4e00\u4e2a\u200bN-d tensor\u200b\u7684\u200bsharding spec\uff0cX0X1...Xn-1\uff0c\u200b\u6211\u4eec\u200b\u8ba9\u200bi\u200b\u4ece\u200b0\u200b\u5230\u200bn-1\u200b\u9010\u200b\u7ef4\u5ea6\u200b\u5730\u200b\u8fdb\u884c\u200b\u8f6c\u6362\u200b\uff0c\u200b\u8fd9\u6837\u200b\u4e0d\u7ba1\u200b\u8bbe\u5907\u200b\u5757\u200b\u548c\u200b\u5f20\u91cf\u200b\u7684\u200b\u7ef4\u5ea6\u200b\u591a\u5c11\u200b\uff0c\u200b\u6211\u4eec\u200b\u90fd\u200b\u53ea\u200b\u9700\u8981\u200b\u4e00\u6b21\u200b\u626b\u63cf\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5f97\u5230\u200b\u4e00\u4e2a\u200b\u53ef\u884c\u200b\u7684\u200b\u8f6c\u6362\u200b\u64cd\u4f5c\u200b\u5e8f\u5217\u200b\uff0c\u200b\u7136\u800c\u200b\u5b83\u200b\u95ee\u9898\u200b\u662f\u200b\u8fd9\u6837\u200b\u7684\u200b\u8f6c\u6362\u200b\u6548\u7387\u200b\u4f1a\u200b\u5f88\u200b\u5dee\u200b\u3002\u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u51fa\u200b\u4e00\u4e2a\u200b\u65b0\u5947\u200b\u7684\u200b\u60f3\u6cd5\u200b\uff0c\u200b\u4f7f\u7528\u200b\u542f\u53d1\u5f0f\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u6765\u200b\u89e3\u51b3\u200bsharding spec\u200b\u7684\u200b\u8f6c\u6362\u200b\u95ee\u9898\u200b\u3002\uff0c\u200b\u8fd9\u4e2a\u200b\u7b97\u6cd5\u200b\u53ef\u4ee5\u200b\u63cf\u8ff0\u200b\u4e3a\u200b\uff1a   1. \u200b\u4ece\u200bsource spec\u200b\u751f\u6210\u200b\u6240\u6709\u200b\u7684\u200bone-step transform sharding specs   2. \u200b\u5728\u200bone-step transform sharding specs\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u51fd\u6570\u200b\uff0c\u200b\u6311\u9009\u200b\u4e00\u4e2a\u200b\u201d\u200b\u533a\u522b\u200b\u6700\u5c0f\u200b\u201c\u200b\u7684\u200bsharding spec\u200b\u4f5c\u4e3a\u200b\u540e\u7eed\u200b\u7684\u200bsource sharding spec\uff0c\u200b\u5e76\u200b\u5c06\u200b\u8be5\u200bsharding spec\u200b\u8bb0\u5f55\u200b\u5728\u200btransform path\u200b\u4e2d\u200b\uff0c\u200b\u5982\u679c\u200bone-step transform sharding spec\u200b\u4e2d\u200b\uff0c\u200b\u6709\u200b\u4e0e\u200btarget sharding spec\u200b\u76f8\u540c\u200b\u7684\u200bsharding spec\uff0c\u200b\u5219\u200b\u7b97\u6cd5\u200b\u7ed3\u675f\u200b\u3002   3. \u200b\u91cd\u590d\u200ba\uff0cb\u200b\u76f4\u5230\u200b\u7b97\u6cd5\u200b\u7ed3\u675f\u200b</p> Source/target sharding spec pairs All gather Shard All to All One step transform Best sharding spec Transform path \\(S_{01}RR\uff0c RS_{01}R\\) \\(S_0RR\\) - \\(S_0RS_1, S_0S_1R\\) \\(S_0RR, S_0RS_1, S_0S_1R\\) \\(S_0RR\\) \\(S_0RR\\) \\(S_0RR, RS_{01}RR\\) \\(RRR\\) \\(S_0S_1R, S_0RS_1\\) \\(RS_0R, RRS_0\\) \\(RRR\\), \\(S_0S_1R\\), \\(S_0RS_1\\), \\(RS_0R\\), \\(RRS_0\\) \\(RS_0R\\) \\(S_0RR\\) -&gt; \\(RS_0R\\) \\(RS_0R, RS_{01}RR\\) \\(RRR\\) \\(RS_{01}R, S_1S_0R, RS_0S_1\\) \\(S_0RR, RRS_0\\) \\(RRR\\), \\(RS_{01}R\\), \\(S_1S_0R\\), \\(RS_0S_1\\), \\(S_0RR\\), \\(RRS_0\\) \\(RS_{01}R\\) \\(S_0RR\\) -&gt; \\(RS_0R\\) -&gt; \\(RS_{01}R\\)"},{"location":"Colossal-Auto/get_started/installation/","title":"\u5b89\u88c5","text":""},{"location":"Colossal-Auto/get_started/installation/#_2","title":"\u58f0\u660e","text":"<p>\u200b\u6211\u4eec\u200b\u7684\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u529f\u80fd\u200b\u5904\u4e8e\u200balpha\u200b\u7248\u672c\u200b\uff0c\u200b\u4ecd\u200b\u5728\u200b\u5feb\u901f\u200b\u7684\u200b\u5f00\u53d1\u200b\u8fed\u4ee3\u200b\u4e2d\u200b\u3002\u200b\u6211\u4eec\u200b\u4f1a\u200b\u5728\u200b\u517c\u5bb9\u6027\u200b\u548c\u200b\u7a33\u5b9a\u6027\u200b\u4e0a\u200b\u505a\u200b\u6301\u7eed\u200b\u5730\u200b\u6539\u8fdb\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\uff0c\u200b\u6b22\u8fce\u200b\u968f\u65f6\u200b\u63d0\u200bissue\u200b\u7ed9\u200b\u6211\u4eec\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/installation/#_3","title":"\u8981\u6c42","text":"<p>\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u4e00\u4e9b\u200b\u989d\u5916\u200b\u7684\u200b\u4f9d\u8d56\u6027\u200b\u6765\u200b\u652f\u6301\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u529f\u80fd\u200b\u3002 \u200b\u8bf7\u200b\u5728\u200b\u4f7f\u7528\u200b\u81ea\u52a8\u200b\u5e73\u884c\u200b\u4e4b\u524d\u200b\u5b89\u88c5\u200b\u5b83\u4eec\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/installation/#pytorch","title":"\u5b89\u88c5\u200bPyTorch","text":"<p>\u200b\u6211\u4eec\u200b\u4ec5\u200b\u652f\u6301\u200bPytorch 1.12\uff0c\u200b\u73b0\u5728\u200b\u672a\u200b\u6d4b\u8bd5\u200b\u5176\u4ed6\u200b\u7248\u672c\u200b\u3002 \u200b\u5c06\u6765\u200b\u6211\u4eec\u200b\u5c06\u200b\u652f\u6301\u200b\u66f4\u200b\u591a\u200b\u7248\u672c\u200b\u3002</p> <pre><code>#conda\nconda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3 -c pytorch\n#pip\npip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n</code></pre>"},{"location":"Colossal-Auto/get_started/installation/#pulpcoin-or-cbc","title":"\u5b89\u88c5\u200bpulp\u200b\u548c\u200bcoin-or-cbc","text":"<pre><code>pip install pulp\nconda install -c conda-forge coin-or-cbc\n</code></pre>"},{"location":"Colossal-Auto/get_started/introduction/","title":"\u4ecb\u7ecd","text":"<p>\u200b\u8fd1\u5e74\u6765\u200b\uff0c\u200b\u5927\u89c4\u6a21\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u7684\u200b\u90e8\u7f72\u200b\u53d7\u5230\u200b\u8d8a\u6765\u8d8a\u200b\u591a\u200b\u7684\u200b\u91cd\u89c6\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u76ee\u524d\u200b\u5e38\u89c1\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u5927\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u65b9\u6848\u200b\uff0c\u200b\u90fd\u200b\u4f9d\u8d56\u200b\u7528\u6237\u200b\u4eba\u5de5\u200b\u53cd\u590d\u200b\u5c1d\u8bd5\u200b\u548c\u200b\u7cfb\u7edf\u200b\u4e13\u5bb6\u200b\u7684\u200b\u7ecf\u9a8c\u200b\u6765\u200b\u8fdb\u884c\u200b\u914d\u7f6e\u200b\u90e8\u7f72\u200b\u3002\u200b\u8fd9\u200b\u5bf9\u200b\u7edd\u5927\u591a\u6570\u200bAI\u200b\u5f00\u53d1\u8005\u200b\u6765\u8bf4\u200b\u5341\u5206\u200b\u4e0d\u200b\u53cb\u597d\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u4ed6\u4eec\u200b\u4e0d\u200b\u5e0c\u671b\u200b\u5c06\u200b\u65f6\u95f4\u200b\u7cbe\u529b\u200b\u82b1\u8d39\u200b\u5728\u200b\u7814\u7a76\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u548c\u200b\u8bd5\u9519\u200b\u4e0a\u200b\u3002 Colossal-AI\u200b\u7684\u200bColossal-Auto \u200b\u5e2e\u52a9\u200bAI\u200b\u5f00\u53d1\u8005\u200b\u7b80\u5316\u200b\u4e86\u200b\u5927\u89c4\u6a21\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u7684\u200b\u90e8\u7f72\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u76f8\u6bd4\u200b\u73b0\u6709\u200b\u5176\u4ed6\u200b\u624b\u52a8\u200b\u914d\u7f6e\u200b\u590d\u6742\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u548c\u200b\u4fee\u6539\u200b\u6a21\u578b\u200b\u7684\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff0cColossal-Auto \u200b\u4ec5\u200b\u9700\u200b\u589e\u52a0\u200b\u4e00\u884c\u200b\u4ee3\u7801\u200b\uff0c\u200b\u63d0\u4f9b\u200b cluster \u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u5355\u673a\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5373\u53ef\u200b\u83b7\u5f97\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u80fd\u529b\u200b\uff0c\u200b\u5e76\u4e14\u200b\u539f\u751f\u200b\u652f\u6301\u200b\u5305\u62ec\u200b Hugging Face\uff0cTimm \u200b\u7b49\u200b\u70ed\u95e8\u200b AI \u200b\u6a21\u578b\u5e93\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/introduction/#_2","title":"\u6982\u89c8","text":""},{"location":"Colossal-Auto/get_started/introduction/#_3","title":"\u7528\u6cd5","text":"<pre><code># wrap the model using auto_engine\nmodel = autoparallelize(model, meta_input_samples)\n# normal training loop\n...\n</code></pre>"},{"location":"Colossal-Auto/get_started/introduction/#_4","title":"\u56fe\u200b\u8ffd\u8e2a","text":"<p>Colossal-Auto \u200b\u662f\u200b\u9996\u4e2a\u200b\u57fa\u4e8e\u200b PyTorch \u200b\u6846\u67b6\u200b\u4f7f\u7528\u200b\u9759\u6001\u200b\u56fe\u200b\u5206\u6790\u200b\u7684\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u7cfb\u7edf\u200b\u3002PyTorch \u200b\u4f5c\u4e3a\u200b\u4e00\u4e2a\u200b\u52a8\u6001\u56fe\u200b\u6846\u67b6\u200b\uff0c\u200b\u83b7\u53d6\u200b\u5176\u200b\u9759\u6001\u200b\u7684\u200b\u6267\u884c\u200b\u8ba1\u5212\u200b\u662f\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u7cfb\u7edf\u200b\u9886\u57df\u200b\u88ab\u200b\u957f\u671f\u200b\u7814\u7a76\u200b\u7684\u200b\u95ee\u9898\u200b\u3002Colossal-Auto \u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200b torch.FX Tracer \u200b\u7684\u200b ColoTracer \u200b\u6765\u200b\u5b8c\u6210\u200b\u5bf9\u4e8e\u200b\u6700\u4f18\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u7684\u200b\u641c\u7d22\u200b\u3002\u200b\u5728\u200b tracing \u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u63a8\u5bfc\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u4e86\u200b\u6bcf\u4e2a\u200b tensor \u200b\u7684\u200b\u5143\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4f8b\u5982\u200b tensor shape\uff0cdims\uff0cdtype \u200b\u7b49\u200b\u3002\u200b\u56e0\u6b64\u200b Colossal-AI \u200b\u5177\u6709\u200b\u66f4\u597d\u200b\u7684\u200b\u6a21\u578b\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4f9d\u9760\u200b\u6a21\u578b\u200b\u540d\u200b\u6216\u200b\u624b\u52a8\u200b\u4fee\u6539\u200b\u6765\u200b\u9002\u914d\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/introduction/#_5","title":"\u7ec6\u7c92\u5ea6\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u7b56\u7565\u200b\u641c\u7d22","text":"<p>\u200b\u6211\u4eec\u200b\u8c03\u7814\u200b\u4e86\u200b\u5f88\u591a\u200b\u73b0\u6709\u200b\u7684\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u7cfb\u7edf\u200b\uff08 Tofu ,  Flexflow ,  Alpa \uff09\uff0c\u200b\u4ee5\u53ca\u200b\u81ea\u52a8\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u68c0\u67e5\u70b9\u200b\u7b97\u6cd5\u200b\uff08 Rotor ,  Sublinear \uff09\uff0c\u200b\u5728\u200b\u4ed6\u4eec\u200b\u7684\u200b\u542f\u53d1\u200b\u4e0b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5f00\u53d1\u200b\u4e00\u4e2a\u200b\u57fa\u4e8e\u200bPyTorch\u200b\u6846\u67b6\u200b\u7684\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u7cfb\u7edf\u200bColossal-Auto\u3002Colossal-Auto\u200b\u4f1a\u200b\u5728\u200b\u6ee1\u8db3\u200b\u5185\u5b58\u200b\u9884\u7b97\u200b\u7684\u200b\u9650\u5236\u200b\u4e0b\u200b\uff0c\u200b\u4ee5\u200b\u6700\u5feb\u200b\u8fd0\u884c\u200b\u65f6\u95f4\u200b\u4e3a\u200b\u76ee\u6807\u200b\uff0c\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b op \u200b\u8fdb\u884c\u200b\u7b56\u7565\u200b\u641c\u7d22\u200b\uff0c\u200b\u6700\u7ec8\u200b\u5f97\u5230\u200b\u771f\u5b9e\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u7684\u200b\u7b56\u7565\u200b\uff0c\u200b\u5305\u62ec\u200b\u6bcf\u4e2a\u200b tensor \u200b\u7684\u200b\u5207\u5206\u200b\u7b56\u7565\u200b\uff0c\u200b\u4e0d\u540c\u200b\u8ba1\u7b97\u200b\u8282\u70b9\u200b\u95f4\u200b\u9700\u8981\u200b\u63d2\u5165\u200b\u7684\u200b\u901a\u4fe1\u200b\u7b97\u5b50\u200b\u7c7b\u578b\u200b\uff0c\u200b\u662f\u5426\u200b\u8981\u200b\u8fdb\u884c\u200b\u7b97\u5b50\u200b\u66ff\u6362\u200b\u7b49\u200b\u3002\u200b\u73b0\u6709\u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u7684\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\uff0c\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff0cNVIDIA \u200b\u5728\u200b Megatron-LM \u200b\u7b49\u200b\u5e76\u884c\u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7684\u200b column \u200b\u5207\u5206\u200b\u548c\u200b row \u200b\u5207\u5206\u200b\u5e76\u884c\u200b\u7b49\u200b\u6df7\u5408\u200b\u5e76\u884c\u200b\uff0c\u200b\u90fd\u200b\u662f\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u53ef\u4ee5\u200b\u641c\u7d22\u200b\u5230\u200b\u7684\u200b\u7b56\u7565\u200b\u7684\u200b\u5b50\u96c6\u200b\u3002\u200b\u9664\u4e86\u200b\u8fd9\u4e9b\u200b\u53ef\u4ee5\u200b\u624b\u52a8\u200b\u6307\u5b9a\u200b\u7684\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b\u5916\u200b\uff0cColossal-AI \u200b\u6709\u200b\u80fd\u529b\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b op \u200b\u6307\u5b9a\u200b\u72ec\u7279\u200b\u7684\u200b\u5e76\u884c\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6709\u200b\u53ef\u80fd\u200b\u627e\u5230\u200b\u6bd4\u200b\u4f9d\u8d56\u200b\u4e13\u5bb6\u200b\u7ecf\u9a8c\u200b\u548c\u200b\u8bd5\u9519\u200b\u914d\u7f6e\u200b\u7684\u200b\u624b\u52a8\u200b\u5207\u5206\u200b\u66f4\u597d\u200b\u7684\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/introduction/#tensor-shape-consistency","title":"\u5206\u5e03\u5f0f\u200b tensor \u200b\u4e0e\u200b shape consistency \u200b\u7cfb\u7edf","text":"<p>\u200b\u4e0e\u200b PyTorch \u200b\u6700\u65b0\u200b\u53d1\u5e03\u200b\u7684\u200b DTensor \u200b\u7c7b\u4f3c\u200b\uff0cColossal-AI \u200b\u4e5f\u200b\u4f7f\u7528\u200b\u4e86\u200b device mesh \u200b\u5bf9\u200b\u96c6\u7fa4\u200b\u8fdb\u884c\u200b\u4e86\u200b\u62bd\u8c61\u200b\u7ba1\u7406\u200b\u3002\u200b\u5177\u4f53\u6765\u8bf4\u200b\uff0cColossal-AI \u200b\u4f7f\u7528\u200b sharding spec \u200b\u5bf9\u200b tensor \u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u5b58\u50a8\u72b6\u6001\u200b\u8fdb\u884c\u200b\u6807\u6ce8\u200b\uff0c\u200b\u4f7f\u7528\u200b shape consistency manager \u200b\u81ea\u52a8\u200b\u5730\u200b\u5bf9\u200b\u540c\u4e00\u200b tensor \u200b\u5728\u200b\u4e0d\u540c\u200b sharding spec \u200b\u95f4\u200b\u8fdb\u884c\u200b\u8f6c\u6362\u200b\u3002\u200b\u8fd9\u200b\u8ba9\u200b Colossal-AI \u200b\u7684\u200b\u901a\u7528\u6027\u200b\u548c\u200b\u6613\u7528\u6027\u200b\u6781\u5927\u200b\u5730\u200b\u63d0\u5347\u200b\uff0c\u200b\u501f\u52a9\u200b shape consistency manager \u200b\u53ef\u4ee5\u200b\u6ca1\u6709\u200b\u8d1f\u62c5\u200b\u5730\u200b\u5207\u5206\u200b tensor\uff0c\u200b\u800c\u200b\u4e0d\u7528\u200b\u62c5\u5fc3\u200b\u4e0a\u6e38\u200b op \u200b\u7684\u200b output \u200b\u4e0e\u200b\u4e0b\u6e38\u200b\u7684\u200b input \u200b\u5728\u200b\u96c6\u7fa4\u200b\u4e2d\u200b\u7684\u200b\u5b58\u50a8\u200b\u65b9\u5f0f\u200b\u4e0d\u540c\u200b\u3002</p> <p>\u200b\u76f8\u8f83\u200b\u4e8e\u200b PyTorch DTensor\uff0cColossal-AI \u200b\u6709\u200b\u4ee5\u4e0b\u200b\u4f18\u52bf\u200b\uff1a + Colossal-AI \u200b\u7684\u200b device mesh \u200b\u53ef\u4ee5\u200b profiling \u200b\u5230\u200b\u96c6\u7fa4\u200b\u6027\u80fd\u6307\u6807\u200b\uff0c\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u7684\u200b\u901a\u4fe1\u200b\u7b97\u5b50\u200b\u8fdb\u884c\u200b\u8017\u65f6\u200b\u4f30\u7b97\u200b\u3002 + Colossal-AI \u200b\u7684\u200b shape consistency \u200b\u4f1a\u200b\u8d2a\u5fc3\u200b\u5730\u200b\u641c\u7d22\u200b sharding spec \u200b\u95f4\u200b\u7684\u200b\u8f6c\u6362\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u6734\u7d20\u200b\u5730\u9010\u200b dimension \u200b\u8fdb\u884c\u200b\u8f6c\u6362\u200b\uff0c\u200b\u8fd9\u6837\u200b\u80fd\u200b\u627e\u5230\u200b\u66f4\u200b\u9ad8\u6548\u200b\u7684\u200b\u8f6c\u6362\u200b\u8def\u5f84\u200b\uff0c\u200b\u8fdb\u800c\u200b\u4f7f\u5f97\u200b sharding spec \u200b\u95f4\u200b\u7684\u200b\u8f6c\u6362\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\u66f4\u200b\u5c0f\u200b\u3002 + \u200b\u52a0\u5165\u200b\u4e86\u200b all_to_all \u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4f7f\u5f97\u200b Colossal-AI \u200b\u7684\u200b\u6269\u5c55\u6027\u200b\u66f4\u5f3a\u200b\uff0c\u200b\u8fd9\u200b\u5728\u200b\u5927\u89c4\u6a21\u200b\u96c6\u7fa4\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c55\u73b0\u51fa\u200b\u5f88\u5927\u200b\u7684\u200b\u4f18\u52bf\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/run_demo/","title":"\u5feb\u901f\u200b\u4e0a\u200b\u624b","text":"<p>Colossal-AI \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e1a\u754c\u200b\u6025\u9700\u200b\u7684\u200b\u4e00\u5957\u200b\u9ad8\u6548\u200b\u6613\u7528\u200b\u81ea\u52a8\u200b\u5e76\u884c\u200b\u7cfb\u7edf\u200b\u3002\u200b\u76f8\u6bd4\u200b\u73b0\u6709\u200b\u5176\u4ed6\u200b\u624b\u52a8\u200b\u914d\u7f6e\u200b\u590d\u6742\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u548c\u200b\u4fee\u6539\u200b\u6a21\u578b\u200b\u7684\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff0cColossal-AI \u200b\u4ec5\u200b\u9700\u200b\u589e\u52a0\u200b\u4e00\u884c\u200b\u4ee3\u7801\u200b\uff0c\u200b\u63d0\u4f9b\u200b cluster \u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u5355\u673a\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5373\u53ef\u200b\u83b7\u5f97\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u80fd\u529b\u200b\u3002Colossal-Auto\u200b\u7684\u200b\u5feb\u901f\u200b\u4e0a\u200b\u624b\u200b\u793a\u4f8b\u200b\u5982\u4e0b\u200b\u3002</p>"},{"location":"Colossal-Auto/get_started/run_demo/#1","title":"1. \u200b\u57fa\u672c\u200b\u7528\u6cd5","text":"<p>Colossal-Auto \u200b\u53ef\u200b\u88ab\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u6bcf\u200b\u4e00\u6b21\u200b\u64cd\u4f5c\u200b\u5bfb\u627e\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u6570\u636e\u200b\u3001\u200b\u5f20\u91cf\u200b\uff08\u200b\u5982\u200b1D\u30012D\u3001\u200b\u5e8f\u5217\u5316\u200b\uff09\u200b\u7684\u200b\u6df7\u5408\u200bSPMD\u200b\u5e76\u884c\u200b\u7b56\u7565\u200b\u3002\u200b\u60a8\u200b\u53ef\u200b\u53c2\u8003\u200bGPT \u200b\u793a\u4f8b\u200b\u3002 \u200b\u8be6\u7ec6\u200b\u7684\u200b\u64cd\u4f5c\u200b\u6307\u5f15\u200b\u89c1\u200b\u5176\u200b <code>README.md</code>\u3002</p>"},{"location":"Colossal-Auto/get_started/run_demo/#2-activation-checkpoint","title":"2. \u200b\u4e0e\u200b activation checkpoint \u200b\u7ed3\u5408","text":"<p>\u200b\u4f5c\u4e3a\u200b\u5927\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u5fc5\u4e0d\u53ef\u5c11\u200b\u7684\u200b\u663e\u5b58\u200b\u538b\u7f29\u200b\u6280\u672f\u200b\uff0cColossal-AI \u200b\u4e5f\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5bf9\u4e8e\u200b activation checkpoint \u200b\u7684\u200b\u81ea\u52a8\u200b\u641c\u7d22\u200b\u529f\u80fd\u200b\u3002\u200b\u76f8\u6bd4\u200b\u4e8e\u200b\u5927\u90e8\u5206\u200b\u5c06\u200b\u6700\u5927\u200b\u663e\u5b58\u200b\u538b\u7f29\u200b\u4f5c\u4e3a\u200b\u76ee\u6807\u200b\u7684\u200b\u6280\u672f\u200b\u65b9\u6848\u200b\uff0cColossal-AI \u200b\u7684\u200b\u641c\u7d22\u200b\u76ee\u6807\u200b\u662f\u200b\u5728\u200b\u663e\u5b58\u200b\u9884\u7b97\u200b\u4ee5\u5185\u200b\uff0c\u200b\u627e\u5230\u200b\u6700\u5feb\u200b\u7684\u200b activation checkpoint \u200b\u65b9\u6848\u200b\u3002\u200b\u540c\u65f6\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u907f\u514d\u200b\u5c06\u200b activation checkpoint \u200b\u7684\u200b\u641c\u7d22\u200b\u4e00\u8d77\u200b\u5efa\u6a21\u200b\u5230\u200b SPMD solver \u200b\u4e2d\u200b\u5bfc\u81f4\u200b\u641c\u7d22\u200b\u65f6\u95f4\u200b\u7206\u70b8\u200b\uff0cColossal-AI \u200b\u505a\u200b\u4e86\u200b 2-stage search \u200b\u7684\u200b\u8bbe\u8ba1\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5408\u7406\u200b\u7684\u200b\u65f6\u95f4\u200b\u5185\u200b\u641c\u7d22\u200b\u5230\u200b\u6709\u6548\u200b\u53ef\u884c\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u65b9\u6848\u200b\u3002 \u200b\u60a8\u200b\u53ef\u200b\u53c2\u8003\u200b Resnet \u200b\u793a\u4f8b\u200b\u3002 \u200b\u8be6\u7ec6\u200b\u7684\u200b\u64cd\u4f5c\u200b\u6307\u5f15\u200b\u89c1\u200b\u5176\u200b <code>README.md</code>\u3002</p>"}]}